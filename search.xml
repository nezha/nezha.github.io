<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Redis基础入门学习-主从备份及集群配置]]></title>
    <url>%2FRedis%2F2018-11-16-Redis%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E4%B8%BB%E4%BB%8E%E5%A4%87%E4%BB%BD%E5%8F%8A%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Redis基础入门学习-主从备份及集群配置Redis主从备份1.创建Redis节点 我们在redis-3.2/redis_cluster/下分别创建三个文件夹/6000/,/6001/和/6002/，这种方式用于放置配置文件，模拟创建3个节点。 123cp ./etc/redis.conf ./redis_cluster/6000/cp ./etc/redis.conf ./redis_cluster/6001/cp ./etc/redis.conf ./redis_cluster/6002/ 假设master节点是6000端口 2.修改配置文件 master节点 &gt; 6000 123port 6000pidfile /var/run/redis_6000.pidrequirepass 123456 Slave1节点 &gt; 6001 12345port 6001pidfile /var/run/redis_6001.pidslaveof 47.1xx.xx.66 6000requirepass 123456masterauth 123456 Slave2节点 &gt; 6002 12345port 6002pidfile /var/run/redis_6002.pidslaveof 47.1xx.xx.66 6000requirepass 123456masterauth 123456 3.启动主节点和从节点 启动节点并且验证服务 123456789101112./bin/redis-server ./redis_cluster/6000/redis.conf./bin/redis-server ./redis_cluster/6001/redis.conf./bin/redis-server ./redis_cluster/6002/redis.confps -ef |grep redis# 关闭的话./bin/redis-cli -p 6000 -a 123456 shutdown./bin/redis-cli -p 6001 -a 123456 shutdown./bin/redis-cli -p 6002 -a 123456 shutdown# 批量关闭pkill -9 redis 4.验证主从复制123# 登录Redis服务./bin/redis-cli -h 127.0.0.1 -p 6000 -a 123456# 可以使用info查看主从关系 在主节点中插入，在从节点看一下 Redis集群 参考文献：Redis 集群部署及踩过的坑：http://blog.jobbole.com/113760/玩转Redis集群(上)：https://www.jianshu.com/p/dbc62ed27f03要是您还有解决不了的，来看我这里的问题排坑。 启动Redis多个实例我们在Redis安装目录下创建目录redis_cluster，并编写6000.conf~6005.conf 6个配置文件，这6个配置文件用来启动6个实例，后面将使用这6个实例组成集群。 以6000.conf为例，配置文件需要填写如下几项： 12345678port 6000 //端口6000-6005 bind 0.0.0.0 //默认ip为127.0.0.1 需要改为其他节点机器可访问的ip 否则创建集群时无法访问对应的端口，无法创建集群, 我用的阿里云ECS，就是公网IPdaemonize yes //redis后台运行pidfile ./redis_6000.pid //pidfile文件对应6000-6005 cluster-enabled yes //开启集群 cluster-config-file nodes_6000.conf //集群的配置 配置文件首次启动自动生成 6000-6005 cluster-node-timeout 5000 //请求超时appendonly yes //aof日志开启 有需要就开启，它会每次写操作都记录一条日志 开启端口由于我们集群需要用到6000-6005的端口，所以如果是ECS的话需要将这些端口打开，而且打开Redis的集群总线端口，不然会有很多问题的！ 网上很多文章居然让关防火墙，也是够了。。。 redis集群总线端口为redis客户端端口加上10000，比如说你的redis 6379端口为客户端通讯端口，那么16379端口为集群总线端口 安装Ruby 这一步问题也是比较多的，一定要注意 这一步可以参考本文中的问题一 创建集群 gem 这个命令来安装 redis接口 gem是ruby的一个工具包 1gem install redis 使用redis-trib.rb来建立集群 1./src/redis-trib.rb create --replicas 1 47.1xx.xx.66:6000 47.1xx.xx.66:6001 47.1xx.xx.66:6002 47.1xx.xx.66:6003 47.1xx.xx.66:6004 47.1xx.xx.66:6005 --replicas 1 表示 自动为每一个master节点分配一个slave节点 上面有6个节点，程序会按照一定规则生成 3个master（主）3个slave(从) 登录验证123456789redis-cli -c -h 47.1xx.xx.66 -p 6000 -a 12345647.1xx.xx.66:6000&gt; cluster nodes04b7ed3ea70b9f3b038a4ffcaff691acaa9ceb59 47.1xx.xx.66:6005 slave 306004e971e0a66b9bbb5c9524609680eeaa81f9 0 1542379253546 6 connectedf39cc13f88ec3ce74be94817e688294320327556 47.1xx.xx.66:6003 slave d5d84a1e573c89be2ada38f30be0cecaeeddbe04 0 1542379254046 4 connectedafaa57622d52240ca7be573bc574b6096e0aa0c0 47.1xx.xx.66:6001 master - 0 1542379254547 2 connected 5461-10922306004e971e0a66b9bbb5c9524609680eeaa81f9 47.1xx.xx.66:6002 master - 0 1542379255048 3 connected 10923-163837e941c80b075aee07305a58193d0e47bbc3cc5af 47.1xx.xx.66:6004 slave afaa57622d52240ca7be573bc574b6096e0aa0c0 0 1542379253546 5 connectedd5d84a1e573c89be2ada38f30be0cecaeeddbe04 172.19.91.173:6000 myself,master - 0 0 1 connected 0-5460 遇到的问题问题一:redis requires ruby version 2.2.2 参考文献：redis requires ruby version 2.2.2的解决方案：https://www.jianshu.com/p/72443fef9554 做Redis的Cluster集群的时候，在执行gem install redis时，提示如下错误： 123gem install redis ERROR: Error installing redis: redis requires Ruby version &gt;= 2.2.2. 1.安装RVM（具体命令可以查看官网，Ruby官网地址 和 Ruby官网安装教程）：1234gpg --keyserver hkp://keys.gnupg.net --recv-keys curl -sSL https://get.rvm.io | bash -s stablefind / -name rvm -printsource /usr/local/rvm/scripts/rvm 2.查看rvm库中已知的ruby版本123456789[root@linux ~]# rvm list known MRI Rubies [ruby-]1.8.6[-p420] [ruby-]1.8.7[-head] # security released on head [ruby-]1.9.1[-p431] [ruby-]1.9.2[-p330] [ruby-]1.9.3[-p551] [ruby-]2.0.0[-p648] .... 3.安装使用一个ruby版本12rvm install 2.4.1rvm use 2.4.1 4.常用操作命令12345678# 设置默认版本rvm use 2.4.1 --default# 卸载一个已知版本：rvm remove 2.3.4# 查看ruby版本：ruby --version# 安装redis：gem install redis 问题二：create ERR Slot 9838 is already busy错误https://www.oschina.net/question/1031396_246716 用redis-cli登录到每个节点执行flushall和cluster reset就可以了 问题三：redis集群报错Node is not emptyhttps://www.jianshu.com/p/338bc2a74300 1)将每个节点下aof、rdb、nodes.conf本地备份文件删除；2)172.168.63.201:7001&gt; flushdb #清空当前数据库(可省略)3)之后再执行脚本，成功执行； 问题四：Sorry, can’t connect to nodehttps://blog.csdn.net/xiaobo060/article/details/80616718 因为redis设置了密码需要修改/usr/local/rvm/gems/ruby-2.4.1/gems/redis-4.0.1/lib/redis/client.rb 123456789101112131415DEFAULTS = &#123; :url =&gt; lambda &#123; ENV["REDIS_URL"] &#125;, :scheme =&gt; "redis", :host =&gt; "127.0.0.1", :port =&gt; 6379, :path =&gt; nil, :timeout =&gt; 5.0, :password =&gt; "xxxxxx", :db =&gt; 0, :driver =&gt; nil, :id =&gt; nil, :tcp_keepalive =&gt; 0, :reconnect_attempts =&gt; 1, :inherit_socket =&gt; false&#125; 问题五：redis集群部署一直卡在Waiting for the cluster to join ……在集群的时候redis-trib.rb create --replicas 1一直在等待，网上的那些好多都不靠谱！使用cluster meet ip port命令根本是无效的 同时，很少有博客提到redis集群总线的内容，都是叫你关闭防火墙，实际生产中谁会这么做？最后，感慨一句，还是官方文档最有用！ redis集群总线端口为redis客户端端口加上10000，比如说你的redis 6379端口为客户端通讯端口，那么16379端口为集群总线端口 参考文献 阿里云Redis开发规范：https://yq.aliyun.com/articles/531067?spm=a2c4e.11163080.searchblog.9.38e22ec1b4kcwD 为什么我们做分布式要用 Redis ？：https://mp.weixin.qq.com/s/1TXICDZ_BoJ7FeAFqiZa5A 为什么要用Redis：https://mp.weixin.qq.com/s/XU6k7T7H6TyM9kurDxoGRw]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>主从备份</tag>
        <tag>集群</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis基础入门学习-安装环境]]></title>
    <url>%2FRedis%2F2018-11-14-Redis%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%E4%B9%8B%E5%AE%89%E8%A3%85%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[1. 安装Redis 1.下载和解压缩 123cd /usr/local/wget http://download.redis.io/releases/redis-3.2.1.tar.gztar -zxvf /redis-3.2.1.tar.gz 2.编译安装 1234cd redis-3.2.1make &amp;&amp; make installcd srcmake install PREFIX=/usr/local/redis-3.2.1 3.调整配置文件位置 12# Redis的服务目录mv redis.conf ./etc/ 这样的话差不多就算安装完成了，然后启动文件都在bin/目录中 2. 配置Redis12daemonize：如需要在后台运行，把该项的值改为yesport：监听端口，默认为6379 3. 增加远程密码登录将redis.conf中的配置改为以下配置 123# bind 127.0.0.1protected-mode no Redis的配置文件默认在/etc/redis.conf，找到如下行：去掉前面的注释，并修改为所需要的密码： 123#requirepass foobaredrequirepass myPassword #（其中myPassword就是要设置的密码） 4. 启动Redis 启动命令都在bin目录中启动时指定配置文件 123456# 启动服务./bin/redis-server ./etc/redis.conf# 客户端登录./bin/redis-cli -h 127.0.0.1 -p 6379 -a password# 关闭Redis服务./bin/redis-cli -a password shutdown 5. Redis 压力测试1./bin/redis-benchmark -h 127.0.0.1 -p 6379 -a password -q -n 10000]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>数据库</tag>
        <tag>远程登录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL优化之-explain的正确使用方式]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2018-11-11-explain%E7%9A%84%E6%AD%A3%E7%A1%AE%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[使用Explain优化SQL语句 原文出处：https://my.oschina.net/liughDevelop/blog/1788148 索引类似大学图书馆建书目索引，可以提高数据检索的效率，降低数据库的IO成本。MySQL在300万条记录左右性能开始逐渐下降，虽然官方文档说500~800w记录，所以大数据量建立索引是非常有必要的。MySQL提供了Explain，用于显示SQL执行的详细信息，可以进行索引的优化。 一、导致SQL执行慢的原因： 硬件问题。如网络速度慢，内存不足，I/O吞吐量小，磁盘空间满了等。 没有索引或者索引失效。（一般在互联网公司，DBA会在半夜把表锁了，重新建立一遍索引，因为当你删除某个数据的时候，索引的树结构就不完整了。所以互联网公司的数据做的是假删除.一是为了做数据分析,二是为了不破坏索引 ） 数据过多（分库分表） 服务器调优及各个参数设置（调整my.cnf） 二、分析原因时，一定要找切入点： 先观察，开启慢查询日志，设置相应的阈值（比如超过3秒就是慢SQL），在生产环境跑上个一天过后，看看哪些SQL比较慢。 Explain和慢SQL分析。比如SQL语句写的烂，索引没有或失效，关联查询太多（有时候是设计缺陷或者不得以的需求）等等。 Show Profile是比Explain更近一步的执行细节，可以查询到执行每一个SQL都干了什么事，这些事分别花了多少秒。 找DBA或者运维对MySQL进行服务器的参数调优。 三、什么是索引？MySQL官方对索引的定义为：索引(Index)是帮助MySQL高效获取数据的数据结构。我们可以简单理解为：快速查找排好序的一种数据结构。Mysql索引主要有两种结构：B+Tree索引和Hash索引。我们平常所说的索引，如果没有特别指明，一般都是指B树结构组织的索引(B+Tree索引)。索引如图所示： 最外层浅蓝色磁盘块1里有数据17、35（深蓝色）和指针P1、P2、P3（黄色）。P1指针表示小于17的磁盘块，P2是在17-35之间，P3指向大于35的磁盘块。真实数据存在于子叶节点也就是最底下的一层3、5、9、10、13……非叶子节点不存储真实的数据，只存储指引搜索方向的数据项，如17、35。 查找过程：例如搜索28数据项，首先加载磁盘块1到内存中，发生一次I/O，用二分查找确定在P2指针。接着发现28在26和30之间，通过P2指针的地址加载磁盘块3到内存，发生第二次I/O。用同样的方式找到磁盘块8，发生第三次I/O。 真实的情况是，上面3层的B+Tree可以表示上百万的数据，上百万的数据只发生了三次I/O而不是上百万次I/O，时间提升是巨大的。 四、Explain分析前文铺垫完成，进入实操部分，先来插入测试需要的数据： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758CREATE TABLE `user_info` ( `id` BIGINT (20) NOT NULL AUTO_INCREMENT, `name` VARCHAR (50) NOT NULL DEFAULT '', `age` INT (11) DEFAULT NULL, PRIMARY KEY (`id`), KEY `name_index` (`name`)) ENGINE = INNODB DEFAULT CHARSET = utf8;INSERT INTO user_info (NAME, age) VALUES ('xys', 20);INSERT INTO user_info (NAME, age) VALUES ('a', 21);INSERT INTO user_info (NAME, age) VALUES ('b', 23);INSERT INTO user_info (NAME, age) VALUES ('c', 50);INSERT INTO user_info (NAME, age) VALUES ('d', 15);INSERT INTO user_info (NAME, age) VALUES ('e', 20);INSERT INTO user_info (NAME, age) VALUES ('f', 21);INSERT INTO user_info (NAME, age) VALUES ('g', 23);INSERT INTO user_info (NAME, age) VALUES ('h', 50);INSERT INTO user_info (NAME, age) VALUES ('i', 15);CREATE TABLE `order_info` ( `id` BIGINT (20) NOT NULL AUTO_INCREMENT, `user_id` BIGINT (20) DEFAULT NULL, `product_name` VARCHAR (50) NOT NULL DEFAULT '', `productor` VARCHAR (30) DEFAULT NULL, PRIMARY KEY (`id`), KEY `user_product_detail_index` ( `user_id`, `product_name`, `productor` )) ENGINE = INNODB DEFAULT CHARSET = utf8;INSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p2', 'WL');INSERT INTO order_info (user_id, product_name, productor) VALUES (1, 'p1', 'DX');INSERT INTO order_info (user_id, product_name, productor) VALUES (2, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (2, 'p5', 'WL');INSERT INTO order_info (user_id, product_name, productor) VALUES (3, 'p3', 'MA');INSERT INTO order_info (user_id, product_name, productor) VALUES (4, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (6, 'p1', 'WHH');INSERT INTO order_info (user_id, product_name, productor) VALUES (9, 'p8', 'TE'); 初体验，执行Explain的效果： 索引使用情况在possiblekeys、key和keylen三列，接下来我们先从左到右依次讲解。 1.id12--id 相同,执行顺序由上而下 EXPLAIN SELECT u.*, o.* FROM user_info u, order_info o WHERE u.id = o.user_id; 12--id 不同, 值越大越先被执行 EXPLAIN SELECT * FROM user_info WHERE id = ( SELECT user_id FROM order_info WHERE product_name = 'p8' ); 2.select_type可以看id的执行实例，总共有以下几种类型： SIMPLE： 表示此查询不包含 UNION 查询或子查询 PRIMARY： 表示此查询是最外层的查询 SUBQUERY： 子查询中的第一个 SELECT UNION： 表示此查询是 UNION 的第二或随后的查询 DEPENDENT UNION： UNION 中的第二个或后面的查询语句, 取决于外面的查询 UNION RESULT, UNION 的结果 DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果. DERIVED：衍生，表示导出表的SELECT（FROM子句的子查询） 3.tabletable表示查询涉及的表或衍生的表： 1EXPLAIN SELECT tt.* FROM ( SELECT u.* FROM user_info u, order_info o WHERE u.id = o.user_id AND u.id = 1 ) tt id为1的表是id为2的u和o表衍生出来的。 4.typetype 字段比较重要，它提供了判断查询是否高效的重要依据依据。 通过 type 字段，我们判断此次查询是 全表扫描 还是 索引扫描等。 type 常用的取值有: system: 表中只有一条数据， 这个类型是特殊的 const 类型。 const: 针对主键或唯一索引的等值查询扫描，最多只返回一行数据。 const 查询速度非常快， 因为它仅仅读取一次即可。例如下面的这个查询，它使用了主键索引，因此 type 就是 const 类型的：explain select * from user_info where id = 2； eqref: 此类型通常出现在多表的 join 查询，表示对于前表的每一个结果，都只能匹配到后表的一行结果。并且查询的比较操作通常是 =，查询效率较高。例如：explain select * from userinfo, orderinfo where userinfo.id = orderinfo.userid; ref: 此类型通常出现在多表的 join 查询，针对于非唯一或非主键索引，或者是使用了 最左前缀 规则索引的查询。例如下面这个例子中， 就使用到了 ref 类型的查询：explain select * from userinfo, orderinfo where userinfo.id = orderinfo.userid AND orderinfo.user_id = 5 range: 表示使用索引范围查询，通过索引字段范围获取表中部分数据记录。这个类型通常出现在 =, &lt;&gt;, &gt;, &gt;=, &lt;, &lt;=, IS NULL, &lt;=&gt;, BETWEEN, IN() 操作中。例如下面的例子就是一个范围查询：explain select * from user_info where id between 2 and 8； index: 表示全索引扫描(full index scan)，和 ALL 类型类似，只不过 ALL 类型是全表扫描，而 index 类型则仅仅扫描所有的索引， 而不扫描数据。index 类型通常出现在：所要查询的数据直接在索引树中就可以获取到, 而不需要扫描数据。当是这种情况时，Extra 字段 会显示 Using index。 ALL: 表示全表扫描，这个类型的查询是性能最差的查询之一。通常来说， 我们的查询不应该出现 ALL 类型的查询，因为这样的查询在数据量大的情况下，对数据库的性能是巨大的灾难。 如一个查询是 ALL 类型查询， 那么一般来说可以对相应的字段添加索引来避免。 通常来说, 不同的 type 类型的性能关系如下：ALL &lt; index &lt; range ~ indexmerge &lt; ref &lt; eqref &lt; const &lt; system ALL 类型因为是全表扫描， 因此在相同的查询条件下，它是速度最慢的。而 index 类型的查询虽然不是全表扫描，但是它扫描了所有的索引，因此比 ALL 类型的稍快.后面的几种类型都是利用了索引来查询数据，因此可以过滤部分或大部分数据，因此查询效率就比较高了。 5.possible_keys它表示 mysql 在查询时，可能使用到的索引。 注意，即使有些索引在 possible_keys 中出现，但是并不表示此索引会真正地被 mysql 使用到。 mysql 在查询时具体使用了哪些索引，由 key 字段决定。 6.key此字段是 mysql 在当前查询时所真正使用到的索引。比如请客吃饭,possible_keys是应到多少人，key是实到多少人。当我们没有建立索引时： 123EXPLAIN SELECT o.* FROM order_info o WHERE o.product_name = 'p1' AND o.productor = 'whh'; CREATE INDEX idx_name_productor ON order_info (productor);DROP INDEX idx_name_productor ON order_info; 建立复合索引后再查询： 7.key_len表示查询优化器使用了索引的字节数，这个字段可以评估组合索引是否完全被使用。 8.ref这个表示显示索引的哪一列被使用了，如果可能的话,是一个常量。前文的type属性里也有ref，注意区别。 9.rowsrows 也是一个重要的字段，mysql 查询优化器根据统计信息，估算 sql 要查找到结果集需要扫描读取的数据行数，这个值非常直观的显示 sql 效率好坏， 原则上 rows 越少越好。可以对比key中的例子，一个没建立索引钱，rows是9，建立索引后，rows是4。 10.extra explain 中的很多额外的信息会在 extra 字段显示, 常见的有以下几种内容: using filesort ：表示 mysql 需额外的排序操作，不能通过索引顺序达到排序效果。一般有 using filesort都建议优化去掉，因为这样的查询 cpu 资源消耗大。 using index：覆盖索引扫描，表示查询在索引树中就可查找所需数据，不用扫描表数据文件，往往说明性能不错。 using temporary：查询有使用临时表, 一般出现于排序， 分组和多表 join 的情况， 查询效率不高，建议优化。 using where ：表名使用了where过滤。 五、优化案例1EXPLAIN SELECT u.*, o.* FROM user_info u LEFT JOIN order_info o ON u.id = o.user_id; 执行结果，type有ALL，并且没有索引： 开始优化，在关联列上创建索引，明显看到type列的ALL变成ref，并且用到了索引，rows也从扫描9行变成了1行： 这里面一般有个规律是：左连接索引加在右表上面，右连接索引加在左表上面。 六、是否需要创建索引？索引虽然能非常高效的提高查询速度，同时却会降低更新表的速度。实际上索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录，所以索引列也是要占用空间的。 参考文献【mysql优化专题】本专题终极总结（共13篇）]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>EXPLAIN</tag>
        <tag>数据库优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis开发规范]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F2018-11-09-Redis%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[Redis开发规范 转载说明：文章转载自云栖社区，为了方便自己查看，如有侵权请告知本人阿里云Redis开发规范 一、键值设计1. key名设计 (1)【建议】: 可读性和可管理性 以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id 1ugc:video:1 (2)【建议】：简洁性 保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如： 1user:&#123;uid&#125;:friends:messages:&#123;mid&#125;简化为u:&#123;uid&#125;:fr:m:&#123;mid&#125;。 (3)【强制】：不要包含特殊字符 反例：包含空格、换行、单双引号以及其他转义字符 2. value设计 (1)【强制】：拒绝bigkey(防止网卡流量、慢查询) string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。 反例：一个包含200万个元素的list。 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，查找方法和删除方法 (2)【推荐】：选择适合的数据类型。 例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡) 反例： 123set user:1:name tomset user:1:age 19set user:1:favor football 正例: 1hmset user:1 name tom age 19 favor football 3.【推荐】：控制key的生命周期，redis不是垃圾桶。 建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。 二、命令使用 1.【推荐】 O(N)命令关注N的数量 例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。 2.【推荐】：禁用命令 禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。 3.【推荐】合理使用select redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。 4.【推荐】使用批量操作提高效率 原生命令：例如mget、mset。非原生命令：可以使用pipeline提高效率。但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。 注意两者不同： 1.原生是原子操作，pipeline是非原子操作。2.pipeline可以打包不同的命令，原生做不到3.pipeline需要客户端和服务端同时支持。 5.【建议】Redis事务功能较弱，不建议过多使用 Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决) 6.【建议】Redis集群版本在使用Lua上有特殊要求： 1.所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，”-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS array” 2.所有key，必须在1个slot上，否则直接返回error, “-ERR eval/evalsha command keys must in same slot” 7.【建议】必要情况下使用monitor命令时，要注意不要长时间使用。 三、客户端使用 1.【推荐】 避免多个应用使用一个Redis实例 正例：不相干的业务拆分，公共数据做服务化。 2.【推荐】 使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式： 执行命令如下： 123456789101112Jedis jedis = null;try &#123; jedis = jedisPool.getResource(); //具体的命令 jedis.executeCommand()&#125; catch (Exception e) &#123; logger.error("op key &#123;&#125; error: " + e.getMessage(), key, e);&#125; finally &#123; //注意这里不是关闭连接，在JedisPool模式下，Jedis会被归还给资源池。 if (jedis != null) jedis.close();&#125; 下面是JedisPool优化方法的文章: Jedis常见异常汇总JedisPool资源池优化 3.【建议】 高并发下建议客户端添加熔断功能(例如netflix hystrix) 4.【推荐】 设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持） 5.【建议】 根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。 默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。 其他策略如下： 12345`allkeys-lru`：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。`allkeys-random`：随机删除所有键，直到腾出足够空间为止。`volatile-random`:随机删除过期键，直到腾出足够空间为止。`volatile-ttl`：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。`noeviction`：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息&quot;(error) OOM command not allowed when used memory&quot;，此时Redis只响应读操作。 四、相关工具 1.【推荐】：数据同步 redis间数据同步可以使用：redis-port 2.【推荐】：big key搜索 redis大key搜索工具 3.【推荐】：热点key寻找(内部实现使用monitor，所以建议短时间使用) facebook的redis-faina 阿里云Redis已经在内核层面解决热点key问题，欢迎使用。 五 附录：删除bigkey121. 下面操作可以使用pipeline加速。2. redis 4.0已经支持key的异步删除，欢迎使用。 Hash删除: hscan + hdel 123456789101112131415161718192021public void delBigHash(String host, int port, String password, String bigHashKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;Entry&lt;String, String&gt;&gt; scanResult = jedis.hscan(bigHashKey, cursor, scanParams); List&lt;Entry&lt;String, String&gt;&gt; entryList = scanResult.getResult(); if (entryList != null &amp;&amp; !entryList.isEmpty()) &#123; for (Entry&lt;String, String&gt; entry : entryList) &#123; jedis.hdel(bigHashKey, entry.getKey()); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigHashKey);&#125; List删除: ltrim 12345678910111213141516public void delBigList(String host, int port, String password, String bigListKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; long llen = jedis.llen(bigListKey); int counter = 0; int left = 100; while (counter &lt; llen) &#123; //每次从左侧截掉100个 jedis.ltrim(bigListKey, left, llen); counter += left; &#125; //最终删除key jedis.del(bigListKey);&#125; Set删除: sscan + srem 123456789101112131415161718192021public void delBigSet(String host, int port, String password, String bigSetKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;String&gt; scanResult = jedis.sscan(bigSetKey, cursor, scanParams); List&lt;String&gt; memberList = scanResult.getResult(); if (memberList != null &amp;&amp; !memberList.isEmpty()) &#123; for (String member : memberList) &#123; jedis.srem(bigSetKey, member); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigSetKey);&#125; SortedSet删除: zscan + zrem 123456789101112131415161718192021public void delBigZset(String host, int port, String password, String bigZsetKey) &#123; Jedis jedis = new Jedis(host, port); if (password != null &amp;&amp; !"".equals(password)) &#123; jedis.auth(password); &#125; ScanParams scanParams = new ScanParams().count(100); String cursor = "0"; do &#123; ScanResult&lt;Tuple&gt; scanResult = jedis.zscan(bigZsetKey, cursor, scanParams); List&lt;Tuple&gt; tupleList = scanResult.getResult(); if (tupleList != null &amp;&amp; !tupleList.isEmpty()) &#123; for (Tuple tuple : tupleList) &#123; jedis.zrem(bigZsetKey, tuple.getElement()); &#125; &#125; cursor = scanResult.getStringCursor(); &#125; while (!"0".equals(cursor)); //删除bigkey jedis.del(bigZsetKey);&#125;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>缓存</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Maven 中如何管理多模块项目的依赖关系]]></title>
    <url>%2F%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7%2F2018-11-07-Maven%E4%B8%AD%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E5%A4%9A%E6%A8%A1%E5%9D%97%E9%A1%B9%E7%9B%AE%E7%9A%84%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[Maven 中如何管理多模块项目的依赖关系 平时在查看项目的过程中，发现包的依赖关系及其随便，在各个子模块中都各自引入相应的依赖包，有些时候重复导入了也不会发觉。在参考alibaba dubbo的源码之后，做出如下总结（别人家的代码 ==！） 12groupId：组织标识，一般为：公司网址的反写+项目名artifactId：项目名称，一般为：项目名-模块名 1.首先建一个空的maven项目，项目只需要一个pom.xml文件 交代一下我的demo 项目（root）的groupId是com.nezha.learn.demo 项目名称 artifactId 是 demo 该项目有三个子模块： 123456&lt;!--使用Jedis依赖--&gt;&lt;module&gt;demo-redis&lt;/module&gt;&lt;!--主要用于管理依赖关系--&gt;&lt;module&gt;demo-parent&lt;/module&gt;&lt;!--使用spring boot的依赖--&gt;&lt;module&gt;demo-juc&lt;/module&gt; 2.通过IDEA中New &gt; Module来构建多个模块其中的pom.xml文件如下： 12345678910111213141516171819202122232425262728293031&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.nezha.learn.demo&lt;/groupId&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;version&gt;1.1-SNAPSHOT&lt;/version&gt; &lt;!--这里是我们的子模块列表--&gt; &lt;modules&gt; &lt;!--使用Jedis依赖--&gt; &lt;module&gt;demo-redis&lt;/module&gt; &lt;!--主要用于管理依赖关系--&gt; &lt;module&gt;demo-parent&lt;/module&gt; &lt;!--使用spring boot的依赖--&gt; &lt;module&gt;demo-juc&lt;/module&gt; &lt;/modules&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-release-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt; &lt;configuration&gt; &lt;autoVersionSubmodules&gt;true&lt;/autoVersionSubmodules&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 3.创建一个专门管理依赖包的模块 同样，该模块只有一个pom.xml文件 123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;artifactId&gt;demo&lt;/artifactId&gt; &lt;groupId&gt;com.nezha.learn.demo&lt;/groupId&gt; &lt;version&gt;1.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;artifactId&gt;demo-parent&lt;/artifactId&gt; &lt;!--集中配置版本关系--&gt; &lt;properties&gt; &lt;jedis.version&gt;2.9.0&lt;/jedis.version&gt; &lt;spring-boot.version&gt;1.5.2.RELEASE&lt;/spring-boot.version&gt; &lt;/properties&gt; &lt;!--此处 dependencyManagement 并不会直接引入依赖，是一种懒加载的方式--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--引入Redis的客户端--&gt; &lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;$&#123;jedis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--引入spring boot的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;$&#123;spring-boot.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 注意此处的artifactId是项目名称，因为所有子模块的依赖都在项目root的pom.xml中定义的。 4.在子模块中引入demo-paren的依赖12345678910111213141516171819202122232425&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;artifactId&gt;demo-parent&lt;/artifactId&gt; &lt;groupId&gt;com.nezha.learn.demo&lt;/groupId&gt; &lt;version&gt;1.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../demo-parent/pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;demo-juc&lt;/artifactId&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;$&#123;project.groupId&#125;&lt;/groupId&gt; &lt;artifactId&gt;demo-redis&lt;/artifactId&gt; &lt;version&gt;$&#123;project.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 注意此处的artifactId是demo-parent此时引入的spring依赖是不需要加上版本号的然后${project.groupId}和${project.version用于指代项目和版本。 如何更新所有子模块的版本号 这个也好解决，Maven有插件鸭！ 在父级的pom.xml中加个插件就OK了，plugins &gt; release &gt; update-versions 123456789101112&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-release-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt; &lt;configuration&gt; &lt;autoVersionSubmodules&gt;true&lt;/autoVersionSubmodules&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; maven的pom文件报错： must be “pom” but is “jar” parent工程的pom.xml文件的project节点下加入如下节点： 1&lt;packaging&gt;pom&lt;/packaging&gt; 参考文献 @Maven POM 详解：https://www.jianshu.com/p/8417a94c4d94 使用maven-release-plugin自动化版本发布https://blog.csdn.net/shenchaohao12321/article/details/79302791 spring dubbo的源码：https://github.com/apache/incubator-dubbo-spring-boot-project]]></content>
      <categories>
        <category>开发工具</category>
      </categories>
      <tags>
        <tag>maven</tag>
        <tag>多模块依赖</tag>
        <tag>pom</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dubbo入门学习一（Spring Boot下构建基于多模块的Dubbo项目）]]></title>
    <url>%2FDubbo%2F2018-10-30-Dubbo%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E4%B8%80%2F</url>
    <content type="text"><![CDATA[Dubbo入门学习一 Spring Boot 中使用 Dubbo 详解一开始只是想实现一下Dubbo的功能，也满满的实现了Dubbo的demo例子，但是出于求知欲又引出了一堆问题！一下是主要的几个 如何使用IDEA构建一个多模块的项目 Java项目中如何指定配置路径 SpringBoot 多模块项目（module）Service自动注入（@Autowired）是怎么实现的。 话不多说，直接上项目！ 这是我的Dubbo的实战项目 Spring Boot 注解下使用Dubbo（使用IDEA构建一个多模块的项目）创建父类工程首先使用 Spring Initializr 来快速创建好一个Maven工程。然后删除无关的文件，只需保留pom.xml 文件。 对的！你没看错，就只需要一个pom.xml文件。 在 pom.xml 里面声明该父工程包含的子模块。（其它信息就不逐一讲述了，诸如继承SpringBoot官方父工程以及统一依赖管理 请查看下面的注释说明） 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;!-- 基本信息 --&gt; &lt;modelVersion&gt;1.0.0&lt;/modelVersion&gt; &lt;name&gt;test-dubbo-boot&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!-- 项目说明：这里作为聚合工程的父工程 --&gt; &lt;groupId&gt;com.nezha&lt;/groupId&gt; &lt;artifactId&gt;test-dubbo-boot&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;!-- 继承说明：这里继承SpringBoot提供的父工程 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.6.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;!-- 模块说明：这里声明多个子模块 --&gt; &lt;modules&gt; &lt;module&gt;test-dubbo-boot-api&lt;/module&gt; &lt;module&gt;test-dubbo-boot-provider&lt;/module&gt; &lt;module&gt;test-dubbo-boot-consumer&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;!-- 父工程导入公有的依赖包 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!--dubbo-springBoot依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 创建子类工程 注：这里是使用IDEA来创建子模块，使用Eclipse的小伙伴可通过 Spring Initializr构建，然后复制去进去父工程根目录即可。这里我主要就是按照分层思想创建了三个模块：test-dubbo-boot-api, test-dubbo-boot-provider和test-dubbo-boot-consumer,如下图所示 test-dubbo-boot-api api中主要定义了服务调用的接口，这里的API是会对外暴露出来的。 test-dubbo-boot-provider provider是服务的提供者，这里实现了api的接口，它会注册为服务。 test-dubbo-boot-consumer consumer是服务的调用者。 创建的子项目需要注意的是：一定要继承本项目的父工程 例如test-dubbo-boot-consumer的pom.xml文件 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 基本信息 --&gt; &lt;groupId&gt;com.nezha&lt;/groupId&gt; &lt;artifactId&gt;test-dubbo-boot-provider&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;test-dubbo-boot-provider&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;!-- 继承本项目的父工程 --&gt; &lt;parent&gt; &lt;groupId&gt;com.nezha&lt;/groupId&gt; &lt;artifactId&gt;test-dubbo-boot&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 由于依赖api接口，引入接口包 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.nezha&lt;/groupId&gt; &lt;artifactId&gt;test-dubbo-boot-api&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!-- spring boot项目依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- spring boot的监控模块，非常牛逼 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 这里在provider和consumer的dependency中一定要记住加上test-dubbo-boot-api的依赖，因为服务提供者和消费者都依赖于接口实现的。在现实的项目中这个api的模块就可以单独的打成JAR包给别人使用了。 Spring Boot 的 Actuator 提供了很多生产级的特性，比如监控和度量Spring Boot 应用程序。Actuator 的这些特性可以通过众多 REST 接口、远程 shell 和 JMX 获得。 具体可以参考：Spring Boot Actuator 使用： https://www.jianshu.com/p/af9738634a21Spring Boot Actuator:健康检查、审计、统计和监控： https://www.jianshu.com/p/d5943e303a1f 如果需要监控dubbo的服务可以引入dubbo的Actuator依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-actuator&lt;/artifactId&gt; &lt;version&gt;0.2.0&lt;/version&gt;&lt;/dependency&gt; 编写子模块代码1.test-dubbo-boot-api 这个模块中其实就只有一个接口类 12345package com.nezha.test.dubbo;public interface DemoService &#123; String sayHello(String name);&#125; 2.test-dubbo-boot-provider provider主要有三个文件：接口实现类、配置文件和启动类 1.接口实现类:DemoServiceImpl.java 12345678910111213141516171819202122package com.nezha.test.dubbo.provider;import com.alibaba.dubbo.config.annotation.Service;import com.nezha.test.dubbo.DemoService;import java.net.InetAddress;import java.text.SimpleDateFormat;import java.util.Date;@Servicepublic class DemoServiceImpl implements DemoService &#123; @Override public String sayHello(String name) &#123; try &#123; System.out.println("[" + new SimpleDateFormat("HH:mm:ss").format(new Date()) + "] Hello " + name + ", request from consumer: " + InetAddress.getLocalHost()); return "Hello " + name + ", response from provider: " + InetAddress.getLocalHost(); &#125;catch (Exception e)&#123; return "net error"; &#125; &#125;&#125; 注意这里的Service是alibaba包下的。 2.配置文件：application.properties 1234567891011121314151617# Spring boot applicationspring.application.name = dubbo-provider-demodubbo.application.name = dubbo-provider-demo#注册中心地址dubbo.registry.address=zookeeper://127.0.0.1:2181#协议名称dubbo.protocol.name=dubbo#协议端口dubbo.protocol.port=20880# DemoService service versiondemo.service.version = 1.0.0# Base packages to scan Dubbo Components (e.g @Service , @Reference)dubbo.scan.basePackages = com.nezha.test.dubbo.provider ！！！重要！！！这里有一个非常坑的地方是0.2版本的dubbo-spring-boot-starter中配置 dubbo的时候，ide自动生成的扫描包路径为：dubbo.scan.base-packages,实际上通过properties注入的名字应该为dubbo.scan.basePackages，导致无法扫描到basePackages，故而没有暴露出服务。将base-packages 修改为 basePackages后 发现成功暴露出服务。 3.启动类：TestDubboBootProviderApplication 12345678910111213141516package com.nezha.test.dubbo.provider;import org.springframework.boot.WebApplicationType;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;@SpringBootApplicationpublic class TestDubboBootProviderApplication &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(TestDubboBootProviderApplication.class) .web(WebApplicationType.NONE) .run(args); &#125;&#125; 3.test-dubbo-boot-consumer 消费者也是主要三个文件。 1.服务调用类：DemoConsumerController 12345678910111213141516171819package com.nezha.test.dubbo.consumer;import com.alibaba.dubbo.config.annotation.Reference;import com.nezha.test.dubbo.DemoService;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class DemoConsumerController &#123; @Reference private DemoService demoService; @RequestMapping("/sayHello") public String sayHello(@RequestParam String name) &#123; return demoService.sayHello(name); &#125;&#125; 2.配置文件：application.properties 12345678# Spring boot applicationspring.application.name = dubbo-consumer-demo# Dubbo 服务消费者配置dubbo.application.name=consumerdubbo.registry.address=zookeeper://127.0.0.1:2181# Service Versiondemo.service.version = 1.0.0 3.启动类：TestDubboBootConsumerApplication 123456789101112package com.nezha.test.dubbo.consumer;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication()public class TestDubboBootConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(TestDubboBootConsumerApplication.class, args); &#125;&#125; Dubbo 简介 这部分的资料来自：来自掘金关于Spring Boot Dubbo的实战 Dubbo是阿里巴巴SOA服务化治理方案的核心框架，每天为2,000+个服务提供3,000,000,000+次访问量支持，并被广泛应用于阿里巴巴集团的各成员站点。Dubbo是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。 Dubbo 是什么？Dubbo是一个分布式服务框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。简单的说，dubbo就是个服务框架，如果没有分布式的需求，其实是不需要用的，只有在分布式的时候，才有dubbo这样的分布式服务框架的需求，并且本质上是个服务调用的东东，说白了就是个远程服务调用的分布式框架 其核心部分包含: 1.远程通讯: 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。2.集群容错: 提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。3.自动发现: 基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。 Dubbo 能做什么？1.透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。2.软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。3.服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。 Dubbo 的架构 节点角色说明 节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次调和调用时间的监控中心 Container 服务运行容器 Dubbo提供三个关键功能，包括基于接口的远程呼叫，容错和负载平衡以及自动服务注册和发现 调用关系说明1.服务容器负责启动，加载，运行服务提供者。2.服务提供者在启动时，向注册中心注册自己提供的服务。3.服务消费者在启动时，向注册中心订阅自己所需的服务。4.注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。5.服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。6.服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 Dubbo 特点Dubbo 架构具有以下几个特点，分别是连通性、健壮性、伸缩性、以及向未来架构的升级性 连通性 注册中心负责服务地址的注册与查找，相当于目录服务，服务提供者和消费者只在启动时与注册中心交互，注册中心不转发请求，压力较小 监控中心负责统计各服务调用次数，调用时间等，统计先在内存汇总后每分钟一次发送到监控中心服务器，并以报表展示 服务提供者向注册中心注册其提供的服务，并汇报调用时间到监控中心，此时间不包含网络开销 服务消费者向注册中心获取服务提供者地址列表，并根据负载算法直接调用提供者，同时汇报调用时间到监控中心，此时间包含网络开销 注册中心，服务提供者，服务消费者三者之间均为长连接，监控中心除外 注册中心通过长连接感知服务提供者的存在，服务提供者宕机，注册中心将立即推送事件通知消费者 注册中心和监控中心全部宕机，不影响已运行的提供者和消费者，消费者在本地缓存了提供者列表 注册中心和监控中心都是可选的，服务消费者可以直连服务提供者 健状性 监控中心宕掉不影响使用，只是丢失部分采样数据 数据库宕掉后，注册中心仍能通过缓存提供服务列表查询，但不能注册新服务 注册中心对等集群，任意一台宕掉后，将自动切换到另一台 注册中心全部宕掉后，服务提供者和服务消费者仍能通过本地缓存通讯 服务提供者无状态，任意一台宕掉后，不影响使用 服务提供者全部宕掉后，服务消费者应用将无法使用，并无限次重连等待服务提供者恢复 伸缩性 注册中心为对等集群，可动态增加机器部署实例，所有客户端将自动发现新的注册中心 服务提供者无状态，可动态增加机器部署实例，注册中心将推送新的服务提供者信息给消费者 升级性 当服务集群规模进一步扩大，带动IT治理结构进一步升级，需要实现动态部署，进行流动计算，现有分布式服务架构不会带来阻力。下图是未来可能的一种架构： 节点角色说明 节点 角色说明 Deployer 自动部署服务的本地代理 Repository 仓库用于存储服务应用发布包 Scheduler 调度中心基于访问压力自动增减服务提供者 Admin 统一管理控制台 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次调和调用时间的监控中心 参考文献 好消息：Dubbo &amp; Spring Boot要来了 Spring Boot集成的新特性可参考官方文档: https://github.com/apache/incubator-dubbo-spring-boot-project 听听八年阿里架构师怎样讲述Dubbo和Spring Cloud微服务架构: Spring Boot Dubbo applications.properties 配置清单 肥朝的Dubbo源码学习https://www.jianshu.com/u/f7daa458b874 Spring Boot 中使用 Dubbo 详解：https://juejin.im/post/59f43c025188253d6816d7fe，这篇文章在掘金中找到的，很不错 dubbo-spring-boot-starter 的官方地址：https://github.com/apache/incubator-dubbo-spring-boot-project，一开始问题一直不知道怎么解决，看了github上的Issues终于解决了！]]></content>
      <categories>
        <category>Dubbo</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>Dubbo</tag>
        <tag>RPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[开发过程中出现的各类问题整理]]></title>
    <url>%2F%E7%96%91%E9%9A%BE%E8%A7%A3%E6%83%91%2F2018-10-15-%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%87%BA%E7%8E%B0%E7%9A%84%E5%90%84%E7%B1%BB%E9%97%AE%E9%A2%98%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[开发过程中出现的各类问题整理一：IDEA开发中的问题及注意项1.IDEA console出现乱码 1.修改IDEA的配置文件 打开Intellij的安装的bin目录，找到idea.exe.vmoptions和idea64.exe.vmoptions两个文件（根据你的系统是32位或64位选择其中一个配置文件），在配置文件中添加： 1-Dfile.encoding=UTF-8 2.配置项目编码及IDE编码 进入settings，选择File Encodings，把IDE Encoding和Project Encoding配置为UTF-8，同时将下面的Default encoding for properties files也配置为UTF-8。 3.配置项目启动服务器参数，在tomcat配置中 在VM options 项中添加 1-Dfile.encoding=UTF-8 2.IDEA 中spring boot 多模块项目SpringBoot多模块项目实践（Multi-Module）-https://segmentfault.com/a/1190000011367492 二：maven1.maven中引用父类pom时，怎么在子模块中引入父类包？还有子模块中${project.version}指代的什么版本？这个可以参考我的博客，[关于多模块项目中的依赖管理]https://nezhaxiaozi.coding.me/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/2018-11-07-Maven%E4%B8%AD%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E5%A4%9A%E6%A8%A1%E5%9D%97%E9%A1%B9%E7%9B%AE%E7%9A%84%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB/ 2.maven中怎么将一个空项目编程Spring Boot项目 1.首先是增加依赖包，主要是spring-boot-starter 12345678910&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2.在resources的文件夹中增加配置文件application.properties 这个一般是spring boot有默认的文件名 3.在包路径根目录下增加Spring Boot启动类 1234567891011package com.nezha.learn.demo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class DemoRedisApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(DemoRedisApplication.class, args); &#125;&#125; 4.如果需要使用测试类，可以增加同样的包路径和注解 1234567891011package com.nezha.learn.demo;import org.junit.runner.RunWith;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTestpublic class DemoRedisApplicationTest &#123;&#125; 三：Java1.为什么Java的实体类需要实现Serializable接口参考文献：Java类中serialversionuid 作用 是什么?举个例子说明https://www.cnblogs.com/duanxz/p/3511695.html Java的序列化机制是通过判断类的serialVersionUID来验证版本一致性的。在进行反序列化时，JVM会把传来的字节流中的serialVersionUID与本地相应实体类的serialVersionUID进行比较，如果相同就认为是一致的，可以进行反序列化，否则就会出现序列化版本不一致的异常，即是InvalidCastException。 四：Spring1.为什么Spring使用接口注入，而不是实现类（而且不是显示的指代接口的实现类） Spring Boot 注入接口 @Autowired interface:https://www.jianshu.com/p/3942cce05f71 2.如果spring的版本修改后，和pom的其他依赖不一样，可不可以 这个一般都是统一管理依赖版本的，依赖版本不一致很有可能出现各种错误的 3.Spring boot中自定义的配置怎么加载和读取4.Spring项目中classpath指代哪个路径[Java][MyBatis]mapperLocations属性通配符的使用- https://blog.csdn.net/szwangdf/article/details/23432783 5.Junit集成测试–Mock http://sishuok.com/forum/blogPost/list/7981.html http://www.cnblogs.com/0201zcr/p/5756642.html Junit 按顺序排序 1@FixMethodOrder(MethodSorters.DEFAULT) 6.SpringBoot 多模块项目（module）Service自动注入（@Autowired） SpringBoot 多模块项目（module）Service自动注入（@Autowired）https://blog.csdn.net/machuang30508/article/details/78616501SpringBoot中Service自动注入很方便，例： Service.class（接口类） ServiceImpl.class（实现类） Controller.class（使用类）用以上三个类来说一下自动注入： 单项目：分别ServiceImpl头上@Service，Controller中Service对象@Autowired即可享用； Multi modules 场景，三个（种）类分别在三个module下： moduleA : Service.class（com.example.moduleA ） moduleB : ServiceImpl.class ( com.example.moduleB ) moduleC : Controller.class ( com.example.moduleC ) 此时B依赖A，C依赖A、B，添加好依赖关系。 如何自动注入？接口、实现、使用类，姿势不变,按单项目方式写即可; 如果你已经试过scanBasePackages，无论是在@SpringBootApplication方式还是@ComponentScan；抑或试过@SpringBootApplication、@ComponentScan同时用，当你这么做时，一定是绝望的。 解决办法:@SpringBootApplictaion(scanBasePackages=&quot;com.example&quot;)核心就是：Service 及 ServiceImpl均需在com.example包下 因为Service、ServiceImpl同在com.example下（C可以不在），所以我看作是同一次scan过程；当然（@ComponentScan=&quot;com.example&quot;）也是可以的，因为前者@SpringBootApplication已经包含@ComponentScan； 7.SpringBoot如何快速运行Service中的方法12345678@SpringBootApplicationpublic class DemoRedisApplication &#123; public static void main(String[] args) &#123; ApplicationContext ctx = SpringApplication.run(DemoRedisApplication.class, args); UseRedisDemo useRedisDemo = ctx.getBean(UseRedisDemo.class); useRedisDemo.say("nezha"); &#125;&#125; 五：MySQL六：Redis问题一:redis requires ruby version 2.2.2 参考文献：redis requires ruby version 2.2.2的解决方案：https://www.jianshu.com/p/72443fef9554 做Redis的Cluster集群的时候，在执行gem install redis时，提示如下错误： 123gem install redis ERROR: Error installing redis: redis requires Ruby version &gt;= 2.2.2. 1.安装RVM（具体命令可以查看官网，Ruby官网地址 和 Ruby官网安装教程）：1234gpg --keyserver hkp://keys.gnupg.net --recv-keys curl -sSL https://get.rvm.io | bash -s stablefind / -name rvm -printsource /usr/local/rvm/scripts/rvm 2.查看rvm库中已知的ruby版本123456789[root@linux ~]# rvm list known MRI Rubies [ruby-]1.8.6[-p420] [ruby-]1.8.7[-head] # security released on head [ruby-]1.9.1[-p431] [ruby-]1.9.2[-p330] [ruby-]1.9.3[-p551] [ruby-]2.0.0[-p648] .... 3.安装使用一个ruby版本12rvm install 2.4.1rvm use 2.4.1 4.常用操作命令12345678# 设置默认版本rvm use 2.4.1 --default# 卸载一个已知版本：rvm remove 2.3.4# 查看ruby版本：ruby --version# 安装redis：gem install redis 问题二：create ERR Slot 9838 is already busy错误https://www.oschina.net/question/1031396_246716 用redis-cli登录到每个节点执行flushall和cluster reset就可以了 问题三：redis集群报错Node is not emptyhttps://www.jianshu.com/p/338bc2a74300 1)将每个节点下aof、rdb、nodes.conf本地备份文件删除；2)172.168.63.201:7001&gt; flushdb #清空当前数据库(可省略)3)之后再执行脚本，成功执行； 问题四：Sorry, can’t connect to nodehttps://blog.csdn.net/xiaobo060/article/details/80616718 因为redis设置了密码需要修改/usr/local/rvm/gems/ruby-2.4.1/gems/redis-4.0.1/lib/redis/client.rb 123456789101112131415DEFAULTS = &#123; :url =&gt; lambda &#123; ENV["REDIS_URL"] &#125;, :scheme =&gt; "redis", :host =&gt; "127.0.0.1", :port =&gt; 6379, :path =&gt; nil, :timeout =&gt; 5.0, :password =&gt; "xxxxxx", :db =&gt; 0, :driver =&gt; nil, :id =&gt; nil, :tcp_keepalive =&gt; 0, :reconnect_attempts =&gt; 1, :inherit_socket =&gt; false&#125; 问题五：redis集群部署一直卡在Waiting for the cluster to join ……在集群的时候redis-trib.rb create --replicas 1一直在等待，网上的那些好多都不靠谱！使用cluster meet ip port命令根本是无效的 同时，很少有博客提到redis集群总线的内容，都是叫你关闭防火墙，实际生产中谁会这么做？最后，感慨一句，还是官方文档最有用！ redis集群总线端口为redis客户端端口加上10000，比如说你的redis 6379端口为客户端通讯端口，那么16379端口为集群总线端口 七：VSCode1.如何快速折叠代码，如何展开代码折叠 –&gt;&gt; command+k+0展开 –&gt;&gt; command+k+j]]></content>
      <categories>
        <category>疑难解惑</category>
      </categories>
      <tags>
        <tag>开发问题</tag>
        <tag>问题解决</tag>
        <tag>百宝箱</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java序列化与反序列化-原生方式与Jackson方式]]></title>
    <url>%2FJava%2F2017-12-14-Java%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96%EF%BC%88%E5%8E%9F%E7%94%9F%E6%96%B9%E5%BC%8F%E4%B8%8EJackson%E6%96%B9%E5%BC%8F%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Java序列化与反序列化 交流或更多内容请关注我的公众号：nezha_blog 我的技术博客：https://nezha.github.io 当两个进程在进行远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。发送方需要把这个Java对象转换为字节序列，才能在网络上传送；接收方则需要把字节序列再恢复为Java对象。 现在主要的序列化方式主要是两个种。一种是Java原生以流的方法进行的序列化，另外一种就是Json序列化方式。我这里Json的序列化方式主要是以Jackson为例。 1. Java原生序列化这种方式只能将支持 java.io.Serializable 接口的对象写入流中。每个 serializable 对象的类都被编码，编码内容包括类名和类签名、对象的字段值和数组值，以及从初始对象中引用的其他所有对象的闭包。 概念 序列化：把Java对象转换为字节序列的过程。 反序列化：把字节序列恢复为Java对象的过程。 用途 把对象的字节序列永久地保存到硬盘上，通常存放在一个文件中； 在网络上传送对象的字节序列。 对象序列化java.io.ObjectOutputStream代表对象输出流，它的writeObject(Object obj)方法可对参数指定的obj对象进行序列化，把得到的字节序列写到一个目标输出流中。只有实现了Serializable和Externalizable接口的类的对象才能被序列化。 java.io.ObjectInputStream代表对象输入流，它的readObject()方法从一个源输入流中读取字节序列，再把它们反序列化为一个对象，并将其返回。 示例代码 123456789101112131415161718192021222324252627282930313233343536373839import java.io.*;import java.util.Date;public class ObjectSaver &#123; public static void main(String[] args) throws Exception &#123; /*其中的 ./objectFile.obj 表示存放序列化对象的文件*/ //序列化对象 ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream("./objectFile.obj")); Customer customer = new Customer("王麻子", 24); out.writeObject("你好!"); //写入字面值常量 out.writeObject(new Date()); //写入匿名Date对象 out.writeObject(customer); //写入customer对象 out.close(); //反序列化对象 ObjectInputStream in = new ObjectInputStream(new FileInputStream("./objectFile.obj")); System.out.println("obj1 " + (String) in.readObject()); //读取字面值常量 System.out.println("obj2 " + (Date) in.readObject()); //读取匿名Date对象 Customer obj3 = (Customer) in.readObject(); //读取customer对象 System.out.println("obj3 " + obj3); in.close(); &#125;&#125;class Customer implements Serializable &#123; private String name; private int age; public Customer(String name, int age) &#123; this.name = name; this.age = age; &#125; public String toString() &#123; return "name=" + name + ", age=" + age; &#125;&#125; 2. 使用Jackson序列化对象pom中增加依赖关系 一开始我还把jackson-annotations和jackson-core也加到pom中了，但是我后来发现databind也包含了这两个依赖，这样我就重复导包了。 1234&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt;&lt;/dependency&gt; 准备工作：12ObjectMapper mapper = new ObjectMapper(); //转换器mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false); 将对象序列化主要使用的是writeValueAsString的函数 1String json=mapper.writeValueAsString(user); //将对象转换成json 将Json字符串对象化(反序列化)主要使用的是readValue的函数 1Map m = mapper.readValue(json, Map.class); 编程实现 User类 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106public class User&#123; private String id; //标识 private String name; //姓名 private int age; //年龄 private double pay; //工资 private boolean valid; //是否有效 private char one; //一个字符 @JsonFormat(pattern = "yyyy-mm-dd") private Date birthday; //生日 private Link link; //联系方式，自定义 private Map map; //测试用 private List list; //测试用 private Set set; //测试用 public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public double getPay() &#123; return pay; &#125; public void setPay(double pay) &#123; this.pay = pay; &#125; public boolean isValid() &#123; return valid; &#125; public void setValid(boolean valid) &#123; this.valid = valid; &#125; public char getOne() &#123; return one; &#125; public void setOne(char one) &#123; this.one = one; &#125; public Date getBirthday() &#123; return birthday; &#125; public void setBirthday(Date birthday) &#123; this.birthday = birthday; &#125; public Link getLink() &#123; return link; &#125; public void setLink(Link link) &#123; this.link = link; &#125; public Map getMap() &#123; return map; &#125; public void setMap(Map map) &#123; this.map = map; &#125; public List getList() &#123; return list; &#125; public void setList(List list) &#123; this.list = list; &#125; public Set getSet() &#123; return set; &#125; public void setSet(Set set) &#123; this.set = set; &#125;&#125; Link类 1234567891011121314151617181920212223242526272829303132public class Link&#123; private String phone; //移动电话 private String address; //地址 private String qq; //QQ public String getPhone() &#123; return phone; &#125; public void setPhone(String phone) &#123; this.phone = phone; &#125; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125; public String getQq() &#123; return qq; &#125; public void setQq(String qq) &#123; this.qq = qq; &#125;&#125; 主函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990public class JacksonTest &#123; public static void main(String[] args) throws JsonGenerationException,JsonMappingException,IOException &#123; User user=new User(); user.setId("01"); user.setName("张三"); user.setAge(33); user.setPay(6666.88); user.setValid(true); user.setOne('E'); user.setBirthday(new Date(20l*366*24*3600*1000)); //1990年 Link link = new Link(); link.setAddress("河南省济源市"); link.setPhone("13899995555"); link.setQq("123456"); user.setLink(link); Map map=new HashMap(); map.put("aa", "this is aa"); map.put("bb", "this is bb"); map.put("cc", "this is cc"); user.setMap(map); List list=new ArrayList()&#123;&#125;; list.add("普洱"); list.add("大红袍"); user.setList(list); Set set=new HashSet(); set.add("篮球"); set.add("足球"); set.add("乒乓球"); user.setSet(set); ObjectMapper mapper = new ObjectMapper(); //转换器 //测试01：对象--json String json=mapper.writeValueAsString(user); //将对象转换成json System.out.println(json); /* 结果如下： &#123;"id":"01","name":"张三","age":33,"pay":6666.88,"valid":true,"one":"E","birthday":1465185448998, "link":&#123;"phone":"13899995555","address":"河南省济源市","qq":"123456"&#125;, "map":&#123;"aa":"this is aa","bb":"this is bb","cc":"this is cc"&#125;, "list":["普洱","大红袍"], "set":["乒乓球","足球","篮球"]&#125; 注意点：（1） 日期--长整型 （2）List、Set均转成数组 */ //测试02：json--map Map m = mapper.readValue(json, Map.class); //json转换成map System.out.println("pay："+m.get("pay").getClass().getName()); //java.lang.Double System.out.println("valid："+m.get("valid").getClass().getName()); //java.lang.Boolean System.out.println("birthday："+m.get("birthday").getClass().getName()); //java.lang.Long System.out.println("link："+m.get("link").getClass().getName()); //java.util.LinkedHashMap System.out.println("map："+m.get("map").getClass().getName()); //java.util.LinkedHashMap System.out.println("list："+m.get("list").getClass().getName()); //java.util.ArrayList System.out.println("set："+m.get("set").getClass().getName()); //java.util.ArrayList /* 结果如下： pay：java.lang.Double valid：java.lang.Boolean birthday：java.lang.Long link：java.util.LinkedHashMap map：java.util.LinkedHashMap list：java.util.ArrayList set：java.util.ArrayList 注意点：（1） 日期--长整型 （2）map、子对象均转换成了LinkedHashMap （3）List、Set均转成ArrayList */ mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES,false); //测试03：map--json json=mapper.writeValueAsString(m); //map转json System.out.println(json); //与之前格式完全相同，说明经过map转换后，信息没有丢失 //测试04：json--对象 User u=mapper.readValue(json, User.class); //json转java对象。经测，转成对象后，一切恢复正常 System.out.println("pay："+u.getPay()); System.out.println("valid："+u.isValid()); System.out.println("birthday："+u.getBirthday()); System.out.println("link："+u.getLink().getAddress()); System.out.println("map："+u.getMap()); System.out.println("list："+u.getList()); System.out.println("set："+u.getSet()); //测试05：其他转换 byte[] data=mapper.writeValueAsBytes(u); //对象转成二进制数组 &#125;&#125;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Jackson</tag>
        <tag>序列化</tag>
        <tag>ObjectOutputStream</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构与算法-排序算法]]></title>
    <url>%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%2F2017-12-13-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95-%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序算法 交流或更多内容请关注我的公众号：nezha_blog 我的技术博客：https://nezha.github.io 冒泡排序原理 俩俩比较相邻记录的排序码，若发生逆序，则交换；有俩种方式进行冒泡，一种是先把小的冒泡到前边去，另一种是把大的元素冒泡到后边。 性能 时间复杂度为$O(N^2)$，空间复杂度为$O(1)$。排序是稳定的，排序比较次数与初始序列无关，但交换次数与初始序列有关。 优化 若初始序列就是排序好的，对于冒泡排序仍然还要比较$O(N^2)$次，但无交换次数。可根据这个进行优化，设置一个flag，当在一趟序列中没有发生交换，则该序列已排序好，但优化后排序的时间复杂度没有发生量级的改变。 ###代码 1234567891011121314public static void bubbleSort(int[] arr) &#123; for (int i = 0; i &lt; arr.length - 1; i++) &#123; boolean flag = true; for (int j = arr.length - 1; j &gt; i; j--) &#123; if (arr[j] &lt; arr[j - 1]) &#123; int tmp = arr[j]; arr[j] = arr[j - 1]; arr[j - 1] = tmp; flag = false; &#125; &#125; if (flag) return; &#125;&#125; 插入排序原理依次选择一个待排序的数据，插入到前边已排好序的序列中。 性能时间复杂度为$O(N^2)$，空间复杂度为$O(1)$。算法是稳定的，比较次数和交换次数都与初始序列有关。 优化直接插入排序每次往前插入时，是按顺序依次往前找，可在这里进行优化，往前找合适的插入位置时采用二分查找的方式，即折半插入。 折半插入排序相对直接插入排序而言：平均性能更快，时间复杂度降至$O(NlogN)$，排序是稳定的，但排序的比较次数与初始序列无关，总是需要$foor(log(i))+1$次排序比较。 代码123456789101112public static void insertSort(int[] arr) &#123; for (int i = 1; i &lt; arr.length; i++)&#123; out: for (int j=i;j&gt;0;j--)&#123; if (arr[j] &lt; arr[j-1])&#123; int tmp = arr[j]; arr[j] = arr[j-1]; arr[j-1] = tmp; &#125;else break out; &#125; &#125;&#125; 1234567891011121314151617181920public static void insertBinarySort(int[] arr)&#123; for (int i = 1; i &lt; arr.length; i++)&#123; if (arr[i] &lt; arr[i-1])&#123; int temp = arr[i]; int low = 0, high = i - 1, mid; while (low &lt;= high)&#123; mid = (low + high) / 2; if (temp &lt; arr[mid])&#123; high = mid - 1; &#125;else &#123; low = mid + 1; &#125; &#125; for (int j = i; j &gt;low; j--)&#123; arr[j] = arr[j - 1]; &#125; arr[low] = temp; &#125; &#125;&#125; 希尔排序原理插入排序的改进版，是基于插入排序的以下俩点性质而提出的改进方法： 插入排序对几乎已排好序的数据操作时，效率很高，可以达到线性排序的效率。 但插入排序在每次往前插入时只能将数据移动一位，效率比较低。 所以希尔排序的思想是： 先是取一个合适的gap&lt;n作为间隔，将全部元素分为gap个子序列，所有距离为gap的元素放入同一个子序列，再对每个子序列进行直接插入排序； 缩小间隔gap，例如去gap=ceil(gap/2)，重复上述子序列划分和排序 直到，最后gap=1时，将所有元素放在同一个序列中进行插入排序为止。 ###性能 开始时，gap取值较大，子序列中的元素较少，排序速度快，克服了直接插入排序的缺点；其次，gap值逐渐变小后，虽然子序列的元素逐渐变多，但大多元素已基本有序，所以继承了直接插入排序的优点，能以近线性的速度排好序。 ###代码 12345678910111213141516171819public static void shellSort(int[] arr) &#123; int gap = Math.round(arr.length / 2); while (gap &gt; 0) &#123; for (int i = 0;i&lt;gap;i++)&#123; for (int j = i + gap;j&lt;arr.length;j+=gap)&#123; if (arr[j] &gt; arr[j-gap])&#123; int temp = arr[j]; int k = j - gap; while (k &gt;= 0 &amp;&amp; arr[k] &gt; temp) &#123; arr[k + gap] = arr[k]; k -= gap; &#125; arr[k + gap] = temp; &#125; &#125; &#125; &#125;&#125; 123456789101112public static void shellSort2(int[] arr)&#123; for (int gap = arr.length / 2; gap &gt; 0; gap /= 2)&#123; for (int i = 0; i &lt; arr.length; i = i + gap)&#123; int temp = arr[i]; int j; for (j = i; j &gt;= gap &amp;&amp; temp &lt; arr[j-gap]; j -= gap)&#123; arr[j] = arr[j - gap]; &#125; arr[j] = temp; &#125; &#125;&#125; 选择排序原理每次从未排序的序列中找到最小值，记录并最后存放到已排序序列的末尾 性能时间复杂度为$O(N^2)$，空间复杂度为$O(1)$，排序是不稳定的（把最小值交换到已排序的末尾导致的），每次都能确定一个元素所在的最终位置，比较次数与初始序列无关。 代码1234567891011121314151617public static void selectSort(int[] arr)&#123; int len = arr.length; //每次从后边选择一个最小值 for (int i = 0; i &lt; len-1; i++)&#123; //只需选择n-1次 int min = i; for (int j = i+1; j &lt; len; j++)&#123; if (arr[min]&gt;arr[j])&#123; min = j; &#125; &#125; if (min != i)&#123; int temp = arr[i]; arr[i] = arr[min]; arr[min] = temp; &#125; &#125;&#125; 快速排序原理 分而治之思想： Divide：找到基准元素pivot，将数组A[p..r]划分为A[p..pivotpos-1]和A[pivotpos+1…q]，左边的元素都比基准小，右边的元素都比基准大; Conquer：对俩个划分的数组进行递归排序； Combine：因为基准的作用，使得俩个子数组就地有序，无需合并操作。 性能快排的平均时间复杂度为$O(NlogN）$，空间复杂度为$O(logN)$，但最坏情况下，时间复杂度为$O(N^2)$，空间复杂度为$O(N)$；且排序是不稳定的，但每次都能确定一个元素所在序列中的最终位置，复杂度与初始序列有关。 代码123456789101112131415161718192021222324252627public static void swap(int i, int j, int[] arr) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;&#125;public static void sortQuick(int[] quickArray) &#123; int[] arr = quickArray; quickSort(0, arr.length - 1, arr);&#125;public static void quickSort(int start, int end, int[] arr) &#123; if (start &lt; end) &#123; int pivot = arr[start]; int left = start; int right = end; while (left != right) &#123; while (arr[right] &gt;= pivot &amp;&amp; left &lt; right) right--; while (arr[left] &lt;= pivot &amp;&amp; left &lt; right) left++; swap(left, right, arr); &#125; arr[start] = arr[left]; arr[left] = pivot; quickSort(start, left - 1, arr); quickSort(left + 1, end, arr); &#125;&#125; 归并排序原理归并排序是采用分治法的一个非常典型的应用。归并排序的思想就是先递归分解数组，再合并数组。 先考虑合并两个有序数组，基本思路是比较两个数组的最前面的数，谁小就先取谁，取了后相应的指针就往后移一位。然后再比较，直至一个数组为空，最后把另一个数组的剩余部分复制过来即可。 再考虑递归分解，基本思路是将数组分解成left和right，如果这两个数组内部数据是有序的，那么就可以用上面合并数组的方法将这两个数组合并排序。如何让这两个数组内部是有序的？可以再二分，直至分解出的小组只含有一个元素时为止，此时认为该小组内部已有序。然后合并排序相邻二个小组即可。 性能时间复杂度总是为$O(NlogN)$，空间复杂度也总为为4O(N)$，算法与初始序列无关，排序是稳定的。 ###代码 12345678910111213141516171819202122232425262728293031323334353637383940414243public static void mergeSort(int[] arr)&#123; mergeSortDiv(arr,0,arr.length-1);&#125;public static int[] mergeSortDiv(int[] arr,int low,int high)&#123; int mid = (low + high) / 2; if (low &lt; high) &#123; // 左边 mergeSortDiv(arr, low, mid); // 右边 mergeSortDiv(arr, mid + 1, high); // 左右归并 merge(arr, low, mid, high); &#125; return arr;&#125;public static void merge(int[] nums, int low, int mid, int high)&#123; int[] temp = new int[high - low + 1]; int i = low;// 左指针 int j = mid + 1;// 右指针 int k = 0; // 把较小的数先移到新数组中 while (i &lt;= mid &amp;&amp; j &lt;= high) &#123; if (nums[i] &lt; nums[j]) &#123; temp[k++] = nums[i++]; &#125; else &#123; temp[k++] = nums[j++]; &#125; &#125; // 把左边剩余的数移入数组 while (i &lt;= mid) &#123; temp[k++] = nums[i++]; &#125; // 把右边边剩余的数移入数组 while (j &lt;= high) &#123; temp[k++] = nums[j++]; &#125; // 把新数组中的数覆盖nums数组 for (int k2 = 0; k2 &lt; temp.length; k2++) &#123; nums[k2 + low] = temp[k2]; &#125;&#125; 堆排序原理堆排序在 top K 问题中使用比较频繁。堆排序是采用二叉堆的数据结构来实现的，虽然实质上还是一维数组。二叉堆是一个近似完全二叉树 。 二叉堆具有以下性质： 父节点的键值总是大于或等于（小于或等于）任何一个子节点的键值。 每个节点的左右子树都是一个二叉堆（都是最大堆或最小堆）。 步骤： 构造最大堆（Build_Max_Heap）：若数组下标范围为0~n，考虑到单独一个元素是大根堆，则从下标n/2开始的元素均为大根堆。于是只要从n/2-1开始，向前依次构造大根堆，这样就能保证，构造到某个节点时，它的左右子树都已经是大根堆。 堆排序（HeapSort）：由于堆是用数组模拟的。得到一个大根堆后，数组内部并不是有序的。因此需要将堆化数组有序化。思想是移除根节点，并做最大堆调整的递归运算。第一次将heap[0]与heap[n-1]交换，再对heap[0…n-2]做最大堆调整。第二次将heap[0]与heap[n-2]交换，再对heap[0…n-3]做最大堆调整。重复该操作直至heap[0]和heap[1]交换。由于每次都是将最大的数并入到后面的有序区间，故操作完后整个数组就是有序的了。 最大堆调整（Max_Heapify）：该方法是提供给上述两个过程调用的。目的是将堆的末端子节点作调整，使得子节点永远小于父节点 。 性能时间复杂度为$O(NlogN)$，空间复杂度为$O(1)$，因为利用的排序空间仍然是初始的序列，并未开辟新空间。算法是不稳定的，与初始序列无关。 使用场景想知道最大值或最小值时，比如优先级队列，作业调度等场景。 代码排序算法之归并排序(JAVA)-数组形式 计数排序原理先把每个元素的出现次数算出来，然后算出该元素所在最终排好序列中的绝对位置(最终位置)，再依次把初始序列中的元素，根据该元素所在最终的绝对位置移到排序数组中。 性能时间复杂度为O(N+K)，空间复杂度为O(N+K)，算法是稳定的，与初始序列无关，不需要进行比较就能排好序的算法。 桶排序原理 根据待排序列元素的大小范围，均匀独立的划分M个桶 将N个输入元素分布到各个桶中去 再对各个桶中的元素进行排序 此时再按次序把各桶中的元素列出来即是已排序好的。 性能时间复杂度为$O(N+C)$，$O(C)=O(M(N/M)log(N/M))=O(NlogN-NlogM)$，空间复杂度为$O(N+M)$，算法是稳定的，且与初始序列无关。 使用场景算法思想和散列中的开散列法差不多，当冲突时放入同一个桶中；可应用于数据量分布比较均匀，或比较侧重于区间数量时。 基数排序原理对于有d个关键字时，可以分别按关键字进行排序。有俩种方法： MSD：先从高位开始进行排序，在每个关键字上，可采用计数排序 LSD：先从低位开始进行排序，在每个关键字上，可采用桶排序 性能时间复杂度为O(d*(N+K))，空间复杂度为O(N+K)。 总结 参考文献[1]经典排序算法总结与实现-基于Python的排序算法总结，写的很不错 [2]排序算法总结-带有优化]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>排序算法</tag>
        <tag>算法</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试整理-Java综合高级篇（吐血整理）]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2017-12-11-%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-Java%E9%9D%A2%E8%AF%95%E7%BB%8F%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[Java面试总结1.你用过哪些集合类？ 大公司最喜欢问的Java集合类面试题40个Java集合面试问题和答案java.util.Collections 是一个包装类。它包含有各种有关集合操作的静态多态方法。java.util.Collection 是一个集合接口。它提供了对集合对象进行基本操作的通用接口方法。 Collection├List│├LinkedList│├ArrayList│└Vector│ └Stack└SetMap├Hashtable├HashMap└WeakHashMap ArrayList、HashMap、TreeMap和HashTable类提供对元素的随机访问。 线程安全 VectorHashTable(不允许插空值) 非线程安全 ArrayListLinkedListHashMap(允许插入空值)HashSetTreeSetTreeMap(基于红黑树的Map实现) 2.你说说 arraylist 和 linkedlist 的区别？ ArrayList和LinkedList两者都实现了List接口，但是它们之间有些不同。（1）ArrayList是由Array所支持的基于一个索引的数据结构，所以它提供对元素的随机访问（2）与ArrayList相比，在LinkedList中插入、添加和删除一个元素会更快（3）LinkedList比ArrayList消耗更多的内存，因为LinkedList中的每个节点存储了前后节点的引用 3.HashMap 底层是怎么实现的？还有什么处理哈希冲突的方法？处理哈希冲突的方法: 解决HashMap一般没有什么特别好的方式，要不扩容重新hash要不优化冲突的链表结构 1.开放定地址法-线性探测法2.开放定地址法-平方探查法3.链表解决-可以用红黑树提高查找效率 HashMap简介HashMap 是一个散列表，它存储的内容是键值对(key-value)映射。HashMap 继承于AbstractMap，实现了Map、Cloneable、java.io.Serializable接口。HashMap 的实现不是同步的，这意味着它不是线程安全的,但可以用 Collections的synchronizedMap方法使HashMap具有线程安全的能力。它的key、value都可以为null。此外，HashMap中的映射不是有序的。HashMap 的实例有两个参数影响其性能：“初始容量” 和 “加载因子”。初始容量默认是16。默认加载因子是 0.75, 这是在时间和空间成本上寻求一种折衷。加载因子过高虽然减少了空间开销，但同时也增加了查询成本.HashMap是数组+链表+红黑树（JDK1.8增加了红黑树部分）实现的,当链表长度太长（默认超过8）时，链表就转换为红黑树. Java8系列之重新认识HashMap功能实现-方法 确定哈希桶数组索引位置 :这里的Hash算法本质上就是三步：取key的hashCode值、高位运算、取模运算。 1234567891011方法一：static final int hash(Object key) &#123; //jdk1.8 &amp; jdk1.7 int h; // h = key.hashCode() 为第一步 取hashCode值 // h ^ (h &gt;&gt;&gt; 16) 为第二步 高位参与运算 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;方法二：static int indexFor(int h, int length) &#123; //jdk1.7的源码，jdk1.8没有这个方法，但是实现原理一样的 return h &amp; (length-1); //第三步 取模运算&#125; 分析HashMap的put方法 扩容机制：原来的两倍 4.熟悉什么算法，还有说说他们的时间复杂度？ 经典排序算法总结与实现 5.ArrayList和Vector的底层代码和他们的增长策略,它们是如何进行扩容的？ ArrayList 默认数组大小是10，其中ensureCapacity扩容，trimToSize容量调整到适中，扩展后数组大小为（(原数组长度1.5）与传递参数中较大者.Vector的扩容，是可以指定扩容因子，同时Vector扩容策略是：1.原来容量的2倍,2.原来容量+扩容参数值。*详细内容可以配合阅读源码 6.jvm 原理。程序运行区域划分 问：Java运行时数据区域？回答：包括程序计数器、JVM栈、本地方法栈、方法区、堆问：方法区里存放什么？本地方法栈：和jvm栈所发挥的作用类似，区别是jvm栈为jvm执行java方法（字节码）服务，而本地方法栈为jvm使用的native方法服务。 JVM栈：局部变量表、操作数栈、动态链接、方法出口。 方法区：用于存储已被虚拟机加载的类信息，常量、静态变量、即时编译器编译后的代码等。 堆：存放对象实例。 7.minor GC 与 Full GC，分别什么时候会触发？ 。分别采用哪种垃圾回收算法？简单介绍算法 GC（或Minor GC）：收集 生命周期短的区域(Young area)。Full GC （或Major GC）：收集生命周期短的区域(Young area)和生命周期比较长的区域(Old area)对整个堆进行垃圾收集。新生代通常存活时间较短基于Copying算法进行回收,将可用内存分为大小相等的两块，每次只使用其中一块；当这一块用完了，就将还活着的对象复制到另一块上，然后把已使用过的内存清理掉。在HotSpot里，考虑到大部分对象存活时间很短将内存分为Eden和两块Survivor，默认比例为8:1:1。代价是存在部分内存空间浪费，适合在新生代使用；老年代与新生代不同，老年代对象存活的时间比较长、比较稳定，因此采用标记(Mark)算法来进行回收,所谓标记就是扫描出存活的对象，然后再进行回收未被标记的对象，回收后对用空出的空间要么进行合并、要么标记出来便于下次进行分配，总之目的就是要减少内存碎片带来的效率损耗。在执行机制上JVM提供了串行GC(Serial MSC)、并行GC(Parallel MSC)和并发GC(CMS)。 Minor GC ，Full GC 触发条件 Minor GC触发条件：当Eden区满时，触发Minor GC。 Full GC触发条件： （1）调用System.gc时，系统建议执行Full GC，但是不必然执行 （2）老年代空间不足 （3）方法去空间不足 （4）通过Minor GC后进入老年代的平均大小大于老年代的可用内存 （5）由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小 8.HashMap 实现原理 在java编程语言中，最基本的结构就是两种，一个是数组，另外一个是模拟指针（引用），所有的数据结构都可以用这两个基本结构来构造的，HashMap也不例外。HashMap实际上是一个“链表散列”的数据结构，即数组和链表的结合体。 9.java.util.concurrent 包下使用过哪些 1.阻塞队列 BlockingQueue( ArrayBlockingQueue, DelayQueue, LinkedBlockingQueue, SynchronousQueue,LinkedTransferQueue,LinkedBlockingDeque)2.ConcurrentHashMap3.Semaphore–信号量4.CountDownLatch–闭锁5.CyclicBarrier–栅栏6.Exchanger–交换机7.Executor-&gt;ThreadPoolExecutor,ScheduledThreadPoolExecutor 12345Semaphore semaphore = new Semaphore(1); //critical section semaphore.acquire(); ... semaphore.release(); 8.锁 Lock–ReentrantLock,ReadWriteLock,Condition,LockSupport 1234Lock lock = new ReentrantLock(); lock.lock(); //critical section lock.unlock(); 10.concurrentMap 和 HashMap 区别 1.hashMap可以有null的键，concurrentMap不可以有2.hashMap是线程不安全的，在多线程的时候需要Collections.synchronizedMap(hashMap),ConcurrentMap使用了重入锁保证线程安全。3.在删除元素时候，两者的算法不一样。ConcurrentHashMap和Hashtable主要区别就是围绕着锁的粒度以及如何锁,可以简单理解成把一个大的HashTable分解成多个，形成了锁分离。 11.信号量是什么，怎么使用?volatile关键字是什么？ 信号量-semaphore：荷兰著名的计算机科学家Dijkstra 于1965年提出的一个同步机制。是在多线程环境下使用的一种设施, 它负责协调各个线程, 以保证它们能够正确、合理的使用公共资源。整形信号量：表示共享资源状态，且只能由特殊的原子操作改变整型量。同步与互斥：同类进程为互斥关系（打印机问题），不同进程为同步关系(消费者生产者)。 使用volatile关键字是解决同步问题的一种有效手段。 java volatile关键字预示着这个变量始终是“存储进入了主存”。更精确的表述就是每一次读一个volatile变量，都会从主存读取，而不是CPU的缓存。同样的道理，每次写一个volatile变量，都是写回主存，而不仅仅是CPU的缓存。Java 保证volatile关键字保证变量的改变对各个线程是可见的。 12.阻塞队列了解吗？怎么使用 阻塞队列 (BlockingQueue)是Java util.concurrent包下重要的数据结构，BlockingQueue提供了线程安全的队列访问方式：当阻塞队列进行插入数据时，如果队列已满，线程将会阻塞等待直到队列非满；从阻塞队列取数据时，如果队列已空，线程将会阻塞等待直到队列非空。并发包下很多高级同步类的实现都是基于BlockingQueue实现的。 以ArrayBlockingQueue为例，我们先来看看代码： 123456789101112public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125; 从put方法的实现可以看出，它先获取了锁，并且获取的是可中断锁，然后判断当前元素个数是否等于数组的长度，如果相等，则调用notFull.await()进行等待，当被其他线程唤醒时，通过enqueue(e)方法插入元素，最后解锁。 12345678910111213/*** Inserts element at current put position, advances, and signals.* Call only when holding lock.*/private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; items[putIndex] = x; if (++putIndex == items.length) putIndex = 0; count++; notEmpty.signal();&#125; 插入成功后，通过notEmpty唤醒正在等待取元素的线程。 13.Java中的NIO，BIO，AIO分别是什么？ IO的方式通常分为几种，同步阻塞的BIO、同步非阻塞的NIO、异步非阻塞的AIO 1.BIO，同步阻塞式IO，简单理解：一个连接一个线程.BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。 在JDK1.4之前，用Java编写网络请求，都是建立一个ServerSocket，然后，客户端建立Socket时就会询问是否有线程可以处理，如果没有，要么等待，要么被拒绝。即：一个连接，要求Server对应一个处理线程。 2.NIO，同步非阻塞IO，简单理解：一个请求一个线程.NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。 NIO本身是基于事件驱动思想来完成的，其主要想解决的是BIO的大并发问题： 在使用同步I/O的网络应用中，如果要同时处理多个客户端请求，或是在客户端要同时和多个服务器进行通讯，就必须使用多线程来处理。也就是说，将每一个客户端请求分配给一个线程来单独处理。这样做虽然可以达到我们的要求，但同时又会带来另外一个问题。由于每创建一个线程，就要为这个线程分配一定的内存空间（也叫工作存储器），而且操作系统本身也对线程的总数有一定的限制。如果客户端的请求过多，服务端程序可能会因为不堪重负而拒绝客户端的请求，甚至服务器可能会因此而瘫痪。 3.AIO，异步非阻塞IO，简单理解：一个有效请求一个线程.AIO方式使用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。 14.类加载机制是怎样的 JVM中类的装载是由ClassLoader和它的子类来实现的,Java ClassLoader是一个重要的Java运行时系统组件。它负责在运行时查找和装入类文件的类。类加载的五个过程：加载、验证、准备、解析、初始化。 从类被加载到虚拟机内存中开始，到卸御出内存为止，它的整个生命周期分为7个阶段，加载(Loading)、验证(Verification)、准备(Preparation)、解析(Resolution)、初始化(Initialization)、使用(Using)、卸御(Unloading)。其中验证、准备、解析三个部分统称为连接。 15.什么是幂等性所谓幂等，简单地说，就是对接口的多次调用所产生的结果和调用一次是一致的。那么我们为什么需要接口具有幂等性呢？设想一下以下情形： 在App中下订单的时候，点击确认之后，没反应，就又点击了几次。在这种情况下，如果无法保证该接口的幂等性，那么将会出现重复下单问题。 在接收消息的时候，消息推送重复。如果处理消息的接口无法保证幂等，那么重复消费消息产生的影响可能会非常大。 16.有哪些 JVM 调优经验 Jvm参数总结：http://linfengying.com/?p=2470 内存参数 参数 作用 -Xmx 堆大小的最大值。当前主流虚拟机的堆都是可扩展的 -Xms 堆大小的最小值。可以设置成和 -Xmx 一样的值 -Xmn 新生代的大小。现代虚拟机都是“分代”的，因此堆空间由新生代和老年代组成。新生代增大，相应地老年代就减小。Sun官方推荐新生代占整个堆的3/8 -Xss 每个线程的堆栈大小。该值影响一台机器能够创建的线程数上限 -XX:MaxPermSize= 永久代的最大值。永久代是 HotSpot 特有的，HotSpot 用永久代来实现方法区 -XX:PermSize= 永久代的最小值。可以设置成和 -XX:MaxPermSize 一样的值 -XX:SurvivorRatio= Eden 和 Survivor 的比值。基于“复制”的垃圾收集器又会把新生代分为一个 Eden 和两个 Survivor，如果该参数为8，就表示 Eden 占新生代的80%，而两个 Survivor 各占10%。默认值为8 -XX:PretenureSizeThreshold= 直接晋升到老年代的对象大小。大于这个参数的对象将直接在老年代分配。默认值为0，表示不启用 -XX:HandlePromotionFailure= 是否允许分配担保失败。在 JDK 6 Update 24 后该参数已经失效。 -XX:MaxTenuringThreshold= 对象晋升到老年代的年龄。对象每经过一次 Minor GC 后年龄就加1，超过这个值时就进入老年代。默认值为15 -XX:MaxDirectMemorySize= 直接内存的最大值。对于频繁使用 nio 的应用，应该显式设置该参数，默认值为0 GC参数 垃圾收集器 参数 备注 Serial（新生代） -XX:+UseSerialGC 虚拟机在 Client 模式下的默认值，打开此开关后，使用 Serial + Serial Old 的收集器组合。Serial 是一个单线程的收集器 ParNew（新生代） -XX:+UseParNewGC 强制使用 ParNew，打开此开关后，使用 ParNew + Serial Old 的收集器组合。ParNew 是一个多线程的收集器，也是 server 模式下首选的新生代收集器 -XX:ParallelGCThreads= 垃圾收集的线程数 Parallel Scavenge（新生代） -XX:+UseParallelGC 虚拟机在 Server 模式下的默认值，打开此开关后，使用 Parallel Scavenge + Serial Old 的收集器组合 -XX:MaxGCPauseMillis= 单位毫秒，收集器尽可能保证单次内存回收停顿的时间不超过这个值。 -XX:GCTimeRatio= 总的用于 gc 的时间占应用程序的百分比，该参数用于控制程序的吞吐量 -XX:+UseAdaptiveSizePolicy 设置了这个参数后，就不再需要指定新生代的大小（-Xmn）、 Eden 和 Survisor 的比例（-XX:SurvivorRatio）以及晋升老年代对象的年龄（-XX:PretenureSizeThreshold）了，因为该收集器会根据当前系统的运行情况自动调整。当然前提是先设置好前两个参数。 Serial Old（老年代） 无 Serial Old 是 Serial 的老年代版本，主要用于 Client 模式下的老生代收集，同时也是 CMS 在发生 Concurrent Mode Failure 时的后备方案 Parallel Old（老年代） -XX:+UseParallelOldGC 打开此开关后，使用 Parallel Scavenge + Parallel Old 的收集器组合。Parallel Old 是 Parallel Scavenge 的老年代版本，在注重吞吐量和 CPU 资源敏感的场合，可以优先考虑这个组合 CMS（老年代） -XX:+UseConcMarkSweepGC 打开此开关后，使用 ParNew + CMS 的收集器组合。 -XX:CMSInitiatingOccupancyFraction= CMS 收集器在老年代空间被使用多少后触发垃圾收集 -XX:+UseCMSCompactAtFullCollection 在完成垃圾收集后是否要进行一次内存碎片整理 -XX:CMSFullGCsBeforeCompaction= 在进行若干次垃圾收集后才进行一次内存碎片整理 附图：可以配合使用的收集器组合 上面有7中收集器，分为两块，上面为新生代收集器，下面是老年代收集器。如果两个收集器之间存在连线，就说明它们可以搭配使用。 其他参数 参数 作用 -verbose:class 打印类加载过程 -XX:+PrintGCDetails 发生垃圾收集时打印 gc 日志，该参数会自动带上 -verbose:gc 和 -XX:+PrintGC -XX:+PrintGCDateStamps / -XX:+PrintGCTimeStamps 打印 gc 的触发事件，可以和 -XX:+PrintGC 和 -XX:+PrintGCDetails 混用 -Xloggc: gc 日志路径 -XX:+HeapDumpOnOutOfMemoryError 出现 OOM 时 dump 出内存快照用于事后分析 -XX:HeapDumpPath= 堆转储快照的文件路径 17.分布式 CAP 了解吗？ 一致性(Consistency)可用性(Availability)分区容忍性(Partition tolerance) 18.Java中HashMap的key值要是为类对象则该类需要满足什么条件？需要同时重写该类的hashCode()方法和它的equals()方法。 当程序试图将一个 key-value 对放入 HashMap 中时，程序首先根据该 key 的 hashCode() 返回值决定该 Entry 的存储位置：如果两个 Entry 的 key 的 hashCode() 返回值相同，那它们的存储位置相同。如果这两个 Entry 的 key 通过 equals 比较返回 true，新添加 Entry 的 value 将覆盖集合中原有 Entry 的 value，但 key 不会覆盖。如果这两个 Entry 的 key 通过 equals 比较返回 false，新添加的 Entry 将与集合中原有 Entry 形成 Entry 链，而且新添加的 Entry 位于 Entry 链的头部——具体说明继续看 addEntry() 方法的说明。 19.java 垃圾回收会出现不可回收的对象吗？怎么解决内存泄露问题？怎么定位问题源？一般不会有不可回收的对象，因为现在的GC会回收不可达内存。 20.终止线程有几种方式？终止线程标记变量为什么是 valotile 类型？ 1.线程正常执行完毕，正常结束2.监视某些条件，结束线程的不间断运行3.使用interrupt方法终止线程 在定义exit时，使用了一个Java关键字volatile，这个关键字的目的是使exit同步，也就是说在同一时刻只能由一个线程来修改exit的值 21.用过哪些并发的数据结构？ cyclicBarrier 什么功能？信号量作用？数据库读写阻塞怎么解决 主要有锁机制，然后基于CAS的concurrent包。 CyclicBarrier的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续干活。CyclicBarrier默认的构造方法是CyclicBarrier(int parties)，其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。CountDownLatch的计数器只能使用一次。而CyclicBarrier的计数器可以使用reset() 方法重置。 Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。很多年以来，我都觉得从字面上很难理解Semaphore所表达的含义，只能把它比作是控制流量的红绿灯，比如XX马路要限制流量，只允许同时有一百辆车在这条路上行使，其他的都必须在路口等待，所以前一百辆车会看到绿灯，可以开进这条马路，后面的车会看到红灯，不能驶入XX马路，但是如果前一百辆中有五辆车已经离开了XX马路，那么后面就允许有5辆车驶入马路，这个例子里说的车就是线程，驶入马路就表示线程在执行，离开马路就表示线程执行完成，看见红灯就表示线程被阻塞，不能执行。 22.关于抽象类和接口的关系 简言之抽象类是一种功能不全的类，接口只是一个抽象方法声明和静态不能被修改的数据的集合，两者都不能被实例化。从某种意义上说，接口是一种特殊形式的抽象类，在java语言中抽象类表示的是一种继承关系，一个类只能继承继承一个抽象类，而一个类却可以实现多个接口。在许多情况下，接口确实可以代替抽象类，如果你不需要刻意表达属性上的继承的话。 23.堆内存和栈内存的区别 寄存器：JVM内部虚拟寄存器，存取速度非常快，程序不可控制。栈：保存局部变量的值包括：1.保存基本数据类型的值；2.保存引用变量，即堆区对象的引用(指针)。也可以用来保存加载方法时的帧。堆：用来存放动态产生的数据，比如new出来的对象。注意创建出来的对象只包含属于各自的成员变量，并不包括成员方法。因为同一个类的对象拥有各自的成员变量，存储在各自的堆中，但是他们共享该类的方法，并不是每创建一个对象就把成员方法复制一次。常量池：JVM为每个已加载的类型维护一个常量池，常量池就是这个类型用到的常量的一个有序集合。包括直接常量(基本类型，String)和对其他类型、方法、字段的符号引用(1)。池中的数据和数组一样通过索引访问。由于常量池包含了一个类型所有的对其他类型、方法、字段的符号引用，所以常量池在Java的动态链接中起了核心作用。常量池存在于堆中。代码段：用来存放从硬盘上读取的源程序代码。数据段：用来存放static修饰的静态成员（在java中static的作用就是说明该变量，方法，代码块是属于类的还是属于实例的）。 24.关于Java文件的内部类的解释？匿名内部类是什么？如何访问在其外面定义的变量？ java中的内部类总结静态内部类不能访问外部类非静态的成员 ###25.关于重载和重写的区别重载是overload，是一个类中同方法名的不同具体实现。然后重写是override，是子类重写父类中的方法。 26.String、StringBuffer与StringBuilder之间区别 1.三者在执行速度方面的比较：StringBuilder &gt; StringBuffer &gt; String String：字符串常量StringBuffer：字符串变量StringBuilder：字符串变量 2.StringBuilder：线程非安全的,StringBuffer：线程安全的对于三者使用的总结： 1.如果要操作少量的数据用 = String2.单线程操作字符串缓冲区 下操作大量数据 = StringBuilder3.多线程操作字符串缓冲区 下操作大量数据 = StringBuffer 27.运行时异常与一般异常有何异同？常见异常 Java提供了两类主要的异常:runtime exception和checked exception常见异常：NullPointerException、IndexOutOfBoundsException、ClassNotFoundException，IllegalArgumentException，ClassCastException(数据类型转换异常) ###28.error和exception有什么区别? error 表示恢复不是不可能但很困难的情况下的一种严重问题。比如说内存溢出。不可能指望程序能处理这样的情况。exception表示一种设计或实现问题。也就是说，它表示如果程序运行正常，从不会发生的情况。 ###29.Java异常处理机制 1.捕获异常：try、catch 和 finally2.抛出异常2.1. throws抛出异常 12methodname throws Exception1,Exception2,..,ExceptionN &#123; &#125; 30.java中有几种方法可以实现一个线程? Java多线程学习（吐血超详细总结）40个Java多线程问题总结 1.class Thread1 extends Thread{},然后重写run方法2.class Thread2 implements Runnable{},然后重写run方法3.class Thread3 implements Callable{},然后new FutureTask(thread3),再用new Thread(future)封装。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475class Thread1 extends Thread &#123; private String name; public Thread1(String name) &#123; this.name = name; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(name + "运行---&gt;&gt;&gt;" + i); &#125; &#125; public static void main(String[] args) &#123; Thread1 mTh11=new Thread1("A"); Thread1 mTh12=new Thread1("B"); mTh1.start(); mTh2.start(); &#125;&#125;class Thread2 implements Runnable &#123; private String name; private int count = 15; public Thread2() &#123; &#125; public Thread2(String name) &#123; this.name = name; &#125; public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(Thread.currentThread().getName() + "运行 : " + count--); &#125; &#125; public static void main(String[] args) &#123; Thread2 mTh2 = new Thread2(); new Thread(mTh2, "C").start(); new Thread(mTh2, "D").start(); &#125;&#125;class MyCallableThread implements Callable&lt;Integer&gt;&#123; public Integer call() throws Exception &#123; int i = 0; for(;i&lt;100;i++) &#123; System.out.println(Thread.currentThread().getName()+" "+i); &#125; return i; &#125; public static void main(String[] args) &#123; MyCallableThread mct = new MyCallableThread(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;Integer&gt;(mct); for(int i = 0;i &lt; 100;i++) &#123; System.out.println(Thread.currentThread().getName()+" 的循环变量i的值"+i); if(i==20) &#123; new Thread(ft,"有返回值的线程").start(); &#125; &#125; try &#123; System.out.println("子线程的返回值："+ft.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 如果一个类继承Thread，则不适合资源共享。但是如果实现了Runable接口的话，则很容易的实现资源共享。 31.Java中常用的类，包，接口。 class: ‘Date’,’System’,’Calender’,’Math’,’ArrayList’,’HashMap’package: ‘java.lang’,’java.util’,’java.io’,’java.sql’,’java.net’interface: ‘Collection’,’Map’,’List’,’Runnable’,’Callable’ 32.java在处理线程同步时，常用方法有： 1、synchronized关键字。2、Lock显示加锁。3、信号量Semaphore。4、CAS算法5、concurrent包 33.Spring IOC/AOP？ 回答了IOC/DI、AOP的概念。AOP（Aspect-OrientedProgramming，面向方面编程），可以说是OOP（Object-Oriented Programing，面向对象编程）的补充和完善。OOP引入封装、继承和多态性等概念来建立一种对象层次结构，用以模拟公共行为的一个集合。当我们需要为分散的对象引入公共行为的时候，OOP则显得无能为力。也就是说，OOP允许你定义从上到下的关系，但并不适合定义从左到右的关系。例如日志功能。日志代码往往水平地散布在所有对象层次中，而与它所散布到的对象的核心功能毫无关系。对于其他类型的代码，如安全性、异常处理和透明的持续性也是如此。这种散布在各处的无关的代码被称为横切（cross-cutting）代码，在OOP设计中，它导致了大量代码的重复，而不利于各个模块的重用。依赖注入(Dependency Injection)和控制反转(Inversion of Control)是同一个概念。当某个角色(可能是一个Java实例，调用者)需要另一个角色(另一个Java实例，被调用者)的协助时，在传统的程序设计过程中，通常由调用者来创建被调用者的实例。但在Spring里，创建被调用者的工作不再由调用者来完成，因此称为控制反转;创建被调用者 实例的工作通常由Spring容器来完成，然后注入调用者，因此也称为依赖注入。不管是依赖注入，还是控制反转，都说明Spring采用动态、灵活的方式来管理各种对象。对象与对象之间的具体实现互相透明。在理解依赖注入之前，看如下这个问题在各种社会形态里如何解决:一个人(Java实例，调用者)需要一把斧子(Java实例，被调用者)。 34.对JVM的垃圾回收的认识? 垃圾回收器的作用是查找和回收（清理）无用的对象。以便让JVM更有效的使用内存。 35.进程与线程的区别，及其通信方式 线程与进程的区别及其通信方式区别1.一个程序至少有一个进程,一个进程至少有一个线程.2.进程在执行过程中拥有独立的内存单元，而多个线程共享内存3.线程是进程的一个实体,是CPU调度和分派的基本单位 进程间通信 1234561.管道（Pipe）及有名管道（named pipe）2.信号（Signal）3.消息队列（Message）4.共享内存5.信号量（semaphore）6.套接口（Socket） 36.JVM如何GC，新生代，老年代，持久代，都存储哪些东西？JVM的GC算法有：引用计数器算法，根搜索方法 新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。 在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 持久代主要存放的是Java类的类信息 37.JVM分为哪些区，每一个区干嘛的？问：Java运行时数据区域？ 回答：包括程序计数器、JVM栈、本地方法栈、方法区、堆 问：方法区里存放什么？ 本地方法栈：和jvm栈所发挥的作用类似，区别是jvm栈为jvm执行java方法（字节码）服务，而本地方法栈为jvm使用的native方法服务。 JVM栈：局部变量表、操作数栈、动态链接、方法出口。 方法区：用于存储已被虚拟机加载的类信息，常量、静态变量、即时编译器编译后的代码等。 堆：存放对象实例。 38.GC用的引用可达性分析算法中，哪些对象可作为GC Roots对象？ 虚拟机栈（栈帧中的本地变量表）中引用的对象； 方法区中类静态属性引用的对象； 方法区中常量引用的对象； 本地方法栈中JNI（即一般说的Native方法）引用的对象 39.用什么工具调试程序？jmap、jstack,JConsole，用过吗？虚拟机性能监控与调优实战–博客 40.线程池用过吗？ 线程池–并发编程网 - ifeve.com 线程池（Thread Pool）对于限制应用程序中同一时刻运行的线程数很有用。因为每启动一个新线程都会有相应的性能开销，每个线程都需要给栈分配一些内存等等。 我们可以把并发执行的任务传递给一个线程池，来替代为每个并发执行的任务都启动一个新的线程。只要池里有空闲的线程，任务就会分配给一个线程执行。在线程池的内部，任务被插入一个阻塞队列（Blocking Queue ），线程池里的线程会去取这个队列里的任务。当一个新任务插入队列时，一个空闲线程就会成功的从队列中取出任务并且执行它。 41.操作系统如何进行分页调度？–要考LRU 1.最讲置换原则-OPT2.先进先出原则-FIFO3.最近最少使用置换算法-LRU4.时钟置换算法 12345678910111213141516171819//扩展一下LinkedHashMap这个类，让他实现LRU算法class LRULinkedHashMap&lt;K,V&gt; extends LinkedHashMap&lt;K,V&gt;&#123; //定义缓存的容量 private int capacity; private static final long serialVersionUID = 1L; //带参数的构造器 LRULinkedHashMap(int capacity)&#123; //调用LinkedHashMap的构造器，传入以下参数 super(16,0.75f,true); //传入指定的缓存最大容量 this.capacity=capacity; &#125; //实现LRU的关键方法，如果map里面的元素个数大于了缓存最大容量，则删除链表的顶端元素 @Override public boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest)&#123; System.out.println(eldest.getKey() + "=" + eldest.getValue()); return size()&gt;capacity; &#125;&#125; 42.讲讲LinkedHashMap Java8 LinkedHashMap工作原理及实现 LinkedHashMap是通过哈希表和链表实现的，它通过维护一个链表来保证对哈希表迭代时的有序性，而这个有序是指键值对插入的顺序。 LinkedHashMap 的大致实现如下图所示，当然链表和哈希表中相同的键值对都是指向同一个对象，这里把它们分开来画只是为了呈现出比较清晰的结构。 LinkedHashMap是Hash表和链表的实现，并且依靠着双向链表保证了迭代顺序是插入的顺序。 三个重点实现的函数 在HashMap中提到了下面的定义： 1234567// Callbacks to allow LinkedHashMap post-actions//1.把当前节点e移至链表的尾部。因为使用的是双向链表，所以在尾部插入可以以O（1）的时间复杂度来完成。并且只有当accessOrder设置为true时，才会执行这个操作。在HashMap的putVal方法中，就调用了这个方法。void afterNodeAccess(Node&lt;K,V&gt; p) &#123; &#125;//2.afterNodeInsertion方法是在哈希表中插入了一个新节点时调用的，它会把链表的头节点删除掉，删除的方式是通过调用HashMap的removeNode方法。通过afterNodeInsertion方法和afterNodeAccess方法，是不是就可以简单的实现一个基于最近最少使用（LRU）的淘汰策略了？当然，我们还要重写removeEldestEntry方法，因为它默认返回的是false。void afterNodeInsertion(boolean evict) &#123; &#125;//3.这个方法是当HashMap删除一个键值对时调用的，它会把在HashMap中删除的那个键值对一并从链表中删除，保证了哈希表和链表的一致性。void afterNodeRemoval(Node&lt;K,V&gt; p) &#123; &#125; LinkedHashMap继承于HashMap，因此也重新实现了这3个函数，顾名思义这三个函数的作用分别是：节点访问后、节点插入后、节点移除后做一些事情。 43.线程同步与阻塞的关系？同步一定阻塞吗？阻塞一定同步吗？,同步和异步有什么区别？ 同步与非同步：主要是保证互斥的访问临界资源的情况阻塞与非阻塞：主要是从 CPU 的消耗上来说的 44.int与Integer的区别，分别什么场合使用12341、Integer是int提供的封装类，而int是Java的基本数据类型2、Integer默认值是null，而int默认值是0；3、声明为Integer的变量需要实例化，而声明为int的变量不需要实例化；4、Integer是对象，用一个引用指向这个对象，而int是基本类型，直接存储数值。 int是基本数据类型，Integer是包装类，类似HashMap这样的结构必须使用包装类，因为包装类继承自Object,都需要实现HashCode，所以可以使用在HashMap这类数据结构中。 45.RPC的详细过程 RPC主要的重点有：动态代理,主要是invoke反射原理序列化,使用Thrift的效率高通信方式,使用Netty的NIO能提高效率服务发现,使用zookeeper可以实现 1）服务消费方（client）调用以本地调用方式调用服务； 2）client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体； 3）client stub找到服务地址，并将消息发送到服务端； 4）server stub收到消息后进行解码； 5）server stub根据解码结果调用本地的服务； 6）本地服务执行并将结果返回给server stub； 7）server stub将返回结果打包成消息并发送至消费方； 8）client stub接收到消息，并进行解码； 9）服务消费方得到最终结果。 交流或更多内容请关注我的公众号：nezha_blog 我的技术博客：https://nezha.github.io]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>面试经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos上搭建私有Git仓库]]></title>
    <url>%2Fweb%E5%BC%80%E5%8F%91%2F2017-12-05-Centos%E4%B8%8A%E6%90%AD%E5%BB%BA%E7%A7%81%E6%9C%89Git%E4%BB%93%E5%BA%93%2F</url>
    <content type="text"><![CDATA[由于GitHub是公开代码的，很多企业或项目刚开始的时候都是需要保密，于是自己可以搭建一个Git私有仓库，整个过程很简单。 个人博客：https://nezha.github.io 1. 安装Git12$ yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-devel$ yum install git 接下来我们 创建一个git用户组和用户，用来运行git服务： 123$ groupadd git$ adduser git -g git #添加git用户，名称可以自己设置，不一定要用git$ passwd git #修改git用户的密码 这里git的密码是用于客户端git上传下载身份验证要的，如果需要用密钥登录可以用下面的的方式 2. 创建证书登录 注意我们这里代码仓库是放在了/home/git/目录下，用于存放验证密钥的.ssh/也要存在/home/git/。 收集所有需要登录的用户的公钥，公钥位于id_rsa.pub文件中，把我们的公钥导入到/home/git/.ssh/authorized_keys文件里，一行一个。如果没有该文件创建它： 123456789$ cd /home$ mkdir git$ chown git:git git/$ cd /home/git/$ mkdir .ssh$ chmod 700 .ssh$ touch .ssh/authorized_keys$ chmod 600 .ssh/authorized_keys$ chown -R git:git /home/git/.ssh #设置目录和目录下的authorized_keys文件的拥有者和群组 关于怎么在客户端生成公钥 1ssh-keygen -t RSA -C "git" #使用RSA加密，密钥备注 3. 初始化Git仓库首先我们选定一个目录作为Git仓库，假定是/home/git/project.git，在/home/git目录下输入命令： 123$ cd /home/git/$ git init --bare project.gitInitialized empty Git repository in /home/gitrepo/runoob.git/ 以上命令Git创建一个空仓库，服务器上的Git仓库通常都以.git结尾。然后，把仓库所属用户改为git： 1$ chown -R git:git project.git 4. 本地克隆仓库1234$ git clone git@xxx.168.45.4:/home/git/project.gitCloning into 'project'...warning: You appear to have cloned an empty repository.Checking connectivity... done. 5. 关闭git用户的ssh shell登陆(Remote)123456$ vim /etc/passwd$ git:x:1001:1001::/home/git:/usr/bin/git-shell #找到git用户，在最后添加#这时候就不能通过shell使用git账号登陆fatal: Interactive git shell is not enabled.hint: ~/git-shell-commands should exist and have read and execute access.Connection to 54.13.87.93 closed. 参考文献：菜鸟笔记-Git 服务器搭建 — 菜鸟笔记没有给Git仓库更改所属用户，问题不大简书-蛋西的：搭建私有git服务]]></content>
      <categories>
        <category>web开发</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>私有仓库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[【转】JAVA对象在JVM中内存分配]]></title>
    <url>%2FJava%2F2017-06-17-%E3%80%90%E8%BD%AC%E3%80%91JAVA%E5%AF%B9%E8%B1%A1%E5%9C%A8JVM%E4%B8%AD%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%2F</url>
    <content type="text"><![CDATA[运行时数据区下图是Java的运行时数据区的划分图，但是从图中直观的很难看出具体在程序中各个变量的存放地址。于是本文主要就是整理这部分的内容，主要的参考文献是：http://www.jianshu.com/p/2f295b9f4cd4 实例分析以一下代码为例，来分析下，java的实例对象在内存中的空间分配（JDK1.8）。 123456789101112131415161718192021public class Student &#123; private String name; private static Birthday birthday = new Birthday(); public Student(String name) &#123; this.name = name; &#125; public static void main(String[] args) &#123; Student s = new Student("zhangsan"); int age = 10; System.out.println(age); &#125;&#125;class Birthday &#123; private int year = 2010; private int month = 10; private int day = 1;&#125; 以Student类执行到main方法的最后一行时来分析java实例对象在内存中的分配情况。如下图： 从图中我们可以看出，普通的java实例对象内存分配，主要在这三个区域：虚拟机栈、堆、方法区。 从内存区域来分析 虚拟机栈: 只存放局部变量 堆: 存储对象的实例 方法区： 存放Class信息和常量信息。 从变量的角度来分析 局部变量：存放在虚拟机栈中（具体应为[栈-&gt;栈帧-&gt;局部变量表]） 基本类型的值直接存在栈中。如age=10 如果是对象的实例，则只存储对象实例的引用。如s=ref 实例变量：存放在堆中的对象实例中。如Student的实例变量 name=ref 静态变量：存放在方法区中的常量池中。如Student.class中的birthday=ref。 如果常量的类型是对象的实例则只存储对象实例的引用地址 通过变量的角度来分析，我们就可以了解为什么静态变量不用new就能调用，而实例变量必须new出对象，才能调用。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>内存模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《深入理解Java虚拟机》读书笔记]]></title>
    <url>%2FJava%2F2017-06-17-%E3%80%8A%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[前言 自己在阅读《深入理解Java虚拟机》后做了部分的整理，内容有些是来自网络，如有侵权，请联系邮箱：&#110;&#101;&#122;&#x68;&#x61;&#x78;&#x69;&#x61;&#111;&#122;&#x69;&#64;&#x71;&#113;&#x2e;&#99;&#111;&#x6d; 本书第一次阅读，所以并没有全篇通读，主要的阅读的章节是 第2章 Java内存区域与内存溢出异常 第3章 Java垃圾回收机器与内存分配策略 第4章 JVM性能监控与故障处理工具 第7章 虚拟机类加载机制 总之此书很值得一读，不管是理解JVM内存模型或者GC的机制及怎么去JVM调优这本书上写的还是挺全面的。 第2章 Java内存区域与内存溢出异常概述对于Java程序员来说，在虚拟机自动内存管理机制下，不需要为new操作去写配对的delete/free代码，不容易出现内存泄漏。但是如果出现内存泄漏问题，如果不了解虚拟机的机制，便难以定位。 运行时数据区域下图是Java运行时数据区域划分图 区域 是否线程共享 是否会内存溢出 程序计数器 否 不会 java虚拟机栈 否 会 本地方法栈 否 会 堆 是 会 方法区 是 会 1.程序计数器(线程私有) 一块较小的内存，可以看作是当前线程所执行的字节码的行号指示器； 在虚拟机概念模型（各种虚拟机实现可能不一样）中，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令； 程序计数器是属于线程私有的内存； 如果执行的是Java方法，该计数器记录的是正在执行的虚拟机字节码指令的地址；如果是Native方法则为空； 2.Java虚拟机栈（线程私有） Java虚拟机栈也是线程私有的； 描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程； 局部变量表存放了编译器可知的各种基本数据类型、对象引用和returnAddress类型；其所需的内存空间在编辑期完成分配，不会再运行期改变； 可能存在两种异常：StackOverflowError(请求栈深度过大)和OutOfMemoryError（内存不够时）； 3.本地方法栈 与虚拟机栈非常相似，只不过是为虚拟机使用到的Native方法服务； 可能存在两种异常：StackOverflowError和OutOfMemoryError； 4.Java堆（线程共享） Java堆是被所有线程共享的，在虚拟机启动时创建； 此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这分配； 是垃圾收集器管理的主要区域，可以分为新生代和老年代； 可以物理不连续，只要逻辑上是连续的即可； 如果堆中没有内存完成实例分配也无法再扩展时，会抛出OutOfMemoryError异常； Eden:From Survivor:To Survivor比值为8：1：1 5.方法区/元空间（永久代）（线程共享） 是线程共享的区域； 用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据； 该区域对于垃圾收集来说条件比较苛刻，但是还是非常有必要要进行回收处理； 当无法满足内存分配需求时，将抛出OutOfMemoryError异常； 6.运行时常量池 是方法区的一部分； Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池，用于存放编译器生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放； Java虚拟机规范要求较少，通常还会把翻译出来的直接引用也存储在此； 另外一个重要特征是具备动态性，可以在运行期间将新的常量放入池中，如String的intern方法； 可能存在的异常：OutOfMemoryError； 7.直接内存 并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域； JDK 1.4的NIO引入了基于通道（Channel）和缓冲区（Buffer）的IO方法，可以使用Native函数库直接分配对外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作以提升性能； 对象的访问定位 栈上的reference类型在虚拟机规范中只规定了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆栈对象的具体位置，目前主流的方式方式有句柄和直接指针两种。 通过句柄：Java堆中划出一块内存作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。其最大好处就是reference存储的是稳定的句柄地址，在对象被移动（垃圾收集时移到）只改变实例数据指针，而reference不需要修改； 通过直接指针：Java堆对象的布局中必须考虑如果放置访问类型数据的相关信息，而reference中存在的直接就是对象地址。其最大好处在于速度更快，节省了一次指针定位的时机开销。HotSpot采用该方式进行对象访问，但其他语言和框架采用句柄的也非常常见。 内存参数的调节见这边JAVA对象在JVM中内存分配第3章 Java垃圾回收机器与内存分配策略概述思考GC需要完成的3件事情： 1.哪些内存需要回收？ 2.什么时候回收？ 3.如何回收？ 再回头看看第二章介绍的Java内存运行时区域的各个部分： 程序计时器、虚拟机栈、本地方法栈：随线程而灭，栈帧随方法而进行出栈和入栈，每一个栈帧分配的内存在类结构确定就已知，因此这几个区域不需要考虑回收； 对于Java堆和方法区，只有程序运行期间才知道会创建哪些对象，内存的分配和回收都是动态的，垃圾收集器所关注的是这部分内存； 判断Java中对象存活的算法1.引用计数算法给对象添加引用计数器，当有地方引用它时就加1，引用失效就减1，为0时就认为对象不再被使用可回收。该算法失效简单，判断高效，但并不被主流虚拟机采用，主要原因是它很难解决对象之间相互循环引用的问题。 2.可达性分析算法通过一系列的称为“GC Roots”的对象作为起点，从这些节点开始向下搜索，搜索所走过的路径称为引用链（Reference Chain），如果一个对象到GC Roots没有引用链相连，则该对象是不可用的。 在Java语言中，可作为GC Roots的对象包括： 虚拟机栈（栈帧中的本地变量表）中引用的对象； 方法区中类静态属性引用的对象； 方法区中常量引用的对象； 本地方法栈中JNI（即一般说的Native方法）引用的对象； 垃圾收集算法 1.标记-清除算法(Mark-Sweep)：首先标记出所有需要回收的对象，然后统一回收所有被标记的对象；缺点是效率不高且容易产生大量不连续的内存碎片； 复制算法：将可用内存分为大小相等的两块，每次只使用其中一块；当这一块用完了，就将还活着的对象复制到另一块上，然后把已使用过的内存清理掉。在HotSpot里，考虑到大部分对象存活时间很短将内存分为Eden和两块Survivor，默认比例为8:1:1。代价是存在部分内存空间浪费，适合在新生代使用； 标记-整理算法：首先标记出所有需要回收的对象，然后让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。适用于老年代。 分代收集算法：一般把Java堆分新生代和老年代，在新生代用复制算法，在老年代用标记-清理或标记-整理算法，是现代虚拟机通常采用的算法。 垃圾收集器 垃圾收集算法是内存回收的方法论，垃圾收集器就是内存回收的具体实现。 这里讨论JDK 1.7 Update 14之后的HotSpot虚拟机（此时G1仍处于实验状态），包含的虚拟机如下图所示（存在连线的表示可以搭配使用）： 1.Serial收集器（单线程的收集器） 最基本、发展历史最悠久，在JDK 1.3之前是新生代收集的唯一选择； 是一个单线程（并非指一个收集线程，而是会暂停所有工作线程）的收集器，采用的是复制算法; 现在依然是虚拟机运行在Client模式下的默认新生代收集器，主要就是因为它简单而高效（没有线程交互的开销）； 2.ParNew收集器（Serial收集器的多线程版本） 其实就是Serial收集器的多线程版本； ParNew收集器在单CPU环境中绝对不会有比Serial收集器更好的效果； 是许多运行在Server模式下虚拟机首选的新生代收集器，重要原因就是除了Serial收集器外，只有它能与CMS收集器配合工作； 并行（Parallel）：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态； 并发（Concurrent）：指用户线程与垃圾收集线程同时执行，用户线程在继续执行而垃圾收集程序运行在另外一个CPU上； 3.Parallel Scavenge收集器 吞吐量=运行用户代码时间/(运行用户代码时间+垃圾收集时间) 新生代收集器，使用复制算法，并行的多线程收集器； 与CMS关注于尽可能缩短垃圾收集时用户线程停顿时间不同，PS的目标是达到一个可控制的吞吐量； 高吞吐量可以高效率利用CPU时间，适合在后台运算而不需要太多交互的任务； -XX:MaxGCPauseMillis参数可以设置最大停顿时间，而停顿时间缩短是以牺牲吞吐量和新生代空间来换取的； 另外它还支持GC自适应的调节策略； 4.Serial Old收集器 是Serial收集器的老年代版本，同样是单线程，使用标记-整理算法； 主要是给Client模式下的虚拟机使用的； 在Server模式下主要是给JDK 1.5及之前配合Parallel Scavenge使用或作为CMS收集器的后备预案； 5.Parallel Old收集器 是Parallel Scavenge的老年代版本，使用多线程和标记-整理算法； 6.CMS收集器 是一种以获取最短回收停顿时间为目标的收集器，特别适合互联网站或者B/S的服务端； 它是基于标记-清除 算法实现的，主要包括4个步骤：初始标记（STW-stop the world，只是初始标记一下GC Roots能直接关联到的对象，速度很快）、并发标记（非STW，执行GC RootsTracing，耗时比较长）、重新标记（STW，修正并发标记期间因用户程序继续导致变动的那一部分对象标记）和并发清除（非STW，耗时较长）； 还有3个明显的缺点：CMS收集器对CPU非常敏感（占用部分线程及CPU资源，影响总吞吐量）、无法处理浮动垃圾（默认达到92%就触发垃圾回收）、大量内存碎片产生（可以通过参数启动压缩）； 7.G1收集器 一款面向服务端应用的垃圾收集器，后续会替换掉CMS垃圾收集器； 特点：并行与并发（充分利用多核多CPU缩短Stop-The-World时间）、分代收集（独立管理整个Java堆，但针对不同年龄的对象采取不同的策略）、空间整合（基于标记-整理）、可预测的停顿（将堆分为大小相等的独立区域，避免全区域的垃圾收集）； 关于Region：新生代和老年代不再物理隔离，只是部分Region的集合；G1跟踪各个Region垃圾堆积的价值大小，在后台维护一个优先列表，根据允许的收集时间优先回收价值最大的Region；Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，采用Remembered Set来避免全堆扫描； 分为几个步骤：1.初始标记（标记一下GC Roots能直接关联的对象并修改TAMS值，需要STW但耗时很短）、2.并发标记（从GC Root从堆中对象进行可达性分析找存活的对象，耗时较长但可以与用户线程并发执行）、3.最终标记（为了修正并发标记期间产生变动的那一部分标记记录，这一期间的变化记录在Remembered Set Log里，然后合并到Remembered Set里，该阶段需要STW但是可并行执行）、4.筛选回收（对各个Region回收价值排序，根据用户期望的GC停顿时间制定回收计划来回收）； 理解GC日志 详细的解读，请查阅本书籍。 最前面的数字代表GC发生的时间（虚拟机启动以后的秒杀）； “[GC”和“[Full GC”说明停顿类型，有Full代表的是Stop-The-World的； “[DefNew”、“[Tenured”和“[Perm”表示GC发生的区域； 方括号内部的“3324K -&gt; 152K(3712K)” 含义是 “GC前该内存已使用容量 -&gt; GC后该内存区域已使用容量(该区域总容量)”; 方括号之外的“3324K -&gt; 152K(11904)” 含义是 “GC前Java堆已使用容量 -&gt; GC后Java堆已使用容量(Java堆总容量)”; 再往后“0.0025925 secs”表示该内存区域GC所占用的时间； 内存分配与回收策略 对象优先在新生代分配 大对象直接进入老年代 长期存活的对象将进入老年代 动态对象年龄判断：如果在Survivor空间中相同年龄所有对象大小总和大于Survivor空间的一半，大于或等于该年龄的对象直接进入老年代； 空间分配担保：发生Minor GC前，虚拟机会先检查老年代最大可用连续空间是否大于新生代所有对象总空间，如果不成立，虚拟机会查看HandlePromotionFailure设置值是否允许担保失败，如果允许继续检查老年代最大可用的连续空间是否大于历次晋升到老年代的平均大小，如果大于会尝试进行一次Minor GC；如果小于或者不允许冒险，会进行一次Full GC； 第4章 JVM性能监控与故障处理工具概述定位问题时，知识和经验是关键基础、数据（运行日志、异常堆栈、GC日志、线程快照、堆转储快照）是依据、工具是运用知识处理数据的手段。 JDK命令行工具 1.jps: 虚拟机进程状况工具 功能：可以列出正在运行的虚拟机进程，并线上虚拟机执行的主类名称及其本地虚拟机唯一ID（LVMID）； 对于本地虚拟机来说，LVMID和操作系统的进程ID是一致的； 其他的工具通常都需要依赖jps获取LVMID； 主要选项：-q（只输出LVMID）、-m（输出传给main函数的参数）、-l（输出主类的全名）、-v（输出虚拟机启动JVM参数）； 2.jstat：虚拟机统计信息监视工具 功能：监视虚拟机各种运行状态信息，包括类装载、内存、垃圾收集、JIT等； 纯文本监控首选 3.jinfo：Java配置信息工具 功能：实时地查看虚拟机各项参数。虽然jps -v可以查看虚拟机启动参数，但是无法查看一些系统默认的参数。 支持运行期修改参数的能力，格式为“jinfo -flag name=value pid”； 4.jmap：Java内存映像工具 功能：用于生成堆转储快照（一般称为heapdump或dump文件）； 其他可生成heapdump的方式：使用参数-XX:+HeapDumpOnOutOfMemoryError；使用参数-XX:+HeapDumpOnCtrlBreak然后使用Ctrl+Break生成；Linux系统使用kill -3生成； 另外它还可以查询finalize执行队列、Java堆和永久代的详细信息； 5.jhat：虚拟机堆转储快照分析工具 功能：用于分析jmap生成的heapdump。其内置了一个微型的HTTP服务器，可以在浏览器查看分析结果； 实际很少用jhat，主要有两个原因：一是分析工程会耗用服务器资源；功能相对BisualVM、IBM HeapAnalyzer较为简陋 6.jstack：Java堆栈跟踪工具 功能：用于生成虚拟机当前时刻的线程快照（一般称为threaddump或javacore文件）。javacore主要目的是定位线程出现长时间停顿的原因，比如死锁、死循环、请求外部资源响应长等； 另外JDK 1.5后Thread类新增了getAllStackTraces()方法，可以基于此自己增加管理页面来分析 7.HSDIS：JIT生成代码反编译 现代虚拟机的实现慢慢地和虚拟机规范产生差距，如果要分析程序如果执行，最常见的就是通过软件调试工具（GDB、Windbg等）断点调试，但是对于Java来说，很多执行代码是通过JIT动态生成到CodeBuffer中的； 功能：HSDIS是官方推荐的HotSpot虚拟机JIT编译代码的反汇编工具，它包含在HotSpot虚拟机的源码中但没有提供编译后的程序，可以自己下载放到JDK的相关目录里； JDK可视化工具1.JConsole：Java监视与管理控制台 是一种基于JMX的可视化监控和管理工具，它管理部分的功能是针对MBean进行管理，由于MBean可以使用代码、中间件服务器或者所有符合JMX规范的软件进行访问，因此这里着重介绍JConsole的监控功能； 通过jconsole命令启动JConsole后，会自动搜索本机所有虚拟机进程。另外还支持远程进程的监控； 进入主界面，支持查看以下标签页：概述、内存、线程、类、VM摘要和MBean； 2.VisualVM：多合一故障处理工具 目前为止JDK发布的功能最强调的运行监控和故障处理程序，另外还支持性能分析； VisualVM还有一个很大的优点：不需要被监视的程序基于特殊Agent运行，对应用程序的实际性能影响很小，可直接应用在生成环境中； VisualVM基于NetBeans平台开发，具备插件扩展功能的特性，基于插件可以做到：显示虚拟机进程以及进程配置、环境信息（jps、jinfo）、监视应用程序的CPU、GC、堆、方法区以及线程的信息（jstat、jstack）、dump以及分析堆转储快照（jmap、jhat）、方法级的程序运行性能分析，找出被调用最多运行时间最长的方法、离线程序快照（收集运行时配置、线程dump、内存dump等信息建立快照）、其他plugins的无限可能。 使用jvisualvm首次启动时需要在线自动安装插件（也可手工安装）； 特色功能：生成浏览堆转储快照（摘要、类、实例标签页、OQL控制台）、分析程序性能（Profiler页签可以录制一段时间程序每个方法执行次数和耗时）、BTrace动态日志跟踪（不停止目标程序运行的前提下通过HotSwap技术动态加入调试代码）； 第7章 虚拟机类加载机制概述 虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 在Java语言里面，类型的加载、连接和初始化过程都是在程序运行期间完成，这虽然增量一些性能开销，但是会为Java应用程序提供高度的灵活性。 类加载的时机 类的整个生命周期：加载、验证、准备、解析、初始化、使用和卸载；其中验证、准备和解析统称为连接； 虚拟机规范没有强制约束类加载的时机，但严格规定了有且只有5种情况必须立即对类进行初始化：遇到new、getstatic、putstatic和invokestatic指令；对类进行反射调用时如果类没有进行过初始化；初始化时发现父类还没有进行初始化；虚拟机启动指定的主类；动态语言中MethodHandle实例最后解析结果REF_getStatic等的方法句柄对应的类没有初始化时； 类加载的过程1.加载 通过一个类的全限定名来获取定义此类的二进制字节流； 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构； 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问入口； 2.验证 验证是连接阶段的第一步，其目的是确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全； 验证阶段是非常重要的，这个阶段是否严谨决定了Java虚拟机是否能承受恶意代码的攻击； 校验动作：文件格式验证（基于二进制字节流）、元数据验证（对类的元数据语义分析）、字节码验证（对方法体语义分析）、符号引用验证（对类自身以外的信息进行匹配性校验）； 3.准备 正式为变量分配内存并设置类变量初始值的阶段，这些变量所使用的内存都将在这个方法区中进行分配； 需要强调两点：这时候内存分配的仅包括类变量，而不包括类实例变量；这里所说的初始化通常情况下是数据类型的零值，真正的赋值是在初始化阶段，如果是static final的则是直接赋值； 4.解析 解析阶段是虚拟机将常量池内的符号引用（如CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等7种）替换为直接引用的过程； 符号引用可以是任何形式的字面量，与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中；而直接引用是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄，它和虚拟机实现的内存布局相关，引用的目标必定以及在内存中存在； 对同一个符号引用进行多次解析请求是很常见的事情，虚拟机实现可以对第一次解析的结果进行缓存； 5.初始化 是类加载过程的最后一步，真正开始执行类中定义的Java程序代码（或者说是字节码）； 初始化阶段是执行类构造器方法的过程，该方法是由编译器自动收集类中的所有类变量的赋值动作和静态语句块中的语句合并产生的； 方法与类的构造函数（或者说是实例构造器方法）不同，它不需要显式地调用父类构造器，虚拟机会保证在子类的方法执行之前，父类的方法已执行完毕； 执行接口的方法不需要先执行父接口的方法，只有当父接口中定义的变量使用时父接口才会初始化，接口的实现类在初始化时也一样不会执行接口的方法； 方法初始化是加锁阻塞等待的，应当避免在方法中有耗时很长的操作； 类加载器 虚拟机设计团队把类加载阶段的“通过一个类的全限定名来获取描述此类的二进制字节流”这个动作放到虚拟机外部去实现，实现这个动作的代码模块称为类加载器； 这是Java语言的一项创新，也是Java语言流行的重要原因，在类层次划分、OSGI、热部署、代码加密等领域大放异彩 类与类加载器 对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在Java虚拟机的唯一性，每一个类加载器都拥有一个独立的类名称空间； 比较两个类是否相等（如Class对象的equals方法、isAssignableFrom方法、isInstance方法），只有在这两个类是由同一个类加载器加载的前提下才有意义； 双亲委派模型 关于双亲委派模型，这篇文章写得简单易懂:http://www.jianshu.com/p/acc7595f1b9d 三种系统提供的类加载器：启动类加载器（Bootstrap ClassLoader）、扩展类加载器（Extension ClassLoader）、应用程序类加载器（Application ClassLoader）； 双亲委派模型要求除了顶层的启动类加载器外，其他的类加载器都应当有自己的父类加载器，这里一般不会以继承的关系来实现，而是使用组合的关系来复用父加载器的代码； 其工作过程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，只有父类加载器反馈自己无法完成这个加载请求时（它的搜索范围中没有找到所需的类），子加载器才会尝试自己去加载； 这样的好处是Java类随着它的类加载器具备了一种带有优先级的层次关系，对保证Java程序的稳定运作很重要； 实现双亲委派的代码都集中在java.lang.ClassLoader的loadClass方法中，逻辑清晰易懂； JVM常用参数调节内存参数 参数 作用 -Xmx 堆大小的最大值。当前主流虚拟机的堆都是可扩展的 -Xms 堆大小的最小值。可以设置成和 -Xmx 一样的值 -Xmn 新生代的大小。现代虚拟机都是“分代”的，因此堆空间由新生代和老年代组成。新生代增大，相应地老年代就减小。Sun官方推荐新生代占整个堆的3/8 -Xss 每个线程的堆栈大小。该值影响一台机器能够创建的线程数上限 -XX:MaxPermSize= 永久代的最大值。永久代是 HotSpot 特有的，HotSpot 用永久代来实现方法区 -XX:PermSize= 永久代的最小值。可以设置成和 -XX:MaxPermSize 一样的值 -XX:SurvivorRatio= Eden 和 Survivor 的比值。基于“复制”的垃圾收集器又会把新生代分为一个 Eden 和两个 Survivor，如果该参数为8，就表示 Eden 占新生代的80%，而两个 Survivor 各占10%。默认值为8 -XX:PretenureSizeThreshold= 直接晋升到老年代的对象大小。大于这个参数的对象将直接在老年代分配。默认值为0，表示不启用 -XX:HandlePromotionFailure= 是否允许分配担保失败。在 JDK 6 Update 24 后该参数已经失效。 -XX:MaxTenuringThreshold= 对象晋升到老年代的年龄。对象每经过一次 Minor GC 后年龄就加1，超过这个值时就进入老年代。默认值为15 -XX:MaxDirectMemorySize= 直接内存的最大值。对于频繁使用 nio 的应用，应该显式设置该参数，默认值为0 GC参数 垃圾收集器 参数 备注 Serial（新生代） -XX:+UseSerialGC 虚拟机在 Client 模式下的默认值，打开此开关后，使用 Serial + Serial Old 的收集器组合。Serial 是一个单线程的收集器 ParNew（新生代） -XX:+UseParNewGC 强制使用 ParNew，打开此开关后，使用 ParNew + Serial Old 的收集器组合。ParNew 是一个多线程的收集器，也是 server 模式下首选的新生代收集器 -XX:ParallelGCThreads= 垃圾收集的线程数 Parallel Scavenge（新生代） -XX:+UseParallelGC 虚拟机在 Server 模式下的默认值，打开此开关后，使用 Parallel Scavenge + Serial Old 的收集器组合 -XX:MaxGCPauseMillis= 单位毫秒，收集器尽可能保证单次内存回收停顿的时间不超过这个值。 -XX:GCTimeRatio= 总的用于 gc 的时间占应用程序的百分比，该参数用于控制程序的吞吐量 -XX:+UseAdaptiveSizePolicy 设置了这个参数后，就不再需要指定新生代的大小（-Xmn）、 Eden 和 Survisor 的比例（-XX:SurvivorRatio）以及晋升老年代对象的年龄（-XX:PretenureSizeThreshold）了，因为该收集器会根据当前系统的运行情况自动调整。当然前提是先设置好前两个参数。 Serial Old（老年代） 无 Serial Old 是 Serial 的老年代版本，主要用于 Client 模式下的老生代收集，同时也是 CMS 在发生 Concurrent Mode Failure 时的后备方案 Parallel Old（老年代） -XX:+UseParallelOldGC 打开此开关后，使用 Parallel Scavenge + Parallel Old 的收集器组合。Parallel Old 是 Parallel Scavenge 的老年代版本，在注重吞吐量和 CPU 资源敏感的场合，可以优先考虑这个组合 CMS（老年代） -XX:+UseConcMarkSweepGC 打开此开关后，使用 ParNew + CMS 的收集器组合。 -XX:CMSInitiatingOccupancyFraction= CMS 收集器在老年代空间被使用多少后触发垃圾收集 -XX:+UseCMSCompactAtFullCollection 在完成垃圾收集后是否要进行一次内存碎片整理 -XX:CMSFullGCsBeforeCompaction= 在进行若干次垃圾收集后才进行一次内存碎片整理 附图：可以配合使用的收集器组合 其他参数 参数 作用 -verbose:class 打印类加载过程 -XX:+PrintGCDetails 发生垃圾收集时打印 gc 日志，该参数会自动带上 -verbose:gc 和 -XX:+PrintGC -XX:+PrintGCDateStamps / -XX:+PrintGCTimeStamps 打印 gc 的触发事件，可以和 -XX:+PrintGC 和 -XX:+PrintGCDetails 混用 -Xloggc:&lt;path&gt; gc 日志路径 -XX:+HeapDumpOnOutOfMemoryError 出现 OOM 时 dump 出内存快照用于事后分析 -XX:HeapDumpPath= 堆转储快照的文件路径 参考文章1.Gino Zhang的博客总结的很全面 http://ginobefunny.com 2.关于双亲委派模型，这篇文章写得简单易懂:http://www.jianshu.com/p/acc7595f1b9d 交流或更多内容请关注我的公众号：nezha_blog 我的技术博客：https://nezha.github.io]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
        <tag>深入理解Java虚拟机</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[完美解决：IntelliJ IDEA通过maven构建的项目默认是Java5,改成Java8编译会出错]]></title>
    <url>%2F%E7%96%91%E9%9A%BE%E8%A7%A3%E6%83%91%2F2017-06-17-IntelliJ_IDEA%E9%80%9A%E8%BF%87maven%E6%9E%84%E5%BB%BA%E7%9A%84%E9%A1%B9%E7%9B%AE%E9%BB%98%E8%AE%A4%E6%98%AFJava5%2F</url>
    <content type="text"><![CDATA[问题是什么当我使用maven构建项目的时候，系统给项目分配的api自动会设置成Java5.0 的版本，这个版本下Java8的好多功能都不支持的，甚至连@override都不支持。 那我改成Java8不就行了于是我在上图中改成了Java8,于是乎就出现了下面的问题….连编译都不能通过了。 完美解决在这里最后参考了https://stackoverflow.com/上的方法，出入已经找不到了，如有同学发现我来加上引用。 主要在pom.xml中置顶build的版本如下xml代码段 12345678910111213&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.5.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 即如下图：]]></content>
      <categories>
        <category>疑难解惑</category>
      </categories>
      <tags>
        <tag>IntelliJ IDEA</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式学习笔记-装饰者模式-Decorator Pattern]]></title>
    <url>%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F2017-05-09-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%A3%85%E9%A5%B0%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[定义 装饰者模式：在不改变原类文件以及不使用继承的情况下，动态地将责任附加到对象上，从而实现动态拓展一个对象的功能。它是通过创建一个包装对象，也就是装饰来包裹真实的对象。 设计原则 要使用装饰者模式，需要满足以下设计原则： 多用组合，少用继承 开放-关闭原则：类应该对拓展开放，对修改关闭 UML类图 我们先来看看装饰者模式的类图，再来详细讲述： 由上自下：1、Girl是基类。通常是一个抽象类或者一个接口，定义了属性或者方法，方法的实现可以由子类实现或者自己实现。通常不会直接使用该类，而是通过继承该类来实现特定的功能，它约束了整个继承树的行为。比如说，如果Girl代表人，即使通过装饰也不会使人变成别的动物。2、AmericanGirl是Girl的子类，实现了相应的方法，它充当了“被装饰者”的角色。3、GirlDecorator也是Girl的子类，它是装饰者共同实现的抽象类（也可以是接口）。比如说，GirlDecorator代表学习课程或兴趣这一类装饰者，那么它的子类应该是科学、艺术课这样的具体的装饰者。4、Science是GirlDecorator的子类，是具体的装饰者，由于它同时也是Girl的子类，因此它能方便地拓展Girl的状态（比如添加新的方法）。每个装饰者都应该有一个实例变量用以保存某个Girl(Component也可以理解为抽象组件)的引用，这也是利用了组合的特性。在持有Girl的引用后，由于其自身也是Girl的子类，那么，相当于Science(ConcreteDecorator)具体的装饰者包裹了Girl(Component)抽象对象，不但有Girl的特性，同时自身也可以有别的特性，也就是所谓的装饰。 Java 实例 为了更加深刻地理解装饰者模式，我们来看一个简单的栗子。首先，我们假设现在有这样一个需求：你是一个教育培训机构，这边女孩有来自各个国家的，然后针对某个国家的女孩学习不同课程需要继续和描述。此时，某个国家的女孩就是被装饰着，某个课程就是装饰者。 Step 1、创建Component基类因为总体对象是女孩，所以我们可以把人抽象为基类，新建Girl.java: 1234567public abstract class Girl &#123; String description = "no particular"; public String getDescription()&#123; return description; &#125; public abstract int cost();&#125; Step 2、创建被装饰者——ConcreteComponent具体的客户有来自各个国家的，美国的，加拿大等。 12345678910public class AmericanGirl extends Girl &#123; //一个实例，相当于被装饰者。 public AmericanGirl()&#123; description = description + "+American"; &#125; @Override public int cost() &#123; return 0; &#125;&#125; Step 3、创建Decorator创建装饰者类GirlDecorator.java 123public abstract class GirlDecorator extends Girl&#123; public abstract String getDescription();&#125; Step 4、创建ConcreteDecorator创建Science.java和Art.java 123456789101112131415161718192021222324public class Science extends GirlDecorator &#123; private Girl girl; public Science(Girl girl)&#123; this.girl = girl; &#125; @Override public String getDescription() &#123; //其中this.girl.getDescription()可能是原始被装饰者 //或者已经装饰过的girl了 return this.girl.getDescription() + "+Like Science"; &#125; //装饰者附加上的功能 public void caltulateStuff() &#123; System.out.println("scientific calculation!"); &#125; @Override public int cost() &#123; //装饰者，去装饰girl对象，然后加上装饰的新属性和任务 return girl.cost() + 100; &#125;&#125; 123456789101112131415161718public class Art extends GirlDecorator &#123; private Girl girl; public Art(Girl girl) &#123; this.girl = girl; &#125; @Override public String getDescription() &#123; return this.girl.getDescription() + "+Like Art"; &#125; @Override public int cost() &#123; return girl.cost() + 200; &#125;&#125; 最后我们在测试类内测试我们的代码12345678910111213141516171819202122public class Main &#123; public static void main(String[] args) &#123; //普通美国女孩 Girl g1 = new AmericanGirl(); System.out.println(g1.getDescription()); //喜欢科学的 Science g2 = new Science(g1); System.out.println(g2.getDescription()); //喜欢艺术的 Art g3 = new Art(g2); System.out.println(g3.getDescription()); //喜欢体育 Sports g4 = new Sports(g3); System.out.println(g4.getDescription()); System.out.println("g1,g2,g3,g4包装后的费用:"+g4.cost()); &#125;&#125; 最终的结果12345no particular+Americanno particular+American+Like Scienceno particular+American+Like Science+Like Artno particular+American+Like Science+Like Art; also learn Sportsg1,g2,g3,g4包装后的费用:600 特点 以上就是装饰者模式的一个小栗子，讲述了装饰者的基本用法。通过上述的例子，我们可以总结一下装饰者模式的特点。（1）装饰者和被装饰者有相同的接口（或有相同的父类）。（2）装饰者保存了一个被装饰者的引用。（3）装饰者接受所有客户端的请求，并且这些请求最终都会返回给被装饰者。（4）在运行时动态地为对象添加属性，不必改变对象的结构。 使用装饰者模式的最大好处就是其拓展性十分良好，通过使用不同的装饰类来使得对象具有多种多样的属性，灵活性比直接继承好。然而它也有缺点，那就是会出现很多小类，即装饰类，使程序变得复杂。 应用 学习了装饰者模式用法、特点以及优缺点后，我们再来看看装饰者模式在实际开发过程的应用。装饰者模式在Java中经常出现的地方就是JavaIO。提到JavaIO，脑海中就冒出了大量的类：InputStream、FileInputStream、BufferedInputStream……等，真是头都大了，其实，这里面大部分都是装饰类，只要弄清楚这一点就容易理解了。我们来看看JavaIO是怎样使用装饰者模式的。从字符流来分析，我们知道，有两个基类，分别是InputStream和OutputStream，它们也就是我们上面所述的Component基类。接着，它有如下子类：FileInputStream、StringBufferInputStream等，它们就代表了上面所述的ConcreteComponent，即装饰对象。此外，InputStream还有FilterInputStream这个子类，它就是一个抽象装饰者，即Decorator，那么它的子类：BufferedInputStream、DataInputStream等就是具体的装饰者了。那么，从装饰者模式的角度来看JavaIO，是不是更加容易理解了呢？ 下面，我们来自己实现自己的JavaIO的装饰者。要实现的功能是：把一段话里面的每个单词的首字母大写。我们先新建一个类：UpperFirstWordInputStream.java 1234567891011121314151617181920public class UpperFirstWordInputStream extends FilterInputStream &#123; private int cBefore = 32; public UpperFirstWordInputStream(InputStream in)&#123; //由于FilterInputStream已经保存了装饰对象的引用，这里直接调用super即可 super(in); &#125; public int read() throws IOException &#123; //根据前一个字符是否是空格来判断是否要大写 int c = super.read(); if(cBefore == 32) &#123; cBefore = c; return (c == -1 ? c: Character.toUpperCase((char) c)); &#125;else&#123; cBefore = c; return c; &#125; &#125;&#125; 接着编写一个测试类：InputTest.java1234567891011121314151617public class InputTest &#123; public static void main(String[] args) throws IOException &#123; int c; StringBuffer sb = new StringBuffer(); try &#123; //这里用了两个装饰者，分别是BufferedInputStream和我们的UpperFirstWordInputStream InputStream in = new UpperFirstWordInputStream(new BufferedInputStream(new FileInputStream("/Users/nezha/Desktop/test.txt"))); while((c = in.read()) &gt;= 0) &#123; sb.append((char) c); &#125; System.out.println(sb); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 参考文献： 学习、探究Java设计模式——装饰者模式 交流或更多内容请关注我的公众号：nezha_blog 我的技术博客：https://nezha.github.io]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>装饰者模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式学习笔记-策略模式]]></title>
    <url>%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F2017-05-08-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在策略模式（Strategy Pattern）中，一个类的行为或其算法可以在运行时更改。这种类型的设计模式属于行为型模式。在策略模式中，我们创建表示各种策略的对象和一个行为随着策略对象改变而改变的 context 对象。策略对象改变 context 对象的执行算法。 介绍意图：定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。主要解决：在有多种算法相似的情况下，使用 if…else 所带来的复杂和难以维护。何时使用：一个系统有许多许多类，而区分它们的只是他们直接的行为。如何解决：将这些算法封装成一个一个的类，任意地替换。关键代码：实现同一个接口。应用实例： 1、诸葛亮的锦囊妙计，每一个锦囊就是一个策略。 2、旅行的出游方式，选择骑自行车、坐汽车，每一种旅行方式都是一个策略。 3、JAVA AWT 中的 LayoutManager。优点： 1、算法可以自由切换。 2、避免使用多重条件判断。 3、扩展性良好。缺点： 1、策略类会增多。 2、所有策略类都需要对外暴露。使用场景： 1、如果在一个系统里面有许多类，它们之间的区别仅在于它们的行为，那么使用策略模式可以动态地让一个对象在许多行为中选择一种行为。 2、一个系统需要动态地在几种算法中选择一种。 3、如果一个对象有很多的行为，如果不用恰当的模式，这些行为就只好使用多重的条件选择语句来实现。注意事项：如果一个系统的策略多于四个，就需要考虑使用混合模式，解决策略类膨胀的问题。 特点1.封装变化。2.多用组合，少用继承。3.针对接口编程，不针对实现编程。 Java实现我们将创建一个定义活动的 IStrategy 接口和实现了 Strategy 接口的实体策略类。Context 是一个使用了某种策略的类。StrategyPatternDemo，我们的演示类使用 Context 和策略对象来演示 Context 在它所配置或使用的策略改变时的行为变化。 步骤 1创建一个接口。Strategy.java123public interface IStrategy &#123; public int doOperation(int num1, int num2);&#125; 步骤 2创建实现接口的实体类。StrategyAdd.java 123456public class StrategyAdd implements IStrategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 + num2; &#125;&#125; StrategySubstract.java123456public class StrategySubstract implements IStrategy &#123; @Override public int doOperation(int num1, int num2) &#123; return num1 - num2; &#125;&#125; StrategyMultiply.java123456public class StrategyMultiply implements IStrategy&#123; @Override public int doOperation(int num1, int num2) &#123; return num1 * num2; &#125;&#125; 步骤 3创建 Context 类。Context.java1234567891011public class Context&#123; private IStrategy strategy; public Context(IStrategy strategy)&#123; this.strategy = strategy; &#125; public int executeStrategy(int num1, int num2)&#123; return strategy.doOperation(num1, num2); &#125;&#125; 步骤 4使用 Context 来查看当它改变策略 Strategy 时的行为变化。StrategyTest.java12345678910111213public class StrategyTest&#123; @Test public void test()&#123; Context context = new Context(new StrategyAdd()); System.out.println("10 + 5 = " + context.executeStrategy(10, 5)); context = new Context(new StrategySubstract()); System.out.println("10 - 5 = " + context.executeStrategy(10, 5)); context = new Context(new StrategyMultiply()); System.out.println("10 * 5 = " + context.executeStrategy(10, 5)); &#125;&#125; 参考文献：http://www.runoob.com/design-pattern/strategy-pattern.html 交流或更多内容请关注我的公众号：nezha_blog 我的技术博客：https://nezha.github.io]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>策略模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式学习笔记-常用设计模式]]></title>
    <url>%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F2017-05-07-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%B8%B8%E7%94%A8%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式概括创建型模式 抽象工厂模式(Abstract factory pattern): 提供一个接口, 用于创建相关或依赖对象的家族, 而不需要指定具体类. 生成器模式(Builder pattern): 使用生成器模式封装一个产品的构造过程, 并允许按步骤构造. 将一个复杂对象的构建与它的表示分离, 使得同样的构建过程可以创建不同的表示. 工厂模式(factory method pattern): 定义了一个创建对象的接口, 但由子类决定要实例化的类是哪一个. 工厂方法让类把实例化推迟到子类. 原型模式(prototype pattern): 当创建给定类的实例过程很昂贵或很复杂时, 就使用原形模式. 单例了模式(Singleton pattern): 确保一个类只有一个实例, 并提供全局访问点. 多例模式(Multition pattern): 在一个解决方案中结合两个或多个模式, 以解决一般或重复发生的问题. 结构型模式 适配器模式(Adapter pattern): 将一个类的接口, 转换成客户期望的另一个接口. 适配器让原本接口不兼容的类可以合作无间. 对象适配器使用组合, 类适配器使用多重继承. 桥接模式(Bridge pattern): 使用桥接模式通过将实现和抽象放在两个不同的类层次中而使它们可以独立改变. 组合模式(composite pattern): 允许你将对象组合成树形结构来表现”整体/部分”层次结构. 组合能让客户以一致的方式处理个别对象以及对象组合. 装饰者模式(decorator pattern): 动态地将责任附加到对象上, 若要扩展功能, 装饰者提供了比继承更有弹性的替代方案. 外观模式(facade pattern): 提供了一个统一的接口, 用来访问子系统中的一群接口. 外观定义了一个高层接口, 让子系统更容易使用. 亨元模式(Flyweight Pattern): 如想让某个类的一个实例能用来提供许多”虚拟实例”, 就使用蝇量模式. 代理模式(Proxy pattern): 为另一个对象提供一个替身或占位符以控制对这个对象的访问. 行为型模式 责任链模式(Chain of responsibility pattern): 通过责任链模式, 你可以为某个请求创建一个对象链. 每个对象依序检查此请求并对其进行处理或者将它传给链中的下一个对象. 命令模式(Command pattern): 将”请求”封闭成对象, 以便使用不同的请求,队列或者日志来参数化其他对象. 命令模式也支持可撤销的操作. 解释器模式(Interpreter pattern): 使用解释器模式为语言创建解释器. 迭代器模式(iterator pattern): 提供一种方法顺序访问一个聚合对象中的各个元素, 而又不暴露其内部的表示. 中介者模式(Mediator pattern) : 使用中介者模式来集中相关对象之间复杂的沟通和控制方式. 备忘录模式(Memento pattern): 当你需要让对象返回之前的状态时(例如, 你的用户请求”撤销”), 你使用备忘录模式. 观察者模式(observer pattern): 在对象之间定义一对多的依赖, 这样一来, 当一个对象改变状态, 依赖它的对象都会收到通知, 并自动更新. 状态模式(State pattern): 允许对象在内部状态改变时改变它的行为, 对象看起来好象改了它的类. 策略模式(strategy pattern): 定义了算法族, 分别封闭起来, 让它们之间可以互相替换, 此模式让算法的变化独立于使用算法的客户. 模板方法模式(Template pattern): 在一个方法中定义一个算法的骨架, 而将一些步骤延迟到子类中. 模板方法使得子类可以在不改变算法结构的情况下, 重新定义算法中的某些步骤. 访问者模式(visitor pattern): 当你想要为一个对象的组合增加新的能力, 且封装并不重要时, 就使用访问者模式. 七大设计原则： 单一职责原则【SINGLE RESPONSIBILITY PRINCIPLE】：一个类负责一项职责. 里氏替换原则【LISKOV SUBSTITUTION PRINCIPLE】：继承与派生的规则. 依赖倒置原则【DEPENDENCE INVERSION PRINCIPLE】：高层模块不应该依赖低层模块，二者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象。即针对接口编程，不要针对实现编程. 接口隔离原则【INTERFACE SEGREGATION PRINCIPLE】：建立单一接口，不要建立庞大臃肿的接口，尽量细化接口，接口中的方法尽量少. 迪米特法则【LOW OF DEMETER】：低耦合，高内聚. 开闭原则【OPEN CLOSE PRINCIPLE】：一个软件实体如类、模块和函数应该对扩展开放，对修改关闭. 组合/聚合复用原则【Composition/Aggregation Reuse Principle(CARP) 】：尽量使用组合和聚合少使用继承的关系来达到复用的原则. 常用设计模式总结1. 策略模式( Strategy )定义个策略接口，不同的实现类提供不同的具体策略算法, 同时它们之间可以互相替换. IStrategy 接口定义了策略方法，Strategy1 和 Strategy2 通过实现 IStrategy 提供不同的策略，而 User 组合了 IStrategy ，可以通过给 User 对象设置不同具体实现类来让其获得不同的策略 2. 简单工厂模式( Simple Factory )定义一个用以创建对象的工厂, 根据不同的条件生成不同的对象 注意简单工厂模式与策略模式是不同的，工厂模式是根据给定的条件返回相应的对象，而策略模式是将不同的策略对象传递给使用者以实现不同策略 3. 工厂模式( Factory )针对每一种产品提供一个工厂类，通过不同的工厂实例来创建不同的产品实例 与简单工厂模式不同点是它要为每一种产品提供一个工厂类，不同工厂类实现同一个工厂接口，返回不同产品 4. 抽象工厂模式( Abstract Factory )应对产品族概念而生 与工厂模式相比，抽象工厂模式是为了应对产品族 5. 装饰者模式( Decorator )动态的给一个对象添加一些额外的功能 ComponentImpl 和 Decorator 类都实现了 IComponent 接口，不同的是 ComponentImpl 提供了具体实现，而 Decorator 是先聚合 ComponentImpl 接着在自己的实现方法即 operation() 方法中做些处理（即装饰）后再调用 ComponentImpl 对象的具体实现 6. 代理模式( Proxy )封装被代理对象并限制外界对被代理对象的访问 注意区分装饰者模式和代理模式的区别。在代理模式中，ComponentImpl 和 Proxy 类都实现了 IComponent 接口，Proxy 对象中虽然也维护着一个 ComponentImpl 对象，但一般情况下它是代理类自己初始化的，不像装饰者模式是通过 set 进去的，同时在接口方法即 operation() 中代理对象会限制外界对被代理对象的访问，而装饰者模式是装饰者给被装饰者添加额外的行为 7. 模板方法模式( Template )定义一个操作的算法骨架, 并将一些步骤延迟到子类中 AbsTemplate 抽象类中定义了一系列的方法，其中外界唯一能调用的 operation() 方法是 final 的（即不可重写），在该方法中分别调用了 first() 、second() 、third() 方法（即搭好算法框架），子类通过继承抽象类重写不同的方法来添加各自的行为 8. 外观模式( Facade )为系统向外界提供一个统一的接口 Fracade 为 ComponentA 、ComponentB 、ComponentC 向外即 ClientA 、ClientB 提供统一的接口 9. 适配器模式( Adapter )将一个类的接口转换成客户希望的另一个接口 比如项目引入第三方类库后应该先封装起来转换成自己需要的接口再使用，防止以后类库出现变更。AdapterA 先将 LibraryClass 封装起来，其对外提供的 operation() 方法中调用 LibraryClass 对象的方法，若以后换类库，只需改 AdapterA 类或者创建新的 Adapter 实现类即可 10. 桥接模式( Bridge )将抽象部分与实现部分分离，使它们都可以独立的变化 将原本要耦合的上下层抽象出来，上层和下层以组合的方式连接，然后上下层抽象可派生出许多不同方向的子类。AbsShape 封装了 IDrawProgram 接口，这样它的子类想从 DPA 切换到 DPB 或者别的，只需 set 进去就行啦（你看，这 UML 图多像座桥） 注: 适配器、桥接与外观三模式之间关系 11. 建造者模式( Builder )将一个复杂对象的构建与它的表示分离. 作为 Product 的内部类，Builder 统一了 Product 的整个构建过程，同时在 build 过程中，可以由于 set 值顺序不同等原因产生不同的效果 12. 观察者模式( Observer )定义了一种一对多的依赖关系,让多个观察者对象同时监听某一主题对象,在它的状态发生变化时,会通知所有的观察者. 先将 Observer 注册到 Observable ，那么当 Observable 状态改变时会通知它持有的所有 Observer ,对了，最好 Observable 中的 mList 的泛型是 WeakReference&lt;Observer&gt; ,防止内存泄漏 13. 单例模式( Singleton )保证一个类仅有一个实例,并提供一个访问它的全局控制点. 下图是利用 Java 的语言特性实现的线程安全且能延迟初始化的单例模式，Singleton 中维护着静态私有的 SingleHolder 类， SingleHolder 类中持有个静态常量 sHolder ，Client 若通过 getSingleInstance 方法获取 Singleton 对象则直接返回 SingleHolder 类的 sHolder ，详细分析可转我的博客-设计模式学习笔记-单例模式 14. 命令模式( Command )将一个请求封装成为一个对象, 使可以用不同的请求对客户进行参数化 Action 封装了具体行为，Command 封装了 Action 并提供空方法 execute() ，它的子类通过重写该方法可在方法里调用 mAction 不同行为达到封装命令的目的，最后 Client 封装了一系列的 Command 对象，并可以通过 notify() 方法一个接着一个调用所持有 Command 对象们的 execute() 方法达到给 Action 传达命令的目的 参考文献14种常用设计模式java 常用十种设计模式示例归纳]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从Jekyll到Hexo]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2017-05-05-Hexo%E9%83%A8%E7%BD%B2%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[为什么用Hexo搭建博客原先是使用Jekyll写博客，但是Jekyll得Markdown语法兼容有些问题，这个时候又关注到Next主题，于是发现Hexo社区近两年很活跃而且兼容性很强。于是改去使用Hexo部署博客。 安装Hexo步骤1.安装Git，并注册Github账号 这部分自行baidu, Google. 2.安装nodejs环境。 这部分也是自己去搞定，主要是下的nodejs和npm一起的。 3.Hexo初始化博客框架1.安装Hexo 1$ npm install -g hexo-cli 2.初始化框架 123$ hexo init &lt;yourFolder&gt;$ cd &lt;yourFolder&gt;$ npm install 3.初始化完成大概的目录： 12345678.├── _config.yml //网站的 配置 信息，您可以在此配置大部分的参数。├── package.json├── scaffolds //模版 文件夹。当您新建文章时，Hexo 会根据 scaffold 来建立文件。├── source //资源文件夹是存放用户资源的地方。| ├── _drafts| └── _posts└── themes //主题 文件夹。Hexo 会根据主题来生成静态页面。 4.新建文章（创建一个Hello World） 1$ hexo new "Hello World" 会在/source/_post里添加hello-world.md文件，之后新建的文章都将存放在此目录下。 5.生成网站 1$ hexo generate 此时会将/source的.md文件生成到/public中，形成网站的静态文件。 6.启动服务器 1$ hexo server -p 3000 输入http://localhost:3000即可查看网站。 7.部署网站 1$ hexo deploy 部署网站之前需要生成静态文件，即可以用$ hexo generate -d直接生成并部署。此时需要在_config.yml中配置你所要部署的站点：12345## Docs: http://hexo.io/docs/deployment.html deploy: type: git repo: git@github.com:YourRepository.git branch: master 如果部署失败，可能是因为没有安装hexo git插件 1npm install hexo-deployer-git --save 安装主题Next1.使用 12$ cd your-hexo-site$ git clone https://github.com/iissnan/hexo-theme-next themes/next 从Next的Gihub仓库中获取最新版本。 2.启用 需要修改/root/_config.yml配置项theme： 1234# Extensions## Plugins: http://hexo.io/plugins/## Themes: http://hexo.io/themes/theme: next 3.主题设定及第三方配置 主题配置 第三方服务 关于公式的问题 主要是说：原生的hexo主题没有MathJax解析器，我们需要配置后才能解析latex格式的公式。 安装hexo-math插件 1npm install hexo-math --save 当然还会有类似下划线的markdown解析冲突 这个就采取最简单的方式出现_，就用\_去解析 关于基本的MathJax公式使用及详细问题可以参考这个文献：LaTeX 在 Hexo 中的使用 -hexo-math 常用的命令 当初次部署完成后，只要在hexo-site/source/_post/添加文件就可以。格式是markdown形式的。 12345678910#1.将hexo-site/package.json中的依赖重新下载npm install #2.清空原来生成的文件，重新整个编译hexo clean#3.生成静态文件，用于直接访问hexo g#4.部署到git上，也可以不部署，只在本地运行hexo d#5.启动本地服务程序hexo s]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式学习笔记-工厂模式]]></title>
    <url>%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F2017-05-03-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E4%B8%89%E7%A7%8D%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式学习笔记-工厂模式 介绍简单工厂模式之前先通过一个披萨项目的例子来引出问题，然后给出简单工厂模式这种解决方案，然后随着披萨项目的不断扩展，遇到新的问题，引出工厂方法模式，然后又遇到新的问题，引出最终解决方案，抽象工厂模式。 简单工厂模式从下面的UML图中就已经可以直观上看出：简单工厂是实现直接的实例对象。 类视图简单工厂模式是类的创建模式，又叫做静态工厂方法（Static Factory Method）模式。简单工厂模式是由一个工厂对象决定创建出哪一种产品类的实例。简单工厂模式的结构如下： Java实例1234567891011121314151617public class SimplePizzaFactory &#123; public static Pizza createPizza(String type) &#123; Pizza pizza = null; if (type.equals("cheese")) &#123; pizza = new CheesePizza(); &#125; else if (type.equals("pepperoni")) &#123; pizza = new PepperoniPizza(); &#125; else if (type.equals("clam")) &#123; pizza = new ClamPizza(); &#125; else if (type.equals("veggie")) &#123; pizza = new VeggiePizza(); &#125; return pizza; &#125;&#125; 总结上面用披萨项目的列子来讲解了简单工厂模式的使用，总结下优缺点： 简单工厂模式的优点： 模式的核心是工厂类。这个类含有必要的判断逻辑，可以决定在什么时候创建哪一个产品类的实例。而客户端则可以免除直接创建对象的责任（比如那个店长）。简单工厂模式通过这种做法实现了对责任的分割。 简单工厂模式的缺点： 这个工厂类集中了所以的创建逻辑，当有复杂的多层次等级结构时，所有的业务逻辑都在这个工厂类中实现。什么时候它不能工作了，整个系统都会受到影响。并且简单工厂模式违背了开闭原则（对扩展的开放，对修改的关闭）。 工厂模式 我们来看一下工厂方法模式的定义吧。工厂方法模式定义了一个创建对象的接口，但由子类决定要实例化哪一个。工厂方法让类把实例化推迟到了子类。（定义摘自《Head First设计模式》） 首先，在工厂方法模式中，核心的工厂类不再负责所有产品的创建，而是将具体创建的工作交给子类去做.这个核心类则摇身一变，成为了一个抽象工厂角色，仅负责给出具体工厂子类必须实现的接口，而不接触哪一个产品类应当被实例化这种细节。 这种进一步抽象化的结果，使这种工厂方法模式可以用来予许系统在不修改具体工厂角色的情况下引进新的产品，也就遵循了开闭原则。 工厂模式结构 实现过程的类视图 Java实现核心 1.客户端的模拟过程。 123456789101112131415public class PizzaTestDrive &#123; public static void main(String[] args) &#123; PizzaStore nyStore = new NYPizzaStore(); PizzaStore chicagoStore = new ChicagoPizzaStore(); Pizza pizza = nyStore.orderPizza("cheese"); System.out.println("Ethan ordered a " + pizza.getName() + "\n"); pizza = chicagoStore.orderPizza("cheese"); System.out.println("Joel ordered a " + pizza.getName() + "\n"); pizza = nyStore.orderPizza("clam"); System.out.println("Ethan ordered a " + pizza.getName() + "\n"); &#125;&#125; 2.抽象工厂 其中createPizza是个抽象方法，这里没有实现它，不过客户端调用抽象工厂时，通过createPizza就能返回具体工厂生产的具体产品。这里忽略了具体产品实现的过程。 1234567891011121314public abstract class PizzaStore &#123; abstract Pizza createPizza(String item); public Pizza orderPizza(String type) &#123; Pizza pizza = createPizza(type); System.out.println("--- Making a " + pizza.getName() + " ---"); pizza.prepare(); pizza.bake(); pizza.cut(); pizza.box(); return pizza; &#125;&#125; 3.具体的工厂-去实现createPizza 通过从抽象工厂集成过来的createPizza实现具体的产品。 1234567891011121314public class NYPizzaStore extends PizzaStore &#123; Pizza createPizza(String item) &#123; if (item.equals("cheese")) &#123; return new NYStyleCheesePizza(); &#125; else if (item.equals("veggie")) &#123; return new NYStyleVeggiePizza(); &#125; else if (item.equals("clam")) &#123; return new NYStyleClamPizza(); &#125; else if (item.equals("pepperoni")) &#123; return new NYStylePepperoniPizza(); &#125; else return null; &#125;&#125; 总结 抽象工厂利用多态的优势将具体的产品的实例化放在具体工厂中实现。 抽象工厂创建的是抽象产品–提供的是抽象方法(createPizza)，但是具体的实现是推迟到具体的工厂中实现。 客户端中对用户可见的对象表面上看到的是两个抽象对象，但是具体工厂会创建用户指定类型的产品。 抽象工厂模式抽象工厂模式是所有形态的工厂模式中最为抽象和最具一般性的一种形态。抽象工厂模式可以向客户端提供一个接口，使得客户端在不必指定产品的具体类型的情况下，创建多个产品族中的产品对象。这就是抽象工厂的用意。 抽象工厂模式结构抽象工厂模式的简略类图如下: 类视图 Java实现 PizzaStore是抽象的工厂，具体的实例化是交给NYPizzaStore这些工厂。 NYPizzaStore是具体的创建类，通过实现createPizza(type)方法来具体化产品。通过PizzaIngredientFactory这个产品整合工厂将不同产品做了整合。 PizzaIngredientFactory是抽象的产品整合工厂，具体的产品整合是交给具体的产品整合厂NYPizzaIngredientFactory这些的。 NYPizzaIngredientFactory是具体的的产品整合厂，它实现了PizzaIngredientFactory的各种创建实例的方法。 这里基本的思想都是延迟实例化，将具体实例化发在具体的子类中实现，对象统一的只提供工厂对象。 1.创建型抽象工厂 1234567891011121314public abstract class PizzaStore &#123; abstract Pizza createPizza(String item); public Pizza orderPizza(String type) &#123; Pizza pizza = createPizza(type); System.out.println("--- Making a " + pizza.getName() + " ---"); pizza.prepare(); pizza.bake(); pizza.cut(); pizza.box(); return pizza; &#125;&#125; 2.创建型具体工厂 1234567891011121314151617181920212223public class NYPizzaStore extends PizzaStore &#123; protected Pizza createPizza(String item) &#123; Pizza pizza = null; PizzaIngredientFactory ingredientFactory = new NYPizzaIngredientFactory(); if (item.equals("cheese")) &#123; pizza = new CheesePizza(ingredientFactory); pizza.setName("New York Style Cheese Pizza"); &#125; else if (item.equals("veggie")) &#123; pizza = new VeggiePizza(ingredientFactory); pizza.setName("New York Style Veggie Pizza"); &#125; else if (item.equals("clam")) &#123; pizza = new ClamPizza(ingredientFactory); pizza.setName("New York Style Clam Pizza"); &#125; else if (item.equals("pepperoni")) &#123; pizza = new PepperoniPizza(ingredientFactory); pizza.setName("New York Style Pepperoni Pizza"); &#125; return pizza; &#125;&#125; 3.创建型整合工厂-用于整合产品 123456789101112131415161718192021222324252627public class NYPizzaIngredientFactory implements PizzaIngredientFactory &#123; public Dough createDough() &#123; return new ThinCrustDough(); &#125; public Sauce createSauce() &#123; return new MarinaraSauce(); &#125; public Cheese createCheese() &#123; return new ReggianoCheese(); &#125; public Veggies[] createVeggies() &#123; Veggies veggies[] = &#123; new Garlic(), new Onion(), new Mushroom(), new RedPepper() &#125;; return veggies; &#125; public Pepperoni createPepperoni() &#123; return new SlicedPepperoni(); &#125; public Clams createClam() &#123; return new FreshClams(); &#125;&#125; 4.抽象的产品类 1234567891011121314151617181920212223242526272829303132public abstract class Pizza &#123; String name; Dough dough; Sauce sauce; Veggies veggies[]; Cheese cheese; Pepperoni pepperoni; Clams clam; abstract void prepare(); void bake() &#123; System.out.println("Bake for 25 minutes at 350"); &#125; void cut() &#123; System.out.println("Cutting the pizza into diagonal slices"); &#125; void box() &#123; System.out.println("Place pizza in official PizzaStore box"); &#125; void setName(String name) &#123; this.name = name; &#125; String getName() &#123; return name; &#125;&#125; 5.产品抽象工厂 12345678910public interface PizzaIngredientFactory &#123; public Dough createDough(); public Sauce createSauce(); public Cheese createCheese(); public Veggies[] createVeggies(); public Pepperoni createPepperoni(); public Clams createClam(); &#125; 6.产品具体工厂 1234567891011121314public class CheesePizza extends Pizza &#123; PizzaIngredientFactory ingredientFactory; public CheesePizza(PizzaIngredientFactory ingredientFactory) &#123; this.ingredientFactory = ingredientFactory; &#125; void prepare() &#123; System.out.println("Preparing " + name); dough = ingredientFactory.createDough(); sauce = ingredientFactory.createSauce(); cheese = ingredientFactory.createCheese(); &#125;&#125; 7.测试代码 面向用户的一层是没有改变接口，还是使用抽象对象PizzaStore和Pizza 12345678910111213141516171819public class PizzaTestDrive &#123; public static void main(String[] args) &#123; PizzaStore nyStore = new NYPizzaStore(); PizzaStore chicagoStore = new ChicagoPizzaStore(); Pizza pizza = nyStore.orderPizza("cheese"); System.out.println("Ethan ordered a " + pizza + "\n"); pizza = chicagoStore.orderPizza("cheese"); System.out.println("Joel ordered a " + pizza + "\n"); pizza = nyStore.orderPizza("clam"); System.out.println("Ethan ordered a " + pizza + "\n"); pizza = chicagoStore.orderPizza("clam"); System.out.println("Joel ordered a " + pizza + "\n"); &#125;&#125; 三者的具体区别工厂方法模式和简单工厂模式比较：工厂方法模式跟简单工厂模式在结构上的不同是很明显的，工厂方法模式的核心是一个抽象工厂类，而简单工厂模式的核心在一个具体类。显而易见工厂方法模式这种结构更好扩展，权力下发，分布式比集中式更具优势。 如果系统需要加入一个新的产品，那么所需要的就是向系统中加入一个这个产品类以及它所对应的工厂类。没有必要修改客户端，也没有必要修改抽象工厂角色或者其他已有的具体工厂角色。对于增加新的产品类而言，这个系统完全支持开闭原则 工厂方法模式和下抽象工厂模式对比 工厂方法模式是一种极端情况的抽象工厂模式，而抽象工厂模式可以看成是工厂方法模式的推广。 工厂方法模式用来创建一个产品的等级结构，而抽象工厂模式是用来创建多个产品的等级结构。 工厂方法模式只有一个抽象产品类，而抽象工厂模式有多个抽象产品类。 工厂方法模式中具体工厂类只有一个创建方法，而抽象工厂模式中具体工厂类有多个创建方法。 Github源码 nezha的GitHub地址：(nezha/DesignPatterns)[https://github.com/nezha/DesignPatterns/tree/master/src/main/java/com/nezha/dp/Factory] 参考文献设计模式干货系列：（一）简单工厂模式 设计模式干货系列：（二）工厂方法模式【学习难度：★★☆☆☆，使用频率：★★★★★】 设计模式干货系列：（三）抽象工厂模式【学习难度：★★★★☆，使用频率：★★★★★】 交流或更多内容请关注我的公众号：nezha_blog 我的技术博客：https://nezha.github.io]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>工厂模式</tag>
        <tag>抽象工厂</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式学习笔记-观察者模式]]></title>
    <url>%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F2017-05-02-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[观察者模式 本文的源代码放在我的GitHub上：nezha/DesignPatterns 观察者模式是对象的行为模式，又叫发布-订阅(Publish/Subscribe)模式、模型-视图(Model/View)模式、源-监听器(Source/Listener)模式或从属者(Dependents)模式。 观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态上发生变化时，会通知所有观察者对象，使它们能够自动更新自己。 Java Messages Service(JMS)消息服务使用观察者模式与命令模式来实现不同的程序之间的数据的发布和订阅。 观察者模式的结构 Command + option + shift 观察者模式所涉及的角色有： 抽象主题(Subject)角色：抽象主题角色把所有对观察者对象的引用保存在一个聚集（比如ArrayList对象）里，每个主题都可以有任何数量的观察者。抽象主题提供一个接口，可以增加和删除观察者对象，抽象主题角色又叫做抽象被观察者(Observable)角色。 具体主题(ConcreteSubject)角色：将有关状态存入具体观察者对象；在具体主题的内部状态改变时，给所有登记过的观察者发出通知。具体主题角色又叫做具体被观察者(Concrete Observable)角色。 抽象观察者(Observer)角色：为所有的具体观察者定义一个接口，在得到主题的通知时更新自己，这个接口叫做更新接口。 具体观察者(ConcreteObserver)角色：存储与主题的状态自恰的状态。具体观察者角色实现抽象观察者角色所要求的更新接口，以便使本身的状态与主题的状态 像协调。如果需要，具体观察者角色可以保持一个指向具体主题对象的引用。 观察者模式例子1.抽象主题(Subject) 1234567public interface Subject &#123; //methods to register and unregister observers public void register(Observer obj); public void unregister(Observer obj); //method to notify observers of change public void notifyObservers();&#125; 2.具体主题(ConcreteSubject) 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class ConcreteSubject implements Subject &#123; private List&lt;Observer&gt; observers; private String message; private boolean changed; private final Object MUTEX= new Object(); public ConcreteSubject()&#123; this.observers=new ArrayList&lt;Observer&gt;(); &#125; @Override public void register(Observer obj) &#123; if(obj == null) throw new NullPointerException("Null Observer"); if(!observers.contains(obj)) observers.add(obj); &#125; @Override public void unregister(Observer obj) &#123; observers.remove(obj); &#125; @Override public void notifyObservers() &#123; List&lt;Observer&gt; observersLocal = null; //synchronization is used to make sure any observer registered after message is received is not notified synchronized (MUTEX) &#123; if (!changed) return; observersLocal = new ArrayList&lt;&gt;(this.observers); this.changed=false; &#125; for (Observer obj : observersLocal) &#123; obj.update("" + new Date() + "&gt;&gt;&gt;"+this.message); &#125; &#125; //method to post message to the topic public void postMessage(String msg)&#123; System.out.println("Message Posted to Subject:"+msg); this.message=msg; this.changed=true; notifyObservers(); &#125;&#125; 3.抽象观察者(Observer) 1234public interface Observer &#123; //method to update the observer, used by subject public void update(String content);&#125; 4.具体观察者(ConcreteObserver) 1234567891011121314151617public class ConcreteObserver implements Observer &#123; private String name; private Subject topic; private String content; public ConcreteObserver(Subject topic, String nm)&#123; this.name=nm; this.topic=topic; topic.register(this); &#125; @Override public void update(String content) &#123; this.content = content; System.out.println(name + this.getClass().getName() +"--- update the info:"+this.content); &#125;&#125; 5.测试实验 1234567891011121314151617public class ObserverPatternTest &#123; public static void main(String[] args) &#123; //create subject ConcreteSubject subject = new ConcreteSubject(); //create observers Observer obj1 = new ConcreteObserver(subject,"Obj1"); Observer obj2 = new ConcreteObserver(subject,"Obj2"); Observer obj3 = new ConcreteObserver(subject,"Obj3"); //now send message to subject subject.postMessage("New Message"); //这里是解绑某一个对象，主动权在subject手中 subject.unregister(obj2); subject.postMessage("将二号对象移除"); &#125;&#125; 参考文献http://ifeve.com/observer-design-pattern-in-java-example-tutorial/ 交流或更多内容请关注我的公众号：nezha_blog 我的技术博客：https://nezha.github.io]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>观察者模式</tag>
        <tag>订阅者模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring-boot分别集成JPA mybatis rabbitmq mongodb redis学习笔记]]></title>
    <url>%2FSpring-Boot%2F2017-04-29-spring-boot%E5%88%86%E5%88%AB%E9%9B%86%E6%88%90JPA_mybatis_rabbitmq_mongodb_redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[交流或更多内容请关注我的公众号：nezha_blog 我的技术博客：https://nezha.github.io 1. Spring Boot学习笔记–全注解方式 Spring Boot教程与Spring Cloud教程 2. pring boot中文帮助文档Spring Boot Reference Guide中文翻译 -《Spring Boot参考指南》—说明：本文档翻译的版本：1.4.1.RELEASE。 3. 常用注解 @RestController返回json形式的结果，便于前后端分离。是@ResponseBody 和 @Controller的组合体 @RequestMapping配置url映射 @EnableAutoConfiguration @Configuration @ComponentScan @SpringBootApplication 很多Spring Boot开发者总是使用 @Configuration ， @EnableAutoConfiguration 和 @ComponentScan 注解他们的main类。由于这些注解被如此频繁地一块使用（特别是你遵循以上最佳实践时），Spring Boot提供一个方便的 @SpringBootApplication 选择。 该 @SpringBootApplication 注解等价于以默认属性使用 @Configuration ， @EnableAutoConfiguration 和 @ComponentScan 。 12345678import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplication // same as @Configuration @EnableAutoConfiguration @ComponentScanpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; @ConfigurationProperties 属性注入,prefix指代注入的配置来自connection的对象 1234567@Component@ConfigurationProperties(prefix="connection")public class ConnectionSettings &#123; private String username; private InetAddress remoteAddress; // ... getters and setters&#125; 1234connection: name: 赵武 age: 18 job: Java研发工程师 为了使用@ConfigurationProperties beans，你可以使用与其他任何bean相同的方式注入它们 1234567891011@Servicepublic class MyService &#123; @Autowired private ConnectionSettings connection; //... @PostConstruct public void openConnection() &#123; Server server = new Server(); this.connection.configure(server); &#125;&#125; @EnableConfigurationProperties @Component和@Bean@Bean主要被用在方法上，来显式声明要用生成的类 @Profiles Spring Profiles提供了一种隔离应用程序配置的方式，并让这些配置只能在特定的环境下生效。 123spring: profiles: active: dev @Value 用于获取配置文件下的配置项 1234people: name: 赵武 age: 18 job: Java研发工程师 12@Value("$&#123;people.name&#125;")private String name; @Controller @PathVariable,@RequestParam@GetMapping,@PostMapping:Get 或Post方式的请求，组合模式 @PathVariable的使用，获取请求参数 1234@RequestMapping(value="/hello/&#123;id&#125;",method = RequestMethod.GET)public String sayhello(@PathVariable("id")Integer myid)&#123; return "id:"+myid;&#125; @RequestParam的使用，获取传统方式的参数 1234@RequestMapping(value="/hi",method = RequestMethod.GET)public String sayhi(@RequestParam(value = "id",required = false,defaultValue = "100")Integer myid)&#123; return "id:"+myid;&#125; 4. spring data JPA – 单数据源 具体的实现代码demo：Spring-Boot-Restful-JPA的demo程序 定义了对象持久化的标准，主要是对Hibernate的整合 现阶段发现和mybatis的直观操作很一致，都是可能集中管理数据库连接与释放，JPA想比较于mybatis可以自动建表，不知道算不算一种优势，在我看来不算是。毕竟表结构基本上数据库工程师都搞定了的事。 1.加入依赖 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.data&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;&lt;/dependency&gt; 2.配置数据库和JPA ddl-auto:创建的方式 12345678910spring: datasource: driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://127.0.0.1:3306/coder username: root password: root jpa: hibernate: ddl-auto: create show-sql: true 3.创建Mapper对象 @Entity: 持久化实例 @Table: 自定义表的名称 123456789101112131415161718192021222324252627282930313233343536@Entity//@Table(name = "programmer")public class Coder &#123; @Id @GeneratedValue(strategy = GenerationType.AUTO) private Integer id; private String name; private Integer age; public Coder()&#123; &#125; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125; 4.集成JpaRepository 主要是基于Hibernate的 1234public interface CoderRepository extends JpaRepository&lt;Coder,Integer&gt; &#123; //这个是扩展开来的查询方式 public List&lt;Coder&gt; findByAge(Integer age);&#125; 5.实现一个CoderController，实现增删改查。 1234567891011121314151617181920212223242526272829303132333435363738394041424344@RestControllerpublic class CoderController &#123; @Autowired private CoderRepository coderRepository; //1.Get方式请求，查询所有程序员信息 @GetMapping(value = "/coders") public List&lt;Coder&gt; coderList()&#123; return coderRepository.findAll(); &#125; //2.Post方式，增加程序员 @PostMapping(value = "/coders") public Coder CoderAdd(@RequestParam("name")String name,@RequestParam("age")Integer age)&#123; Coder coder = new Coder(); coder.setAge(age); coder.setName(name); return coderRepository.save(coder); &#125; //3.通过id查询一个人 @GetMapping(value = "/coders/&#123;id&#125;") public Coder CoderFindOne(@PathVariable("id")Integer id)&#123; return coderRepository.findOne(id); &#125; //4.通过id删除一个人 @DeleteMapping(value = "/coders/&#123;id&#125;") public void CoderDelete(@PathVariable("id")Integer id)&#123; coderRepository.delete(id); &#125; //5.更新一个人,用Postman模拟的时候注意：用x-www-form-urlencoded @PutMapping(value = "/coders/&#123;id&#125;") public Coder CoderUpdateOne(@PathVariable("id")Integer id, @RequestParam("name") String name, @RequestParam("age")Integer age)&#123; Coder coder = new Coder(); coder.setId(id); coder.setName(name); coder.setAge(age); return coderRepository.save(coder); &#125; //6.扩展Jpa接口，按照年龄查找 @GetMapping(value = "/coder/age/&#123;age&#125;") public List&lt;Coder&gt; CoderFindAll(@PathVariable("age")Integer age)&#123; return coderRepository.findByAge(age); &#125;&#125; 6.实现mysql的事务 首先新建一个Service类:CoderService 12345678910111213141516171819@Servicepublic class CoderService &#123; @Autowired CoderRepository coderRepository; @Transactional public void insertTwo()&#123; Coder coderA = new Coder(); coderA.setAge(101); coderA.setName("1"); coderRepository.save(coderA); Coder coderB = new Coder(); coderB.setAge(102); coderB.setName("102"); coderRepository.save(coderB); &#125;&#125; 在CoderController中自动载入coderService 12@Autowiredprivate CoderService coderService; 在CoderController调用service。 12345//7.使用事务，同时插入两个人的数据@PostMapping(value = "coder/two")public void coderTwo()&#123; coderService.insertTwo();&#125; 7.使用@Query实现自定义sql查询 在CoderRepository实现下面代码 12@Query("select p from Coder p where p.id = (select max(p2.id) from Coder p2)") Coder getMaxIdCoder(); 在CoderController中使用getMaxIdCoder方法 12345//8.自定义sql语句查询@GetMapping(value = "/coder/find")public Coder CoderFindByTask()&#123; return coderRepository.getMaxIdCoder();&#125; 5. Spring Boot MyBatis – 单数据源基于注解方式的Mybatis其实和JPA很类似，不过mybatis不提供自动创建表的操作。这点上jpa更好些。 我的demo程序，在我的github上：spring-boot-mybatis-mysql 引用博客：Spring Boot + MyBatis + MySQL 整合–简书 FlySheep_ly 程序员DD：Spring Boot整合MyBatis [Spring Boot中使用MyBatis注解配置详解](http://blog.didispace.com/mybatisinfo/) 1.引入依赖 123456789101112&lt;!-- 添加 MyBatis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.0&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 添加 MySQL --&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.41&lt;/version&gt;&lt;/dependency&gt; 2.application.properties中配置mysql的连接配置 1234spring.datasource.url=jdbc:mysql://localhost:3306/test01spring.datasource.username=rootspring.datasource.password=rootspring.datasource.driver-class-name=com.mysql.jdbc.Driver 3.创建映射对象User 关于序列化的实现，最好还是实现一下。 12345678910111213141516171819202122232425262728293031323334353637import java.io.Serializable;public class User implements Serializable&#123; private static final long serialVersionUID = -5554561712056198940L; private Long id; private String name; private Integer age; public User()&#123; &#125; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125; 4.创建User映射的操作UserMapper 关于Mapper的更多操作，请参考mybatis官网 1234567891011121314151617181920212223/** * Created by nezha on 2017/4/26. */@Mapperpublic interface UserMapper &#123; /** * 添加操作，返回新增元素的 ID * @param User */ @Insert("insert into person(name,age) values(#&#123;name&#125;,#&#123;age&#125;)") @Options(useGeneratedKeys = true, keyColumn = "id", keyProperty = "id") void insert(User user); /** * 查询所有 * @return */ @Select("select id,name,age from person") List&lt;User&gt; selectAll(); @Select("SELECT * FROM USER WHERE NAME = #&#123;name&#125;") User findByName(@Param("name") String name);&#125; 5.调用测试 发现Restful风格真是好习惯，很好用很实用。 123456789101112@EnableTransactionManagement@RestControllerpublic class TestController &#123; @Autowired private UserMapper userMapper; @GetMapping(value = "/test/&#123;name&#125;") public User findOne(@PathVariable("name")String name)&#123; return userMapper.findByName(name); &#125;&#125; 可能出现的问题： mybatis+spring boot, mapper 提示Could not autowire. 一直提示不能加载 解决方案 修改idea配置，将spring 的severity的值设置为”warning”, 如下： 如果想进一步缩小修改范围的话： 12Alt + Enter quick fix or change settingsSettings - Editor - Inspections - Spring - Spring Core - Code - Autowiring for Bean Class - warning 关于多源配置的问题：1.Spring Boot 整合 Mybatis 实现 Druid 多数据源详解 2.springboot+mybatis多数据源最简解决方案-springboot+mybatis%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90%E6%9C%80%E7%AE%80%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88.html) 6. Spring Boot RabbitMQ 我的demo程序：spring-boot-RabbitMQ Spring Boot RabbitMQ 入门–这篇文章写得不错,关于RabbitMQ的三种Exchange方式讲的很好。不过代码不是很简洁。 RabbitMQ详解-RabbitMQ详解.html)–纯洁的微笑的文章代码很简洁 安装与配置 翟永超-Spring boot系列教程 RabbitMQ的三种Exchange方式1.Direct Exchange 如果 routing key 匹配, 那么Message就会被传递到相应的queue中。其实在queue创建时，它会自动的以queue的名字作为routing key来绑定那个exchange。 2.Fanout Exchange 只需要简单的将队列绑定到交换机上。一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。Fanout交换机转发消息是最快的。 3.Topic Exchange 将路由键和某模式进行匹配。此时队列需要绑定要一个模式上。符号“#”匹配一个或多个词，符号“”匹配不多不少一个词。因此“audit.#”能够匹配到“audit.irs.corporate”，但是“audit.” 实例讲解 三种方式最主要的文件就三个： 1.sender的配置 2.receiver的配置 3.rabbitConfig的配置 下面，我们通过在Spring Boot应用中整合RabbitMQ，并实现一个简单的发送、接收消息的例子来对RabbitMQ有一个直观的感受和理解。 在Spring Boot中整合RabbitMQ是一件非常容易的事，因为之前我们已经介绍过Starter POMs，其中的AMQP模块就可以很好的支持RabbitMQ，下面我们就来详细说说整合过程： 1.pom依赖引入 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 2.连接配置 12345spring.application.name=rabbitmq-hellospring.rabbitmq.host=localhostspring.rabbitmq.port=5672spring.rabbitmq.username=guestspring.rabbitmq.password=guest 3.创建消息生产者Sender 创建消息生产者Sender。通过注入AmqpTemplate接口的实例来实现消息的发送，AmqpTemplate接口定义了一套针对AMQP协议的基础操作。在Spring Boot中会根据配置来注入其具体实现。在该生产者，我们会产生一个字符串，并发送到名为hello的队列中。 12345678910@Componentpublic class Sender &#123; @Autowired AmqpTemplate amqpTemplate; public void send() &#123; String context = "hello " + new Date(); System.out.println("Sender : " + context); this.amqpTemplate.convertAndSend("hello", context); &#125;&#125; 4.创建消息消费者Receiver 创建消息消费者Receiver。通过@RabbitListener注解定义该类对hello队列的监听，并用@RabbitHandler注解来指定对消息的处理方法。所以，该消费者实现了对hello队列的消费，消费操作为输出消息的字符串内容。 12345678@Component@RabbitListener(queues = "hello")public class Receiver &#123; @RabbitHandler public void process(String hello) &#123; System.out.println("Receiver1 : " + hello); &#125;&#125; 5.创建RabbitMQ的配置类RabbitConfig 创建RabbitMQ的配置类RabbitConfig，用来配置队列、交换器、路由等高级信息。这里我们以入门为主，先以最小化的配置来定义，以完成一个基本的生产和消费过程。 12345678910@Configurationpublic class RabbitConfig &#123; //1.配置一个名为hello的一对一的消息队列 @Bean public Queue helloQueue() &#123; return new Queue("hello"); &#125;&#125; 5.单元测试: 12345678910@RunWith(SpringJUnit4ClassRunner.class)@SpringApplicationConfiguration(classes = HelloApplication.class)public class HelloApplicationTests &#123; @Autowired private Sender sender; @Test public void hello() throws Exception &#123; sender.send(); &#125;&#125; 7. Spring Boot mongodb spring boot mongodb 的demo程序:spring-boot-mongodb 安装与配置 mongodb的安装与配置: CentOS 6.5下通过yum安装MongoDB记录 用户管理参考：mongodb 3.2 用户权限管理配置 Mac下的mongodb安装与配置: Mac 上安装MongoDB 1、进入mongodb的shell ： mongo 2、切换数据库： use admin 3、添加用户，指定用户的角色和数据库： 1234567891011db.createUser( &#123; user: &quot;admin&quot;, customData：&#123;description:&quot;superuser&quot;&#125;, pwd: &quot;admin&quot;, roles: [ &#123; role: &quot;userAdminAnyDatabase&quot;, db: &quot;admin&quot; &#125; ] &#125; ) user字段，为新用户的名字；pwd字段，用户的密码；cusomData字段，为任意内容，例如可以为用户全名介绍；roles字段，指定用户的角色，可以用一个空数组给新用户设定空角色。在roles字段,可以指定内置角色和用户定义的角色。 4、查看创建的用户 ： show users 或 db.system.users.find() 5、启用用户权限： 修改配置文件，增加配置： 123$ vim /etc/mongod.confsecurity: authorization: enabled 6.重新启动mongodb 1sudo service mongod restart 7.使用用户管理账户登录认证 12use admindb.auth(&apos;admin&apos;, &apos;admin&apos;) 8.远程登陆 1mongo 123.xxx.xxx.xxx:27017/amdin -uadmin -padmin 第一个admin:指代数据库第二个admin:指代用户名第三个admin:指代密码 spring boot 集成 mongodb1.引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-mongodb&lt;/artifactId&gt;&lt;/dependency&gt; 2.创建存储的实体 创建要存储的User实体，包含属性：id、username、age 12345678910111213141516171819202122232425262728293031323334353637383940414243public class User &#123; @Id private String id; private String username; private Integer age; public User(String username, Integer age) &#123;// this.id = id; this.username = username; this.age = age; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "username:"+username+"--age:"+age; &#125;&#125; 3.实现User的数据访问对象 实现User的数据访问对象：UserRepository 12345public interface UserRepository extends MongoRepository&lt;User, String&gt; &#123; User findByUsername(String username);&#125; 4.配置mongodb的连接 1234#mongodb3.X的配置spring.data.mongodb.uri=mongodb://admin:admin@123.206.xxx.xxx:27017/test#mongodb2.x的配置spring.data.mongodb.host=localhost spring.data.mongodb.port=27017 5.在单元测试中调用 1234567891011121314151617181920212223@RunWith(SpringRunner.class)@SpringBootTestpublic class Test05ApplicationTests&#123; @Autowired private UserRepository userRepository; @Test public void test() &#123; userRepository.deleteAll(); // 创建三个User，并验证User总数 userRepository.save(new User("didi", 30)); userRepository.save(new User("mama", 40)); userRepository.save(new User("kaka", 50)); Assert.assertEquals(3, userRepository.findAll().size()); // 删除一个User，再验证User总数 User u = userRepository.findByUsername("didi"); System.out.println(u.toString()); userRepository.delete(u); Assert.assertEquals(2, userRepository.findAll().size()); &#125;&#125; 出现的问题1.发现运行成功，但是查不到数据 主要是自己理解错误，mongodb数据库下还有collection(相当于表).然后针对每一个Database下可能有多个collection 8. Spring Boot redis redis的demo程序：nezha/spring-boot-redis redis的配置：CentOS6.5下Redis安装与配置 redis开启远程连接redis开启远程访问 redis远程连接redis-cli -h 123.206.xxx.xxx -p 6379 1.引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-redis&lt;/artifactId&gt;&lt;/dependency&gt; 2.参数配置 12345678910111213141516171819# REDIS (RedisProperties)# Redis数据库索引（默认为0）spring.redis.database=0# Redis服务器地址spring.redis.host=123.206.xxx.xxx# Redis服务器连接端口spring.redis.port=6379# Redis服务器连接密码（默认为空）spring.redis.password=# 连接池最大连接数（使用负值表示没有限制）spring.redis.pool.max-active=-1# 连接池最大阻塞等待时间（使用负值表示没有限制）spring.redis.pool.max-wait=-1# 连接池中的最大空闲连接spring.redis.pool.max-idle=16# 连接池中的最小空闲连接spring.redis.pool.min-idle=0# 连接超时时间（毫秒）spring.redis.timeout=0 3.测试访问 123456789101112131415@RunWith(SpringRunner.class)@SpringBootTestpublic class Test04ApplicationTests &#123; @Autowired StringRedisTemplate stringRedisTemplate; @Test public void test() throws Exception &#123; // 保存字符串 stringRedisTemplate.opsForValue().set("aaa", "111"); Assert.assertEquals("111", stringRedisTemplate.opsForValue().get("aaa")); &#125;&#125; 9. Spring Boot定时任务 定时任务demo程序:spring-boot-schedule 1.pom包配置 这部分基本的spring boot启动项就行，没有什么特别的依赖包 2.启动类启用定时 12345678@EnableScheduling@SpringBootApplicationpublic class ScheduleApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ScheduleApplication.class, args); &#125;&#125; 3.创建定时任务实现类 定时任务一 123456789101112/** * Created by nezha on 2017/4/28. */@Componentpublic class SchedulerTask &#123; private int count = 0; @Scheduled(cron="*/6 * * * * ?") private void process()&#123; System.out.println("this is scheduler task runing "+(count++)); &#125;&#125; 定时任务二 123456789101112/** * Created by nezha on 2017/4/28. */@Componentpublic class SchedulerTask2 &#123; private static SimpleDateFormat dateFormat = new SimpleDateFormat("HH:mm:ss"); @Scheduled(fixedRate = 6000) public void reportCurrentTime() &#123; System.out.println("现在时间：" + dateFormat.format(new Date())); &#125;&#125; 4.参数说明 @Scheduled 参数可以接受两种定时的设置，一种是我们常用的cron=&quot;*/6 * * * * ?&quot;,一种是 fixedRate = 6000，两种都表示每隔六秒打印一下内容。 fixedRate 说明 @Scheduled(fixedRate = 6000) ：上一次开始执行时间点之后6秒再执行 @Scheduled(fixedDelay = 6000) ：上一次执行完毕时间点之后6秒再执行 @Scheduled(initialDelay=1000, fixedRate=6000) ：第一次延迟1秒后执行，之后按fixedRate的规则每6秒执行一次 10. Spring Boot相关技术自定义图标Spring Boot自定义Banner—自定义图标 部署spring项目1.IntelliJ Idea中直接运行 2.mvn spring-boot:run 3.mvn install &gt;&gt;&gt; 会生成jar文件，执行jar文件。 spring boot测试的时候，怎么单元测试1.使用@SpringBootTest文件主要实在test目录下 123456789101112131415@RunWith(SpringRunner.class)@SpringBootTestpublic class Test05ApplicationTests&#123; @Autowired private UserRepository userRepository; @Test public void test() &#123; userRepository.deleteAll(); // 创建三个User，并验证User总数 userRepository.save(new User("didi", 30)); userRepository.save(new User("mama", 40)); userRepository.save(new User("kaka", 50)); &#125;&#125; 2.使用@SpringBootApplication 在主目录下com.nezha/ 123456789101112131415@SpringBootApplicationpublic class Application implements CommandLineRunner &#123; @Autowired private CustomerRepository repository; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Override public void run(String... args) throws Exception &#123; repository.deleteAll(); // save a couple of customers repository.save(new Customer("Alice", "Smith")); repository.save(new Customer("Bob", "Smith")); &#125;&#125; 3.使用RestController 这种方式很方便，很好用，有些时候我会用。]]></content>
      <categories>
        <category>Spring Boot</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
        <tag>Spring Jpa</tag>
        <tag>mybatis</tag>
        <tag>rabbitmq</tag>
        <tag>mongodb</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jupyter Notebook的使用总结]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2017-01-05-Jupyter%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[Jupyter Notebook的使用总结1.Jupyter Notebook 的快捷键Jupyter Notebook 有两种键盘输入模式。编辑模式，允许你往单元中键入代码或文本；这时的单元框线是绿色的。命令模式，键盘输入运行程序命令；这时的单元框线是灰色。 1.1命令模式 (按键 Esc 开启) Enter : 转入编辑模式 Shift-Enter : 运行本单元，选中下个单元 Ctrl-Enter : 运行本单元 Alt-Enter : 运行本单元，在其下插入新单元 Y : 单元转入代码状态 M :单元转入markdown状态 R : 单元转入raw状态 1 : 设定 1 级标题 2 : 设定 2 级标题 3 : 设定 3 级标题 4 : 设定 4 级标题 5 : 设定 5 级标题 6 : 设定 6 级标题 Up : 选中上方单元 K : 选中上方单元 Down : 选中下方单元 J : 选中下方单元 Shift-K : 扩大选中上方单元 Shift-J : 扩大选中下方单元 A : 在上方插入新单元 B : 在下方插入新单元 X : 剪切选中的单元 C : 复制选中的单元 Shift-V : 粘贴到上方单元 V : 粘贴到下方单元 Z : 恢复删除的最后一个单元 D,D : 删除选中的单元 Shift-M : 合并选中的单元 Ctrl-S : 文件存盘 S : 文件存盘 L : 转换行号 O : 转换输出 Shift-O : 转换输出滚动 Esc : 关闭页面 Q : 关闭页面 H : 显示快捷键帮助 I,I : 中断Notebook内核 0,0 : 重启Notebook内核 Shift : 忽略 Shift-Space : 向上滚动 Space : 向下滚动 1.2编辑模式 ( Enter 键启动) Tab : 代码补全或缩进 Shift-Tab : 提示 Ctrl-] : 缩进 Ctrl-[ : 解除缩进 Ctrl-A : 全选 Ctrl-Z : 复原 Ctrl-Shift-Z : 再做 Ctrl-Y : 再做 Ctrl-Home : 跳到单元开头 Ctrl-Up : 跳到单元开头 Ctrl-End : 跳到单元末尾 Ctrl-Down : 跳到单元末尾 Ctrl-Left : 跳到左边一个字首 Ctrl-Right : 跳到右边一个字首 Ctrl-Backspace : 删除前面一个字 Ctrl-Delete : 删除后面一个字 Esc : 进入命令模式 Ctrl-M : 进入命令模式 Shift-Enter : 运行本单元，选中下一单元 Ctrl-Enter : 运行本单元 Alt-Enter : 运行本单元，在下面插入一单元 Ctrl-Shift– : 分割单元 Ctrl-Shift-Subtract : 分割单元 Ctrl-S : 文件存盘 Shift : 忽略 Up : 光标上移或转入上一单元 Down :光标下移或转入下一单元 参考：【1】：Jupyter Notebook 的快捷键]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Jupyter</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式学习笔记-单例模式]]></title>
    <url>%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%2F2016-12-17-%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式的学习与理解 单例模式算是设计模式中最容易理解，也是最容易手写代码的模式了吧。但是其中的坑却不少，所以也常作为面试题来考。本文主要对几种单例写法的整理，并分析其优缺点。很多都是一些老生常谈的问题，但如果你不知道如何创建一个线程安全的单例，不知道什么是双检锁，那这篇文章可能会帮助到你。 单例模式中，主要的技巧是： 1.将构造函数标为私有类型，然后就不能通过构造方法创建实例了 2.当然还是需要创建实例的，那就声明一个静态类变量 3.然后外部当需要获取实例的时候就通过公有类型的静态类方法获取静态类实例 1.懒汉模式当被问到要实现一个单例模式时，很多人的第一反应是写出如下的代码，包括教科书上也是这样教我们的。 12345678910public class Singleton &#123; private static Singleton instance; private Singleton( )&#123; &#125; public static Singleton getInstance()&#123; if(instance == null)&#123; instance = new Singleton(); &#125; return instance; &#125;&#125; 这段代码简单明了，而且使用了懒加载模式，但是却存在致命的问题。当有多个线程并行调用 getInstance() 的时候，就会创建多个实例。也就是说在多线程下不能正常工作。 2.饿汉模式这种方法非常简单，因为单例的实例被声明成 static 和 final 变量了，在第一次加载类到内存中时就会初始化，所以创建实例本身是线程安全的。 12345678public class SingletonUrge &#123; //创建类的时候就会执行这句话 private static final SingletonUrge instance = new SingletonUrge(); private SingletonUrge()&#123;&#125; public static SingletonUrge getInstance()&#123; return instance; &#125;&#125; 这种写法如果完美的话，就没必要在啰嗦那么多双检锁的问题了。缺点是它不是一种懒加载模式（lazy initialization），单例会在加载类后一开始就被初始化，即使客户端没有调用 getInstance()方法。饿汉式的创建方式在一些场景中将无法使用：譬如 Singleton 实例的创建是依赖参数或者配置文件的，在 getInstance() 之前必须调用某个方法设置参数给它，那样这种单例写法就无法使用了。 3.加同步锁为了解决懒汉模式下的问题，最简单的方法是将整个 getInstance() 方法设为同步（synchronized）。 12345678910public class SingletonSync &#123; private static SingletonSync instance; private SingletonSync()&#123;&#125; public synchronized static SingletonSync getInstance()&#123; if (null == instance) &#123; instance = new SingletonSync(); &#125; return instance; &#125;&#125; 虽然做到了线程安全，并且解决了多实例的问题，但是它并不高效。因为在任何时候只能有一个线程调用 getInstance() 方法。但是同步操作只需要在第一次调用时才被需要，即第一次创建单例实例对象时。这就引出了双重检验锁。 4.双重验证机制双重检验锁模式（double checked locking pattern），是一种使用同步块加锁的方法。程序员称其为双重检查锁，因为会有两次检查 null == instance，一次是在同步块外，一次是在同步块内。为什么在同步块内还要再检验一次？因为可能会有多个线程一起进入同步块外的if，如果在同步块内不进行二次检验的话就会生成多个实例了。 1234567891011121314public class SingletonDauth &#123; private volatile static SingletonDauth instance; private SingletonDauth()&#123;&#125; public static SingletonDauth getInstance()&#123; if (null == instance) &#123; synchronized (SingletonDauth.class)&#123; if (null == instance)&#123; instance = new SingletonDauth(); &#125; &#125; &#125; return instance; &#125;&#125; 这段代码看起来很完美，很可惜，它是有问题。主要在于instance = new Singleton()这句，这并非是一个原子操作，事实上在 JVM 中这句话大概做了下面 3 件事情。 给 instance 分配内存 调用 Singleton 的构造函数来初始化成员变量 将instance对象指向分配的内存空间（执行完这步 instance 就为非 null 了） 但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非null了（但却没有初始化），所以线程二会直接返回instance，然后使用，然后顺理成章地报错。 我们只需要将 instance 变量声明成 volatile就可以了。 5.静态内部类我比较倾向于使用静态内部类的方法，这种方法也是《Effective Java》上所推荐的。 123456789public class SingletonInnerclass &#123; private static class SingletonHolder&#123; public static SingletonInnerclass instance = new SingletonInnerclass(); &#125; private SingletonInnerclass()&#123;&#125; public static SingletonInnerclass getInstance()&#123; return SingletonHolder.instance; &#125;&#125; 这种写法仍然使用JVM本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它是懒汉式的；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。 6.枚举型通过enum关键字来实现枚举，在枚举中需要注意的有： 1.枚举中的属性必须放在最前面，一般使用大写字母表示 2.枚举中可以和java类一样定义方法 3.枚举中的构造方法必须是私有的 12345678910111213141516public class Resource&#123; //这里就是需要存放的单例资源 public Resource()&#123; &#125;&#125;public enum Singleton&#123; INSTANCE; private Resource instance = null; private Singleton()&#123; instance = new Resource(); &#125; public Resource getInstance() &#123; return instance; &#125;&#125; 默认枚举实例的创建是线程安全的.(创建枚举类的单例在JVM层面也是能保证线程安全的),这个优秀的思想直接源于Joshua Bloch的《Effective Java》（《Java高效编程指南》）。 所以不需要担心线程安全的问题 这里有几个原因关于为什么在Java中宁愿使用一个枚举量来实现单例模式： 1、 自由序列化； 2、 保证只有一个实例（即使使用反射机制也无法多次实例化一个枚举量）； 3、 线程安全 Junit测试下面是构建了一个maven项目，然后将设计模式的程序进行分析学习。之后将会把程序源码放到我的github上。 Java代码测试如下 12345678910111213import org.junit.Test;public class AppTest&#123; @Test public void test()&#123; Singleton singleton1 = Singleton.getInstance(); Singleton singleton2 = Singleton.getInstance(); System.out.println("Singleton Test"+singleton1.hashCode()+"and"+singleton2.hashCode()); SingletonInnerclass singleton3 = SingletonInnerclass.getInstance(); SingletonInnerclass singleton4 = SingletonInnerclass.getInstance(); System.out.print("SingletonInnerclass Test"+singleton3.hashCode()+"and"+singleton4.hashCode()); &#125;&#125; maven配置如下 12345678910111213141516171819202122232425&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.nezha.dp&lt;/groupId&gt; &lt;artifactId&gt;dp&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;dp&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/junit/junit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt; 参考文献[1] http://blog.csdn.net/goodlixueyong/article/details/51935526 [2] Freeman E, Freeman E, Sierra K, et al. Head First 设计模式[J]. 2007. [3] http://wuchong.me/blog/2014/08/28/how-to-correctly-write-singleton-pattern/ 交流或更多内容请关注我的公众号：nezha_blog 我的技术博客：https://nezha.github.io]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>单例模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最小二乘法的公式推导及python实战]]></title>
    <url>%2F%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%2F2016-10-26-%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E7%9A%84%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC%E5%8F%8Apython%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[最小二乘法的公式推导及python实战 在基于传播模型法定位中，最常用的定位算法就是最小二乘法，当然还有加权最小二乘法或其他类似算法，下面将介绍最小二乘法的使用步骤，其他算法请自行查阅相关论文。 最小二乘法的公式推导首先如上图所示：A,B,C点是基站的位置-也可以理解为信号源的位置。D点是用户的位置，需要我们计算出来，此时至少需要三个信号源同时参与定位才能实现用户的位置定位。首先我们假设用户所在位置D的坐标为：$(x,y)$然后A,B,C三个信号源的坐标为$(x{i},y{i})$然后A,B,C与D点的距离可以表示为：（这里的距离其实是已知的，因为可以通过信号传播模型获取到，先不管继续推导）这里我们定位$K{i} = x{i}^{2} + y{i}^{2}$然后我们继续定义$r{i,1}$这展开就是：然后我们就可以得出：展开就是：将上一条公式与第一条公式结合：这里$x{i,1}$和$y{i,1}$指代的是：$x{i}-x{1}$和$y{i}-y{1}$,将$r_{1}$,$x$和$y$移到一边公式展开后即：上面的公式可以简单的表示为：所以最终的结果可以计算出来了： 最小二乘法的python实战1234567891011121314151617181920212223242526272829303132###最小二乘法试验###import numpy as npfrom scipy.optimize import leastsq###采样点(Xi,Yi) &gt;&gt;&gt;此处可以改成信号源的坐标集###Xi=np.array([0,1,2,3,-1,-2,-3])Yi=np.array([-1.21,1.9,3.2,10.3,2.2,3.71,8.7])###代价函数###def error(p,x,y): a,b,c=p return a*x**2+b*x+c-y #x、y都是列表，故返回值也是个列表#TESTp0=[5,2,10]###主函数从此开始####试验最小二乘法函数leastsq得调用几次error函数才能找到使得均方误差之和最小的a~cPara=leastsq(error,p0,args=(Xi,Yi)) #把error函数中除了p以外的参数打包到args中a,b,c=Para[0]print"a=",a,'\n',"b=",b,"c=",c###绘图，看拟合效果###import matplotlib.pyplot as pltplt.figure(figsize=(8,6))plt.scatter(Xi,Yi,color="red",label="Sample Point",linewidth=3) #画样本点x=np.linspace(-5,5,1000)y=a*x**2+b*x+cplt.plot(x,y,color="orange",label="Fitting Curve",linewidth=2) #画拟合曲线plt.legend()plt.show() 参考：[1]：最小二乘法介绍 [2]：[最小二乘法的WiKi引文]https://zh.wikipedia.org/wiki/%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95]]></content>
      <categories>
        <category>科学计算</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>最小二乘法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kalman滤波的理解与使用]]></title>
    <url>%2F%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%2F2016-10-10-kalman%E6%BB%A4%E6%B3%A2%E7%9A%84%E7%90%86%E8%A7%A3%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[kalman滤波的理解与使用kalman 滤波原理kalman 滤波效果演示kalman filter 程序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import numpy as npimport matplotlib.pyplot as pltplt.rcParams['figure.figsize'] = (10, 8)# intial parametersn_iter = 50sz = (n_iter,) # size of arrayx = -0.37727 # truth value (typo in example at top of p. 13 calls this z)z = np.random.normal(x,0.1,size=sz) # observations (normal about x, sigma=0.1)Q = 1e-5 # process variance# allocate space for arraysxhat=np.zeros(sz) # a posteri estimate of xP=np.zeros(sz) # a posteri error estimatexhatminus=np.zeros(sz) # a priori estimate of xPminus=np.zeros(sz) # a priori error estimateK=np.zeros(sz) # gain or blending factorR = 0.1**2 # estimate of measurement variance, change to see effect# intial guessesxhat[0] = 0.0P[0] = 1.0for k in range(1,n_iter): # time update xhatminus[k] = xhat[k-1] Pminus[k] = P[k-1]+Q # measurement update K[k] = Pminus[k]/( Pminus[k]+R ) xhat[k] = xhatminus[k]+K[k]*(z[k]-xhatminus[k]) P[k] = (1-K[k])*Pminus[k]plt.figure()plt.plot(z,'k+',label='noisy measurements')plt.plot(xhat,'b-',label='a posteri estimate')plt.axhline(x,color='g',label='truth value')plt.legend()plt.title('Estimate vs. iteration step', fontweight='bold')plt.xlabel('Iteration')plt.ylabel('Voltage')plt.figure()valid_iter = range(1,n_iter) # Pminus not valid at step 0plt.plot(valid_iter,Pminus[valid_iter],label='a priori error estimate')plt.title('Estimated $\it&#123;\mathbf&#123;a \ priori&#125;&#125;$ error vs. iteration step', fontweight='bold')plt.xlabel('Iteration')plt.ylabel('$(Voltage)^2$')plt.setp(plt.gca(),'ylim',[0,.01])plt.show() 效果图 参考：[1]：kalman Filter intro [2]：http://blog.csdn.net/xiahouzuoxin/article/details/39582483 [3]：Understanding the Basis of the Kalman Filter Via a Simple and Intuitive Derivation]]></content>
      <categories>
        <category>科学计算</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>滤波算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pybrain初入门]]></title>
    <url>%2F%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%2F2016-09-11-pybrain%E5%88%9D%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[pybrain初入门 标准的官方网址：http://pybrain.org/ 在python语言中自己实现神经网络的所有代码很复杂，但是有了pybrain就容易的多了，我们只需要专注于算法本身，而忽略算法的繁琐细节 pybrain的介绍 基本流程 1.构造神经网络 2.构造数据集 3.训练神经网络 4.结果可视化 5.验证与分析 pybrain使用入门 参考文献: 下面的基本用法将逐步的完善补充，主要还是根据自己的学习进度进行推进 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119#coding=utf-8import numpy as npdef generate_data(): """generate original data of u and y""" u = np.random.uniform(-1,1,200) y=[] former_y_value = 0 for i in np.arange(0,200): y.append(former_y_value) next_y_value = (29 / 40) * np.sin( (16 * u[i] + 8 * former_y_value) / (3 + 4 * (u[i] ** 2) + 4 * (former_y_value ** 2))) \ + (2 / 10) * u[i] + (2 / 10) * former_y_value former_y_value = next_y_value return u,y#大概分为以下这几步。# 构造神经网络# 构造数据集# 训练神经网络# 结果可视化# 验证与分析#1.构造神经网络from pybrain.structure import *# 建立神经网络fnnfnn = FeedForwardNetwork()# 设立三层，一层输入层（3个神经元，别名为inLayer），一层隐藏层，一层输出层inLayer = LinearLayer(2, name='inLayer')hiddenLayer = SigmoidLayer(10, name='hiddenLayer0')outLayer = LinearLayer(1, name='outLayer')# 将三层都加入神经网络（即加入神经元）fnn.addInputModule(inLayer)fnn.addModule(hiddenLayer)fnn.addOutputModule(outLayer)# 建立三层之间的连接in_to_hidden = FullConnection(inLayer, hiddenLayer)hidden_to_out = FullConnection(hiddenLayer, outLayer)# 将连接加入神经网络fnn.addConnection(in_to_hidden)fnn.addConnection(hidden_to_out)# 让神经网络可用fnn.sortModules()#2.构造数据集#在构造数据集的时候，我用的是SupervisedDataset，即监督数据集。也可以试一试别的。from pybrain.supervised.trainers import BackpropTrainerfrom pybrain.datasets import SupervisedDataSet# 定义数据集的格式是三维输入，一维输出DS = SupervisedDataSet(2,1)# 往数据集内加样本点# 假设x1，x2，x3是输入的三个维度向量，y是输出向量，并且它们的长度相同u,y = generate_data()for i in np.arange(199): DS.addSample([u[i], y[i]], [y[i+1]])# 如果要获得里面的输入／输出时，可以用X = DS['input']Y = DS['target']# print(X,Y)# 如果要把数据集切分成训练集和测试集，可以用下面的语句，训练集：测试集＝8:2# 为了方便之后的调用，可以把输入和输出拎出来dataTrain, dataTest = DS.splitWithProportion(0.8)xTrain, yTrain = dataTrain['input'], dataTrain['target']xTest, yTest = dataTest['input'], dataTest['target']# print dataTest# 3.训练神经网络#俗话说得好，80%的工作往往是20%的部分完成的。嗯哼，其实最重要的代码就是如下这几行啦。# 不过调用的是别人的东西，也不知道内部的实现比例，就是开个玩笑。from pybrain.supervised.trainers import BackpropTrainer# 训练器采用BP算法# verbose = True即训练时会把Total error打印出来，库里默认训练集和验证集的比例为4:1，可以在括号里更改trainer = BackpropTrainer(fnn, dataTrain, verbose = False, learningrate=0.01)# maxEpochs即你需要的最大收敛迭代次数，这里采用的方法是训练至收敛，我一般设为1000trainer.trainUntilConvergence(maxEpochs=1000)#4.结果可视化# 数据可视化就不提了，基本上用的是Pylab来进行数据可视化#5.验证与分析import matplotlib.pyplot as pltpredict_resutl=[]for i in np.arange(len(xTest)): predict_resutl.append(fnn.activate(xTest[i])[0])print(predict_resutl)plt.figure()plt.plot(np.arange(0,len(xTest)), predict_resutl, 'ro--', label='predict number')plt.plot(np.arange(0,len(xTest)), yTest, 'ko-', label='true number')plt.legend()plt.xlabel("x")plt.ylabel("y")plt.show()for mod in fnn.modules: print "Module:", mod.name if mod.paramdim &gt; 0: print "--parameters:", mod.params for conn in fnn.connections[mod]: print "-connection to", conn.outmod.name if conn.paramdim &gt; 0: print "- parameters", conn.params if hasattr(fnn, "recurrentConns"): print "Recurrent connections" for conn in fnn.recurrentConns: print "-", conn.inmod.name, " to", conn.outmod.name if conn.paramdim &gt; 0: print "- parameters", conn.params 机器学习相关的库 scikit_learn 机器学习方面的库 pandas 处理数据文本用 tensorflow 谷歌的深度学习，神经网络库 pybrain 机器学习中神经网络的库 NLTK 自然语言处理 xgboost 预测模型 参考：]]></content>
      <categories>
        <category>科学计算</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux常见函数]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2016-08-31-Linux%E5%B8%B8%E8%A7%81%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[Linux常见函数1.curl命令使用 - 请求数据包 学习网站一： curl命令详解 访问GET方式的页面,请求后将数据返回出来 1curl -i 'http://www.iheima.com/?page=2&amp;category=%E5%85%A8%E9%83%A8' 访问POST方式的页面,然后加入头文件 1curl -i 'http://person.sac.net.cn/pages/registration/train-line-register!orderSearch.action' -d 'filter_EQS_OTC_ID=10&amp;ORDERNAME=AOI#AOI_NAME&amp;ORDER=ASC&amp;sqlkey=registration&amp;sqlval=SELECT_LINE_PERSON' 加入头信息的请求 1curl -i 'http://www.iheima.com/?page=2&amp;category=%E5%85%A8%E9%83%A8' -H 'X-Requested-With:XMLHttpRequest' 2.linux和windows之间传文件 rz和sz在window的系统中很好用，scp和ftp在linux之间可以考虑 12rz -y #windows上传文件到linuxsz db_script.tar.gz #从linux中下载文件到linux 3.kill命令杀死进程123killall -9 python #按照进程类型杀程序kill -9 18040 #按照进程号杀死进程 4.ps命令查看进程1ps -aux | grep python 5.crontab执行定制脚本 有些时候需要定时的去执行某一段脚本 121. crontab -l2. crontab --help 6.获取当前的周数1date +%W 7.解压包命令12tar zcvf db_script.tar.gz db_script/ #解压命令sz db_script.tar.gz #打包命令 连接mongo1mongo ccinfo -uccinfoadm -p8EBDB935F8B30DA2 连接Redis1[root@CentOS-31 zhangyi]# redis-cli -p 6401]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python常用函数积累]]></title>
    <url>%2Fpython%2F2016-08-24-python%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E7%A7%AF%E7%B4%AF%2F</url>
    <content type="text"><![CDATA[python常用函数积累 python提供了相当丰富的函数库，没有做不到，只有想不到。而往往就是因为想不到在哪有适当的函数将简单问题复杂化的。再接触python这么久之后，我发现真的不要什么IDE记事本足已，然后Ipython是个神器，多用它！ python numpy包的使用 Numpy 是高性能科学计算和数据分许的基础包，它部分功能如下：ndarray，一个具有矢量算术运算的快速且节省空间的多维数组用于对整组数据进行快速运算而不要编写循环的标准数学函数线性代数，随机数生成及傅立叶变化功能用于读写磁盘数据的工具 matrix学习理解12345import numpy as np#1.生成随机数组array_data = np.random.randn(5,3)#2.转换成矩阵matrix_data = np.matrix(array_data) 随机函数的运用 函数 说明 seed 确定随机生成数的种子 rand 产生均匀分布的样本值 randint 从给定的上下限范围内随机选取整数 randn 产生正态分布的样本值 normal 产生正态/高斯分布的样本值 uniform 产生在[0,1]中均匀分布的样本值 binomial 产生二项分布的样本值 gamma 产生Gamma分布的样本值 shuffle 对一个序列就地随机排列 permutation 返回一个序列的随机排列 求均值方差123import numpy as nppos = np.random.randn(5,2) #按列求方差 对于位置坐标获取X和Y轴的列集合1234Loc_sample_matrix = np.matrix(Loc_sample).getH()print Loc_sample_matrix.shapeprint Loc_sample_matrixplt.plt_line(Loc_sample_matrix[0], Loc_sample_matrix[1]) 两个坐标位置间的距离12345result_location = [0,0]true_location = np.array([5,5])result_location = np.array(result_location)vector_dis = true_location - result_locationdis_std = np.sqrt(np.dot(vector_dis.T,vector_dis)) 提取特定精度的数字 很多时候浮点数强制转换会有精度损失的，所以需要保留一定的精度 12#将array类型转成list用tolist()函数不会有精度损失Number = np.round(raw,2).tolist() python pandas的使用 它使含有数据分析工作变得更快更简单，pandas是基于numpy构建的。我已经整理过的函数有：pd.read_excel,pd.DataFrame.sort,pd.read_csv,df.reset_index,df.isin read_excel函数的使用 参考文献: pandas API文档 123import pandas as pd#读取excel文件，并且指定某一页，如果有中文的情况可以转成unicode编码，data的类型是dataframe类型的data = pd.read_excel('../data1wuhan.xls',sheetname=u'sheet1') DataFrame的理解12345678910111213141516171819202122232425262728293031323334353637383940414243#1.读取指定位置的数据specific_data1 = data.loc[0:10,['PM10','PM2.5']]specific_data2 = data.PM10[0:10]specific_data3 = data['PM10'] #取出的一列数据到Series类型中specific_data4 = data[['PM10','SO2']] #2.如何删除指定的列？del(data['NO2'])#3.获取列数col_size = data.columns.size#4.将Dataframe转换成矩阵形势import numpy as nparray_data = np.random.randn(5,3)frame_data = pd.DataFrame(array_data)frame_data.as_matrix()#转化成numpy中的数组了#5.索引一条记录或几条记录：data[1:3]#6.DataFrame按照某一列排序data = frame_data.sort('sche_all_rest',ascending=1)help(frame_data.sort)#7.按照某一属性大小取整个数据集data[data['Col_Name']&gt;0]#8.如何按照list中的条件，整体的从DataFrame中寻找到数据, http://stackoverflow.com/questions/40999119/how-to-find-data-from-dataframe-at-a-time-when-the-condition-is-a-listcondition = [2,4,6,8]df[df["1"].isin(condition)].index#index是将索引的索引返回出来#9.DataFrame怎么按照条件获取索引位置, http://stackoverflow.com/questions/37502298/python-pandas-get-index-from-column-value?noredirect=1&amp;lq=1df.index.get_loc('2016-04-14')#10.按照顺序将DataFrame的索引重新排序df.reset_index()#11.如何按照自己的索引创建DataFramedata = [[1,2,3],[4,5,6]] index = ['d','e'] columns=['a','b','c'] df = pd.DataFrame(data=data, index=index, columns=columns) ###pandas csv的读写 1234#1.读取csv文件data = pd.read_csv('file_path',names=['xx','xx'])#header=None#2.将DataFrame格式的数据写入到csv文件中，以','为分隔符data.to_csv('./ans1_11_schemes.csv') #sep='|' pandas 数据预处理-处理缺失值 缺失值填充的方法 有缺失值的时候处理 1.先来创建一个带有缺失值的DataFrame: 1234567import pandas as pd import numpy as np df=pd.DataFrame(np.random.randn(5,3),index=list('abcde'),columns=['one','two','three']) df=pd.DataFrame(np.random.randn(5,3),index=list('abcde'),columns=['one','two','three']) df.ix[1,:-1]=np.nan df.ix[1:-1,2]=np.nan df 2.使用0替代缺失值（当然你可以用任意一个数字代替NaN） 1df.fillna(0) 3.用一个字符串代替缺失值 1df.fillna('missing') 4.用前一个数据代替NaN：method=’pad’ 1df.fillna(method='pad') 5.与pad相反，bfill表示用后一个数据代替NaN。这里我们增加一个知识点，用limit限制每列可以替代NaN的数目，下面我们限制每列只能替代一个NaN 1df.fillna(method='bfill',limit=1) 6.除了上面用一个具体的值来代替NaN之外，还可以使用平均数或者其他描述性统计量来代替NaN 1df.fillna(df.mean()) 7.最后，我们还可以选择哪一列进行缺失值的处理。 1df.fillna(df.mean()['one':'two']) 8.查找缺失值 1df.isnull() 9.滤除缺失数据 1df.dropna() 10.去除特定列的缺失数据 1df.dropna(subset=[['one',"two"]]) python collections使用 参考文献1：廖雪峰的官方网站参考文献2：不可不知的Python模块: collections Counter计数器 Counter可以迅速的统计出字符串或list中item的出现次数 代码 12345678&gt;&gt;&gt; Counter('abcdeabcdabcaba').most_common(3)[('a', 5), ('b', 4), ('c', 3)]&gt;&gt;&gt; Counter([1,2,3,3,1,2,3,1,2,3]).most_common(2)[(3, 4), (1, 3)]&gt;&gt;&gt; Counter('123234567')Counter(&#123;'3': 2, '2': 2, '1': 1, '5': 1, '4': 1, '7': 1, '6': 1&#125;)&gt;&gt;&gt; Counter(['aa','bb','cc','aa']).most_common(2)[('aa', 2), ('cc', 1)] defaultdict带有默认值的字典 我们都知道，在使用Python原生的数据结构dict的时候，如果用 d[key]`` 这样的方式访问， 当指定的key不存在时，是会抛出KeyError异常的。 &lt;br&gt; 但是，如果使用defaultdict，只要你传入一个默认的工厂方法，那么请求一个不存在的key时， 便会调用这个工厂方法使用其结果来作为这个key`的默认值。 1234567891011121314151617181920# -*- coding: utf-8 -*-from collections import defaultdictmembers = [ # Age, name ['male', 'John'], ['male', 'Jack'], ['female', 'Lily'], ['male', 'Pony'], ['female', 'Lucy'],]result = defaultdict(list)for sex, name in members: result[sex].append(name)print result# Result:defaultdict(&lt;type 'list'&gt;, &#123;'male': ['John', 'Jack', 'Pony'], 'female': ['Lily', 'Lucy']&#125;) python scipy的使用SciPy解决的问题还是很多的，主要的功能如下 功能 常数和特殊函数 优化问题—optimize 插值—interpolate 数值积分—integrate 信号处理—signal 图像处理—ndimage 统计—stats 1.优化问题—optimize1.scipy.optimize.linprog 求解线性规划问题 scipy.optimize.linprog(c, A_ub=None, b_ub=None, A_eq=None, b_eq=None, bounds=None, method=&#39;simplex&#39;, callback=None, options=None)[source] Example: http://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.optimize.linprog.html 假设有如下的问题: Minimize: f = -1*x[0] + 4*x[1] 约束条件是: -3*x[0] + 1*x[1] &lt;= 6 1*x[0] + 2*x[1] &lt;= 4 x[1] &gt;= -3 where: -inf &lt;= x[0] &lt;= inf 1234567891011121314151617&gt;&gt;&gt; c = [-1, 4]&gt;&gt;&gt; A = [[-3, 1], [1, 2]]&gt;&gt;&gt; b = [6, 4]&gt;&gt;&gt; x0_bounds = (None, None)&gt;&gt;&gt; x1_bounds = (-3, None)&gt;&gt;&gt; res = linprog(c, A_ub=A, b_ub=b, bounds=(x0_bounds, x1_bounds),... options=&#123;"disp": True&#125;)&gt;&gt;&gt; print(res)Optimization terminated successfully. Current function value: -11.428571 Iterations: 2status: 0success: Truefun: -11.428571428571429x: array([-1.14285714, 2.57142857])message: 'Optimization terminated successfully.'nit: 2 2.插值—interpolate 插值法在补全数据方面是很有用的，当数据不是完整的情况下有效的根据数据变化趋势相应的进行插值是一个需要研究的问题。现在主要的插值法主要有拉格朗日插值法和牛顿插值法等，python中主要介绍的拉格朗日插值法 3.常用函数或特殊函数1.Matlab中.mat文件的读写 12345import scipy.io as sio #matlab文件名 matfn=u'./readdata.mat' data=sio.loadmat(matfn) sio.savemat('saveddata.mat', &#123;'name1': list1,'name2': list2&#125;) python itertools使用 在需要进行排列组合的时候这个函数包就非常方便了 1.product 笛卡尔积 2.permutations 排列 3.combinations 组合,没有重复 4.combinations_with_replacement 组合,有重复 product的使用 1234from itertools import productl = [1, 2, 3]print list(product(l, l))print list(product(l, repeat=4)) python 读写文件csv文件的读写 参考文献: https://docs.python.org/3/library/csv.html 写文件 1234567891011import csvcsvfile = file('csv_test.csv', 'wb')writer = csv.writer(csvfile)writer.writerow(['姓名', '年龄', '电话'])data = [ ('小河', '25', '1234567'), ('小芳', '18', '789456')]writer.writerows(data)csvfile.close() 读文件 1234567import csvcsvfile = file('csv_test.csv', 'rb')reader = csv.reader(csvfile)for line in reader: print linecsvfile.close() python杂记二维list取个set map 是一个很好的函数，可以多使用 参考网址： http://stackoverflow.com/questions/39081807/python-2-d-list-how-to-make-a-set/39081998#comment65511507_39081807 1234&gt;&gt;&gt; list1 = [[1,2],[3,4],[1,2]]&gt;&gt;&gt; list2 = list(map(list, set(map(tuple,list1))))&gt;&gt;&gt; list2[[1, 2], [3, 4]] 计算均方根误差-RMSE 参考网址： http://stackoverflow.com/questions/17197492/root-mean-square-error-in-python $$[RMSE=\sqrt{\frac{1}{n}\sum{i=1}^{n}\left ( d{i}-p_{i} \right )^{2}}]$$ 123456789#方法一：使用sklearn中的函数from sklearn.metrics import mean_squared_errorfrom math import sqrtrms = sqrt(mean_squared_error(y_actual, y_predicted))#按照公式直接使用def rmse(predictions, targets): return np.sqrt(((predictions - targets) ** 2).mean()) python中赋值得注意12345678910a = [1,2,3,4]#此时修改b的时候，a的值也会被修改掉，此时的赋值类似于传地址b = a##正确的方法有两种##1.不借助函数包b = a[:]##2.借助于copy函数包import copyb = copy.copy(a) map函数式编程123456def convert2second(time_cur): time_list = time_cur.split(":") time_list = map(lambda x: int(x),time_list) time_second = time_list[2] + time_list[1]*60 + time_list[0]*3600 return time_secondtime_second_all_list = map(convert2second,time_all_list)]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>常用技能</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TBSchedule使用实战]]></title>
    <url>%2F%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE%2F2016-08-03-TBSchedule%E4%BD%BF%E7%94%A8%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[tbschedule的部署与使用1. zookeeper的集群部署与使用假设我们的设想是在三台机子上建立zookeeper集群，分别是192.168.8.28 31 32的目标主机中部署集群环境 全程的部署及运行都是基于centos系统，并且需要保证有java环境 1.1 下载zookeeper的压缩包下面的操作在三台主机中都是同样的操作创建同样的目录结构 123456789#1.下载源文件wget https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.3.6/zookeeper-3.3.6.tar.gz#2.解压到当前的目录tar -zxvf zookeeper-3.3.6.tar.gz#3.重命名mv zookeeper-3.3.6 zk#4.创建数据文件和日志文件目录，此时与zk目录是同级的mkdir datamkdir log 1.2 zookeeper配置1.2.1 进入zk目录，在conf目录下复制 zoo_sample.cfg文件至zoo.cfg 1cp zoo_sample.cfg zoo.cfg 1.2.2 vim进入修改配置文件至如下： [ ] ClientPort端口：此时我们是多机集群部署，所以都是指定为2181端口,如果在1台机器上部署多个server，那么每台机器都要不同的 clientPort，比如 server1是2181,server2是2182，server3是2183 [ ] dataDir和dataLogDir：dataDir和dataLogDir也需要区分下，将数据文件和日志文件分开存放，同时每个server的这两变量所对应的路径都是不同的 [ ] server.X和myid： server.X 这个数字就是对应，data/myid中的数字。在3个server的myid文件中分别写入了1，2，3那么每个server中的zoo.cfg都配 server.1 server.2,server.3就行了。后面连着的2个端口是zookeeper间的通信端口可以一致 注意:这里的server.1=192.168.8.28:2287:3387其中data/myid的值和server.1中1的值都要对应到后面的IP地址的主机 1234567891011121314151617181920212223# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial# synchronization phase can takeinitLimit=10# The number of ticks that can pass between# sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.dataDir=/home/zhangyi/zookeeper/data# the port at which the clients will connectclientPort=2181#the location of the log filedataLogDir=/home/zhangyi/zookeeper/logserver.1=192.168.8.28:2287:3387server.2=192.168.8.31:2288:3388server.3=192.168.8.32:2289:3389 1.3 zookeeper的启动与测试1.3.1 启动zookeeper 进入zookeeper的bin目录下，使用如下命令 分别进入三台目标主机的zookeeper下的bin目录启动下面命令 1./zkServer.sh start 1.3.2 测试运行状态 执行下面命令就会进入该IP主机zookeeper的工作空间，其中启动过程不能出现任何的错误信息报出，如果出错查看myid有没有正确写入，并且使用命令jps查看是否已经启动了zookeeper服务 1./zkCli.sh -server 192.168.8.28 2. tbschedule的部署与配置2.1 下载tbschedule的源码，并且在tbschedule源码的基础上创建自己的maven项目 tbschedule下载下来源码是放在trunk/的目录下的 2.2 tbschedule控制台部署tbSchedule就是个用servlet/JSP 写的web项目，我们可以直接把war包部署到tomcat中，然后在浏览器访问 1234//向注册中心注册配置http://&#123;server&#125;:&#123;port&#125;/ScheduleConsole/schedule/config.jsp//配置调度任务http://&#123;server&#125;:&#123;port&#125;/ScheduleConsole/schedule/index.jsp 2.3 修改代码中的zookeeper配置修改src/test/resources/schedule.xml中的配置信息指向已经启动的zookeeper服务器。为了避免不同应用任务类型间冲突，rootPath尽量全局唯一 由于tbschedule是基于spring框架的，所以此处的src/test/resources/schedule.xml是需要spring中ApplicationContext来解析xml文件的，由于maven项目结构和spring结构不太一致一般情况下spring是解析不到.xml文件的，指定这个.xml目录的文件是项目根目录下一个以项目名＋.imp中&lt;sourceFolder url=&quot;file://$MODULE_DIR$/src/main/resources&quot; type=&quot;java-resource&quot; /&gt;指定的。 123456789101112131415161718192021&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans default-autowire="byName" xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="demoTaskBean" class="com.intsig.task.DemoTaskBean"/&gt; &lt;bean id="scheduleManagerFactory" class="com.taobao.pamirs.schedule.strategy.TBScheduleManagerFactory" init-method="init"&gt; &lt;property name="zkConfig"&gt; &lt;map&gt; &lt;entry key="zkConnectString" value="192.168.8.31:2181" /&gt; &lt;entry key="rootPath" value="/root/zhangyi/zookeeper/data" /&gt; &lt;entry key="zkSessionTimeout" value="10000" /&gt; &lt;entry key="userName" value="root" /&gt; &lt;entry key="password" value="admin" /&gt; &lt;entry key="isCheckParentPath" value="true" /&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt; 3. tbschedule的实例分析上面把所有的基本的配置及环境的搭建都讲好了，结下来的就是最接近实战的内容了，当然了关于spring的知识还是需要有部分的积累的，主要这里用到的是spring的依赖注入的思想，然后最主要的就是用maven导入spring-framework的框架。 3.1 任务和调度策略的初始化,启动首先，这一部分的配置可以说有三种方式的配置 通过java代码的初始化 这种方式主要参考的方式是源码中InitialDemoConfigData.java中变成方式，其中需要注意的是创建任务调度时setDealBeanName()中设置的名字需要和schedule.xml中执行任务的bean的id一致。这种方式先执行InitialDemoConfigData类，然后执行StartDemoSchedule 通过xml文件的初始化 这种方式在我认为可扩展性，更强一点，就是可以将策略和任务的配置通过xml的形式写入, 如果对spring有一定的理解后可以尝试一下，这部分不做详细介绍 通过tbschedule控制台的初始化 这种方式应该说是最为简单方便的初始化飞方式，配置策略和任务时需要注意的是任务处理Bean的名称必须和schedule.xml中执行任务的bean的id一致，如果要运行的话可以直接运行StartDemoSchedule 3.2 具体逻辑代码的实现 在这部分中我们最为主要的是实现IScheduleTaskDealSingle&lt;T&gt;或IScheduleTaskDealMulti&lt;T&gt;中的selectTasks和execute。 3.2.1 情景假设 假设我们现在向姓名首字母a-z的所有用户发送一封邮件，我们需要以最快的方式发出去，这个时候就可以考虑使用分布式的方式用多台服务器不重复的同时发送目标邮件。 创建调度策略，其中“最大线程组数量”设置为13，表示在机器上的通过4个线程组并行执行数据同步任务。 创建调度任务，需要注意下面设置 任务名称：对应调度策略中的任务名称，标识任务和策略的关联关系； 任务处理的SpringBean：对应Demo TaskDeal服务Spring容器中的任务对象ID； 每次获取数据量：对应于bean任务类selectTasks方法参数 eachFetchDataNum 执行开始时间：“0 ?” 表示每分钟的0秒开始，表达式同Quartz设置的Crontab格式，有工具可以生成，详细解释参照这里 任务项：在上面的a-z中有26个字母，我们可以让一个县城组处理两个首字母的人名，向这些人发邮件，我们就可以将任务划分为a-z的任务片。26个任务碎片被分配到13个线程组，那么每个线程组对应2个任务碎片，运行时任务项参数又被传递到bean任务类selectTasks方法的List&lt;TaskItemDefine&gt; queryCondition参数，例如第1个线程组调用selectTasks方法是queryCondition参数条件为a,b ，第2个线程组执行参数条件为c,d，bean任务类中根据参数生成对应的字母条件去数据库中找到响应的人名的邮箱信息，并将结果提交到execute方法执行，从而实现并行计算。 3.2.2 demo演示 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package Task;import java.sql.ResultSet;import java.util.ArrayList;import java.util.Comparator;import java.util.List;import com.taobao.pamirs.schedule.IScheduleTaskDealSingle;import com.taobao.pamirs.schedule.TaskItemDefine;import DBHelper.*;public class DataSyncABean implements IScheduleTaskDealSingle&lt;OrderInfo&gt; &#123; public List&lt;CustomInfo&gt; selectTasks(String taskParameter, String ownSign, int taskItemNum, List&lt;TaskItemDefine&gt; queryCondition, int eachFetchDataNum) throws Exception &#123; List&lt;OrderInfo&gt; result = new ArrayList&lt;OrderInfo&gt;(); if (queryCondition.size() == 0) &#123; return result; &#125; StringBuffer condition = new StringBuffer(); for (int i = 0; i &lt; queryCondition.size(); i++) &#123; if (i &gt; 0) &#123; condition.append(","); &#125; //获取到被分配到执行主机上的名字首字母 condition.append(queryCondition.get(i).getTaskItemId()); &#125; String sql = "select * from custom " + "where " + " firstchar in (" + condition + ") " + "limit " + eachFetchDataNum; System.out.println("开始执行SQL：" + sql); ResultSet rs = MySQLHelper.executeQuery(sql); while (rs.next()) &#123; CustomInfo custom = new CustomInfo(); custom.name = rs.getString("name"); custom.email = rs.getString("email"); result.add(custom); if (rs.isLast()) &#123; break; &#125; &#125; MySQLHelper.free(rs, rs.getStatement(), rs.getStatement() .getConnection()); return result; &#125; public Comparator&lt;OrderInfo&gt; getComparator() &#123; return null; &#125; public boolean execute(CustomInfo task, String ownSign) throws Exception &#123; //TODO 执行发邮件的操作， //这里的task是一个单个的数据对象，即只对应一个人的信息 return true; &#125;&#125; 参考文献1.http://code.taobao.org/p/tbschedule/wiki/tbschedule-quick-start/ 2.http://www.cnblogs.com/sunddenly/p/4018459.html 3.http://blog.csdn.net/neosmith/article/details/46535853 4.http://geek.csdn.net/news/detail/65738?utm_source=tuicool&amp;utm_medium=referral 5.http://blog.csdn.net/taosir_zhang/article/details/50728362 6.http://www.cnblogs.com/lengfo/p/4146797.html]]></content>
      <categories>
        <category>开源项目</category>
      </categories>
      <tags>
        <tag>TBSchedule</tag>
        <tag>淘宝任务调度</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯云LAMP环境配置]]></title>
    <url>%2Fweb%E5%BC%80%E5%8F%91%2F2016-04-13-%E8%85%BE%E8%AE%AF%E4%BA%91LAMP%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[腾讯云LAMP环境配置 参考网址: 国外网站: https://www.digitalocean.com/community/tutorials/how-to-install-linux-apache-mysql-php-lamp-stack-on-centos-7 CentOS 7 yum方式配置LAMP环境 ： http://www.cnblogs.com/zutbaz/p/4420791.html 安装Apache1.安装httpd 1yum install httpd //默认情况下，选择Y，进行安装 2.安装成功后，默认情况下，是禁止外部IP访问的，需要进行设置 1234567891011vi /etc/httpd/conf/httpd.conf //进入配置文件找到&lt;Directory /&gt;AllowOverride noneRequire all denied&lt;/Directory &gt;修改为：&lt;Directory /&gt;AllowOverride noneRequire all granted&lt;/Directory &gt; 3.启动服务器,自启动 12345systemctl start httpd.service //启动systemctl restart httpd.service //停止systemctl status httpd.service //查看状态systemctl restart httpd.service //重启systemctl enable httpd.service //开机启动 4.访问服务器IP，如果显示测试界面，则安装成功： 安装MySQL 在CentOS7中，mariadb代替了Mysql，其实mariadb只是一个M有sql的一个分支，由于Mysql旧部员工不满Oracle收购Mysql导致更新速度变慢，又重新开发了和Mysql类似的开源数据库。来应对Oracle的Mysql。 1.安装mariadb 1yum install mariadb maridb-server //默认安装 2.启动数据库 1sudo systemctl start mariadb 3.设置密码 1sudo mysql_secure_installation 然后会出现下面的内容提示设置密码 1234567891011Enter current password for root (enter for none):OK, successfully used password, moving on...Setting the root password ensures that nobody can log into the MariaDBroot user without the proper authorization.New password: passwordRe-enter new password: passwordPassword updated successfully!Reloading privilege tables.. ... Success! 4.开机自启,重新启动 12sudo systemctl enable mariadb.servicesudo systemctl restart mariadb.service 安装PHP1.安装PHP 1sudo yum install php php-mysql 2.重新启动Apache 1sudo systemctl restart httpd.service 3.在Apche的目录下面新建一文件test.php 12cd /var/www/htmlvi test.php 可以键入相关PHP代码，以输入hello world为例， 123&lt;?php echo "hello world";?&gt; 访问网站IP/test.php,如果正常解析，则说明PHP环境完成。 安装PHPMyAdmin]]></content>
      <categories>
        <category>web开发</category>
      </categories>
      <tags>
        <tag>php环境</tag>
        <tag>LAMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯云FTP的配置]]></title>
    <url>%2Fweb%E5%BC%80%E5%8F%91%2F2016-04-12-%E8%85%BE%E8%AE%AF%E4%BA%91FTP%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[腾讯云FTP的配置 参考网址: 官方教程: http://www.qcloud.com/wiki/ 国外网站: http://www.unixmen.com/install-configure-ftp-server-centos-7/ centos启用ftp功能 ： http://os.51cto.com/art/201408/448630.htm 腾讯云论坛: http://wsq.discuz.qq.com/?c=index&amp;a=viewthread&amp;f=inner&amp;siteid=264281419&amp;tid=1343&amp;source=wxhy&amp;fromuid=0 在腾讯云上配置FTP如果按照官方的教程来做,有可能是不能实现访问的.网上现在到处都能找到的教程都是基于Centos的,但是好多都是人云亦云没有很好的概括其中的脉络及可能出现的问题. 防火墙配置 在腾讯云中虽然我选择的是Centos的版本,但是好像还是经过了一些的配置,因为我查看进程的时候发现其中根本没有开firewalld也没有开selinux 1.查看防火墙运行状态 12netstat -tunlp #查看防火墙运行状态systemctl status firewalls 2.关闭防火墙 12systemctl mask firewalldsystemctl stop firewalld 3.安装iptables防火墙 12345# yum -y install iptables-services# systemctl enable iptables# systemctl enable ip6tables# systemctl start iptables# systemctl start ip6tables 4.配置iptables,开放21端口 在行上面有22 -j ACCEPT 下面另起一行输入跟那行差不多的，只是把22换成21，然后：wq保存。 1# vi /etc/sysconfig/iptables 5.如果要关闭SeLinux 12345678# vi /etc/selinux/config# SELINUX=enforcing #注释掉# SELINUXTYPE=targeted #注释掉# SELINUX=disabled #增加:wq! #保存退出setenforce 0 #使配置立即生效 FTP服务器端配置 安装vsftpd组件，安装完后，有/etc/vsftpd/vsftpd.conf 文件，用来配置，还有新建了一个ftp用户和ftp的组，指向home目录为/var/ftp,默认是nologin（不能登录系统） 1.安装vsftpd组件 1yum -y install vsftpd 可以用下面命令查看用户 1cat /etc/passwd 默认ftp服务是没有启动的，用下面命令启动 1systemctl start vsftpd 2.设置自动启动 1systemctl enable vsftpd 3.将匿名登录禁用掉 在配置文件中第11行的“anonymous_enable=YES”改为“anonymous_enable=NO”，即将匿名登录禁用。 1# vim /etc/vsftpd/vsftpd.conf 重新启动vsftpd 1systemctl restart vsftpd 4.安装ftp客户端组件（用来验证是否vsftpd） 1yum -y install ftp 执行命令尝试登录 1ftp localhost 输入用户名ftp，密码随便（因为默认是允许匿名的）登录成功，就代表ftp服务可用了。但是，外网是访问不了的，所以还要继续配置。 5.设置FTP用户账号。设置成功后，即可通过该账号登录FTP服务器。 设置FTP用户的账号，例如账号为“ftpuser1”，目录为/home/ftpuser1，且设置不允许通过ssh登录。 1useradd -m -d /home/ftpuser1 -s /sbin/nologin ftpuser1 #两个ftpuser1都必须有,而且一致 设置账号对应的密码，例如密码为“ftpuser1”。 1passwd ftpuser1 6.修改vsftpd的pam配置，使用户可以通过自己设置的FTP用户帐号和密码连接到云服务器。 修改pam 1vim /etc/pam.d/vsftpd 内容修改为： 123456#%PAM-1.0 auth required /lib64/security/pam_listfile.so item=user sense=deny file=/etc/ftpusers onerr=succeed auth required /lib64/security/pam_unix.so shadow nullok auth required /lib64/security/pam_shells.so account required /lib64/security/pam_unix.so session required /lib64/security/pam_unix.so 7.重启vsftpd服务，使修改生效 1systemctl restart vsftpd FTP客户端配置 添加完毕之后理论上就可以访问了，但是很多客户端会出现pasv错误。 问题所在FTP协议传输文件有2种模式，分为主动模式和被动模式。这里的问题原因简单来讲是这样：FTP客户端默认的传输模式是被动模式，因此在通信过程中会去寻找服务器端的ip地址进行连接，但是由于腾讯云的外网ip不是直接配在网卡上，因此在被动模式下客户端找不到有效的ip（因为找到的是腾讯云的内网ip，内网ip无法直接和外网通信），故无法建立连接。 解决方案a、将客户端传输模式改为主动即可； b、如果客户端网络环境要求被动模式，那么需要在服务端的配置文件中新增这些语句 打开vsftpd.conf文件，在后面加上 12pasv_min_port=30000 pasv_max_port=30999 改完重启一下vsftpd 可能的问题]]></content>
      <categories>
        <category>web开发</category>
      </categories>
      <tags>
        <tag>centos配置</tag>
        <tag>搭建FTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[腾讯云的使用]]></title>
    <url>%2Fweb%E5%BC%80%E5%8F%91%2F2016-04-10-%E8%85%BE%E8%AE%AF%E4%BA%91%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[腾讯云的使用 参考网址: 主要的参考还是腾讯的官方教程: http://www.qcloud.com/wiki/ 下面的内容主要介绍怎么使用腾讯几乎是免费送给大家的免费云平台,在这里的你可以尽情的展现你自己的想法,我的想法也很简单: 1.搭建自己的CMS 2.搭建自己家的云平台实现数据的云端处理 3.将实验的服务器端放在虚拟主机(云服务器中)，方便以后的管理 为什么选择腾讯云为什么要选择腾讯云,这个最为主要的原因是自己经济情况决定的,腾讯云每年送我一个域名然后每个月只要1元就可以租用腾讯的云平台.相比较于阿里云,阿里云是学生价9.9元每个月,由于自己对云平台的要求也不是很高而且对系统也没有特殊要求况且两个平台的操作系统都差不多.这样自己就选择了腾讯云,对于学生其实花这1块钱我是认为很有必要的,在学校不多学点东西,到社会工作早晚还是会加倍的学习的.总之一句话:‘欠下的迟早要还的’。 该选择哪种系统对于选择什么系统的问题上,自己感觉要学习的话还是Linux系统好,我选择的是Centos的纯净版,当然了如果有人希望系统中把所有的环境都搭建好其实也是可以选择的. 怎么登陆服务器对于登陆方式,主要是分为两种,一种是通过密码登录这种方式很简单；另一种就是通过密钥登录这种略复杂点.我采用的密码登录的方式,当然凡事试一下的态度我也尝试了通过密钥登录,整体来说也不是很复杂就是步骤多了一点 windows平台putty密钥登录这个我有点懒了,要是非要这样做可以自己去查看官方文档这里面写的很详细.官方文档的是将私钥给你然后自己用这个私钥绑定主机. 还有一种方式是通过本地产生公钥给服务器然后实现绑定,具体的教程是腾讯云配置密钥使用putty登录 Linux or Mac平台ssh密码登录ssh下的密码登录很简单,就是一行的代码,然后按照要求输入密码就行了. 1ssh root@115.111.111.111 #root是系统管理员 ssh密钥登录我还是感觉在linux下用命令行登录的方式非常方便,按下面的代码操作也就两行,window下却需要一堆的操作 1234chmod 400 私钥文件 #将您的私钥文件设置权限为400ssh -i 私钥文件 系统管理员@服务器IP #对于ubuntu系统管理员为ubuntu；对于redhat，centos，debian，suse用户名为root例：ssh -i ~/test root@203.111.111.111 #私钥文件路径为~/test，用户名为ubuntu，服务IP为203.111.111.111 主要的问题1.主要是当在Mac下终端编辑的中文到windows平台下时终端打开是乱码 如果有谁能帮忙解决的,希望能给我留言或发邮件给我nezhaxiaozi@outlook.com]]></content>
      <categories>
        <category>web开发</category>
      </categories>
      <tags>
        <tag>腾讯云</tag>
        <tag>web开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github常见问题]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2016-03-15-github%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98(%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0)%2F</url>
    <content type="text"><![CDATA[github常见问题 git 在做协作开发的时候往往代码会分支出很多个版本 问题1:服务器上做了配置修改 如果系统中有一些配置文件在服务器上做了配置修改,然后后续开发又新添加一些配置项的时候,在发布这个配置文件的时候,会发生代码冲突: 12error: Your local changes to the following files would be overwritten by merge: protected/config/main.phpPlease, commit your changes or stash them before you can merge. 1.如果希望保留生产服务器上所做的改动,仅仅并入新配置项, 处理方法如下: 12345git stashgit pullgit stash pop然后可以使用git diff -w +文件名 来确认代码自动合并的情况. 2.反过来,如果希望用代码库中的文件完全覆盖本地工作版本. 方法如下: 1234git reset --hardgit pull其中git reset是针对版本,如果想针对文件回退本地修改,使用git checkout HEAD file/to/restore 问题2:在Mac下文件不现实.gitignore文件 在Mac下，可视化界面中是看不’.’开始的文件的,但是在github文件夹中有些是很有用处的类似’.gitignore’,而且在mac环境下会自动产生.DS_Store的文件,这个是Mac下特有的,我们并不需要它. 1.查看github文件夹下所有的文件 在可视化目录中看不到,就只能用命令行去查看了 1ls -la 2.编辑文件,让上传的时候自动忽略 在自己需要同步的文件夹下编辑一个’.gitignore’文件,编辑自己需要忽略掉的文件 *.lock .DS_Store 其中’*’是通配符表示任何字符,其他的是表示需要忽略的文件 参考：【1】：http://blog.csdn.net/zwhfyy/article/details/8625228]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>Latex</tag>
        <tag>Linux</tag>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac初次使用]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2016-03-06-Mac%E5%88%9D%E6%AC%A1%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Mac初次使用 作为一名程序员，Mac笔记本真的很有必要，基于unix开发的mac osx 有着和linux一样的操作体验。 参考网址：Mac入门 mac基本快捷键介绍 mac的手势操作在系统偏好设置中的触控板中有详细的动画演示 快捷键的总结 常用快捷键 Command+Shift+C 快速打开Finder Command+⬆️/⬇️ 进入或退出当前目录 开发必备mac的应用命令行安装管理-Homebrewbrew 又叫Homebrew，是Mac OSX上的软件包管理工具，能在Mac中方便的安装软件或者卸载软件， 只需要一个命令， 非常方便.brew类似ubuntu系统下的apt-get的功能 参考网址： Homebrew官网 Mac入门－使用brew安装软件 1.获取homebrew 打开终端窗口, 粘贴以下脚本。 1/usr/bin/ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)" 2.使用homebrew安装软件 具体参考下面git的安装 3. homebrew常用命令 123456789brew list 列出已安装的软件brew update 更新brewbrew home 用浏览器打开brew的官方网站brew info 显示软件信息brew deps 显示包依赖 git安装配置作为一名程序员只要必须要会用一种版本控制工具，不管是git还是svn，我选择的用git是因为自己之前一直用git bash命令管理自己的项目。我的github地址是 https://github.com/nezha 参考网址： Mac入门－使用brew安装软件 Mac下git命令自动补全 基本操作 12345brew search git 查找gitbrew install git 安装gitbrew uninstall卸载git 更新git 1brew upgrade git git命令自动补全 默认情况下双击tab键是不会有代码提示的 1$ brew install bash-completion 安装完成之后 123456$ brew info bash-completion==&gt; CaveatsAdd the following lines to your ~/.bash_profile:if [ -f $(brew --prefix)/etc/bash_completion ]; then. $(brew --prefix)/etc/bash_completionfi 将if…then…那一句添加到~/.bash_profile（如果没有该文件，新建一个） python集成环境的配置之前自己一直在windows环境下用python做科学计算方向的研究，平时处理数据出图什么的都是用python的集成包开发的，一下子转到mac osx 环境下竟然找不到之前windows用的python(x,y)，查阅相关资料后，发现现在主要的科学计算即成环境对应如下： python(x,y) –&gt;&gt;&gt; windows Anaconda –&gt;&gt;&gt; mac osx,windows,linux 参考网址： 目前比较流行的Python科学计算发行版 Anaconda install官方文档 安装过程 Download the Anaconda installer and double click the .pkg file. Answer the prompts on Introduction, Read Me, and License screens.On Destination Select screen, choose “Install for me only.” NOTE: If you get the message “You cannot install Anaconda in this location”, reselect “Install for me only”. 常用命令 12345678910rm -rf ~/anaconda #OS X uninstallconda update condaconda update anaconda #Updating from older Anaconda versionsconda list #查看所有的可安装包conda install numpy #安装numpyconda update numpy #升级 Java环境的配置Java的环境是非常必要的，默认情况下mac是安装了低版本的java，我们需要做的事下载高版本的jdk然后安装它，并不会有复杂的环境变量配置的问题。 参考网址： 官方java安装教程 安装过程 下载 java-8u73-macosx-x64.dmg 文件。在下载文件前，需查看并同意许可证协议的条款。 双击 .dmg 文件以启动它 双击程序包图标以启动安装向导 要测试 Java 是否已正确安装在您的计算机上并正常运行，请运行此测试 applet 或者在终端中运行javac 或者 java Android环境的配置Android的开发主要就是下载Android Studio，这个我是全程VPN的，没有什么问题，一开始的时候会检查java运行环境，所以安装之前必须将java环境安装好。 Sublime的配置Sublime的安装及配置请移步至我的博客sublime2使用教程 Mac下安装office套件 参考网址： baidu教程 资源链接：这里 破解补丁:这里 密码是：excd pip的安装如果需要安装第三方的软件时，pip是很好的选择，很多时候安装python的第三方包的时候就需要用到pip。 参考网址： pip官方教程 安装过程 To install pip, securely download get-pip.py. Then run the following: 1python get-pip.py 常用软件 参考网址： 1.OS X 上有哪些优质的 app 2.oh my zsh 官网 3.程序员如何优雅地使用 Mac? 4.Mac 上有哪些鲜为人知但极大提高工作效率的工具？ 1.API文档：Dash Dash可以下载现在主流的所有语言的API,这样能很方便的插文档了 2.浏览器：Google Chrome 也可以用 Firefox 吧，不知道现在谁的开发者扩展生态比较好。反正 Chrome 对我够用了，有很多观察 DOM 的，解析 Angular 的插件之类的。 3.写作：Texstudio 带自动补全、预设符号、局部预览等功能的 TeX 编辑器。这个在写论文的时候很有用。 4.Caffeine 可以让电脑不关机。 只是一个小小的图标而已。当那个小茶杯冒烟就是保持屏幕常亮 5.Spotlight 用 ‘control’ + ‘space’ 键唤醒,功能很强大, 6.Go2shell 在当前目录打开终端注意事项: 最新的在拖到Finder的时候需要按住’command’键 7.终端:iTerm ＋ Oh My Zsh 这个可以提供丰富的配色方案,很好看～不过还不知道到底哪边比Mac自带的终端好用. 8.系统监控:Monity 这个说用处大也不是很大,就是可以实时的查看到系统,内存,电池等信息. 9.远程控制：TeamView 当我们多平台需要控制的时候,这个工具就很有用了.可以远程控制自己的所有设备.很方便,而且是全平台兼容 10.识别U盘：Tuxera 初始状态下Mac电脑对U盘只能读不能写,这时候这个软件就很有用了. 11.连接Android:smartFinder 一般情况下,Android手机是不能被Mac系统识别的,装了这个之后就可以实现Android手机的文件管理 12.阅读pdf：skim 原来自己是用adobe公司的PDF阅读的,但是在Mac下打开奇卡无比,还有人说Mac自带的preview就很好－－－我表示不服,我在win平台注释过的文档在Mac下打开就会出现问题. 常见问题.DS_Store 文件是什么？ 参考网址： .DS_Store 文件是什么 .DS_Store是Mac OS保存文件夹的自定义属性的隐藏文件，如文件的图标位置或背景色，相当于Windows的desktop.ini。 1，禁止.DS_store生成： 打开 “终端” ，复制黏贴下面的命令，回车执行，重启Mac即可生效。 1defaults write com.apple.desktopservices DSDontWriteNetworkStores -bool TRUE 2，恢复.DS_store生成： 1defaults delete com.apple.desktopservices DSDontWriteNetworkStores]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Mac使用</tag>
        <tag>应用安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scikit_learn初入门]]></title>
    <url>%2F%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%2F2016-03-04-scikit_learn%E5%88%9D%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[scikit_learn初入门(更新于2016/10/9) 标准的官方网址：http://scikit-learn.org/stable/ scikit_learn在kaggle比赛中看到和pandas结合起来用的非常多，也确实在机器学习方面这里面的算法非常的全面。 scikit_learn的介绍 基本领域 分类–Classification 回归–Regression 聚类–Clustering 降维–Dimensionality reduction 模型选择–Model selection 预处理–Preprocessing 如何快速安装python库 无论是在Mac os，’Linux’还是’Windows’，最为方便管理python扩展的工具是pip命令，如果不知道怎么使用和安装pip，请自行百度或谷歌。 skLearn使用入门 下面sk-learning的基本用法将逐步的完善补充，主要还是根据自己的学习进度进行推进 分类–Classification逻辑回归 参考文档：http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#coding=utf-8import matplotlib.pyplot as pltimport numpy as npfrom matplotlib.colors import ListedColormapdef plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02): # setup marker generator and color map markers = ('s', 'x', 'o', '^', 'v') colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan') cmap = ListedColormap(colors[:len(np.unique(y))]) # plot the decision surface x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1 x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1 xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution)) Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T) Z = Z.reshape(xx1.shape) plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap) plt.xlim(xx1.min(), xx1.max()) plt.ylim(xx2.min(), xx2.max()) # plot class samples for idx, cl in enumerate(np.unique(y)): plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],alpha=0.8, c=cmap(idx),marker=markers[idx], label=cl) # highlight test samples if test_idx: X_test, y_test = X[test_idx, :], y[test_idx] plt.scatter(X_test[:, 0], X_test[:, 1], c='', alpha=1.0, linewidth=1, marker='o', s=55, label='test set')from sklearn import datasetsimport numpy as npfrom sklearn.cross_validation import train_test_splitiris = datasets.load_iris()# 由于Iris是很有名的数据集，scikit-learn已经原生自带了。X = iris.data[:, [2, 3]]y = iris.targetX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)# 为了追求机器学习和最优化算法的最佳性能，我们将特征缩放from sklearn.preprocessing import StandardScalersc = StandardScaler()sc.fit(X_train)# 估算每个特征的平均值和标准差X_train_std = sc.transform(X_train)# 注意：这里我们要用同样的参数来标准化测试集，使得测试集和训练集之间有可比性X_test_std = sc.transform(X_test)X_combined_std = np.vstack((X_train_std, X_test_std))y_combined = np.hstack((y_train, y_test))'''# 训练感知机模型from sklearn.linear_model import Perceptron# n_iter：可以理解成梯度下降中迭代的次数# eta0：可以理解成梯度下降中的学习率# random_state：设置随机种子的，为了每次迭代都有相同的训练集顺序ppn = Perceptron(n_iter=40, eta0=0.1, random_state=0)ppn.fit(X_train_std, y_train) # 分类测试集，这将返回一个测试结果的数组y_pred = ppn.predict(X_test_std)# 计算模型在测试集上的准确性，我的结果为0.9，还不错accuracy_score(y_test, y_pred)'''from sklearn.linear_model import LogisticRegressionlr = LogisticRegression(C=1000.0, random_state=0)lr.fit(X_train_std, y_train)lr.predict_proba(X_test_std[0,:]) # 查看第一个测试样本属于各个类别的概率plot_decision_regions(X_combined_std, y_combined, classifier=lr, test_idx=range(105,150))plt.xlabel('petal length [standardized]')plt.ylabel('petal width [standardized]')plt.legend(loc='upper left')plt.show() 分类结果 回归–Regression一元线性回归123456789import numpy as npfrom sklearn.linear_model import LinearRegression#一元线性回归X = [[6], [8], [10], [14], [18]]y = [[7], [9], [13], [17.5], [18]]# 创建并拟合模型model = LinearRegression()model.fit(X, y)print('预测一张12英寸匹萨价格：$%.2f' % model.predict(np.array([12]).reshape(-1, 1))[0]) 多变量线性回归1234567891011from sklearn.linear_model import LinearRegressionX = [[6, 2], [8, 1], [10, 0], [14, 2], [18, 0]]y = [[7], [9], [13], [17.5], [18]]model = LinearRegression()model.fit(X, y)X_test = [[8, 2], [9, 0], [11, 2], [16, 2], [12, 0]]y_test = [[11], [8.5], [15], [18], [11]]predictions = model.predict(X_test)for i, prediction in enumerate(predictions): print('Predicted: %s, Target: %s' % (prediction, y_test[i]))print('R-squared: %.2f' % model.score(X_test, y_test)) 多项式回归 参考文献：1.多项式回归的文献2.最小二乘法的WiKi解释 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#coding=utf-8import numpy as npfrom sklearn.linear_model import LinearRegressionfrom sklearn.preprocessing import PolynomialFeaturesimport matplotlib.pyplot as pltdef runplt(): plt.figure() plt.title(u'diameter-cost curver') plt.xlabel(u'diameter') plt.ylabel(u'cost') plt.axis([0, 25, 0, 25]) plt.grid(True) return pltX_train = [[6], [8], [10], [14], [18]]y_train = [[7], [9], [13], [17.5], [18]]X_test = [[6], [8], [11], [16]]y_test = [[8], [12], [15], [18]]# 建立线性回归，并用训练的模型绘图# regressor = LinearRegression()# regressor.fit(X_train, y_train)xx = np.linspace(0, 26, 100)#计数的100个点# yy = regressor.predict(xx.reshape(xx.shape[0], 1))# plt = runplt()# plt.plot(X_train, y_train, 'k.')# plt.plot(xx, yy)plt = runplt()plt.plot(X_train, y_train, 'k.') #花训练样本集quadratic_featurizer = PolynomialFeatures(degree=2) #设置拟合度X_train_quadratic = quadratic_featurizer.fit_transform(X_train)X_test_quadratic = quadratic_featurizer.transform(X_test)regressor_quadratic = LinearRegression()regressor_quadratic.fit(X_train_quadratic, y_train)xx_quadratic = quadratic_featurizer.transform(xx.reshape(xx.shape[0], 1))plt.plot(xx, regressor_quadratic.predict(xx_quadratic), 'r-')seventh_featurizer = PolynomialFeatures(degree=7)X_train_seventh = seventh_featurizer.fit_transform(X_train)X_test_seventh = seventh_featurizer.transform(X_test)regressor_seventh = LinearRegression()regressor_seventh.fit(X_train_seventh, y_train)xx_seventh = seventh_featurizer.transform(xx.reshape(xx.shape[0], 1))plt.plot(xx, regressor_seventh.predict(xx_seventh))print('2 r-squared', regressor_quadratic.score(X_test_quadratic, y_test))print('7 r-squared', regressor_seventh.score(X_test_seventh, y_test))###下面是官方demo中的方法# from sklearn.pipeline import Pipeline# from sklearn.linear_model import (LinearRegression, TheilSenRegressor, RANSACRegressor)from sklearn.pipeline import make_pipeline# estimators = [('OLS', LinearRegression()),\# ('Theil-Sen', TheilSenRegressor(random_state=42)),\# ('RANSAC', RANSACRegressor(random_state=42))]model = make_pipeline(PolynomialFeatures(2),LinearRegression())model.fit(X_train,y_train)COEF = model.named_steps['linearregression'].coef_ #输出训练的多项式系数print "coefficients",COEFX_test_quadratic = model.predict(X_test)# print X_test_quadraticprint('2 r-squared easy method', model.score(X_test_quadratic, y_test))plt.show() 聚类–Clusteringsklearn 中 make_blobs模块使用 实验中需要生成特定个簇的时候make_blobs就很管用了 例如要生成5类数据（100个样本，每个样本有2个特征），代码如下： 1234567from sklearn.datasets import make_blobsfrom matplotlib import pyplotdata, label = make_blobs(n_samples=100, n_features=2, centers=5)# 绘制样本显示pyplot.scatter(data[:, 0], data[:, 1], c=label)pyplot.show() 如果希望为每个类别设置不同的方差，需要在上述代码中加入cluster_std参数： 1234567from sklearn.datasets import make_blobsfrom matplotlib import pyplotdata, label = make_blobs(n_samples=10, n_features=2, centers=3, cluster_std=[0.8, 2.5, 4.5])# 绘制样本显示pyplot.scatter(data[:, 0], data[:, 1], c=label)pyplot.show() 降维–Dimensionality reduction模型选择–Model selection预处理–Preprocessing 参考网址：http://www.cnblogs.com/cherishZhang/p/4267113.html scikit_learn的数据集 from sklearn import datasets iris数据集 Iris数据集是常用的分类实验数据集，由Fisher, 1936收集整理。Iris也称鸢尾花卉数据集，是一类多重变量分析的数据集。数据集包含150个数据集，分为3类，每类50个数据，每个数据包含4个属性。可通过花萼长度，花萼宽度，花瓣长度，花瓣宽度4个属性预测鸢尾花卉属于（Setosa，Versicolour，Virginica）三个种类中的哪一类。 1234567891011121314import pandas as pdimport matplotlib.pyplot as pltimport numpy as np df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None) # 加载Iris数据集作为DataFrame对象X = df.iloc[:, [0, 2]].values # 取出2个特征，并把它们用Numpy数组表示 plt.scatter(X[:50, 0], X[:50, 1],color='red', marker='o', label='setosa') # 前50个样本的散点图plt.scatter(X[50:100, 0], X[50:100, 1],color='blue', marker='x', label='versicolor') # 中间50个样本的散点图plt.scatter(X[100:, 0], X[100:, 1],color='green', marker='+', label='Virginica') # 后50个样本的散点图plt.xlabel('petal length')plt.ylabel('sepal length')plt.legend(loc=2) # 把说明放在左上角，具体请参考官方文档plt.show() scikit_learn的交叉验证模块cross_validation 常用的函数有train_test_split()将数据集分为训练集和测试集k-fold 参考文献：http://blog.csdn.net/u010454729/article/details/50754076 12345678from sklearn import datasetsimport numpy as npfrom sklearn.cross_validation import train_test_splitiris = datasets.load_iris()X = iris.data[:, [2, 3]]y = iris.targetX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0) 机器学习相关的库 scikit_learn 机器学习方面的库 pandas 处理数据文本用 tensorflow 谷歌的深度学习，神经网络库 pybrain，keras 机器学习中神经网络的库 NLTK 自然语言处理 xgboost 预测模型 参考：[1]：http://scikit-learn.org/[2]：https://www.tensorflow.org/]]></content>
      <categories>
        <category>科学计算</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>聚类算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[sublime2使用教程]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2016-01-21-sublime2%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[sublime2的使用 本文主要参考转载的是：Sublime Text 2安装汉化破解、插件包安装教程 sublime2破解 首先要打开Sublime Text 2 help-&gt;Enter License 粘贴下面代码即可 12345678910111213----- BEGIN LICENSE ----- Andrew Weber Single User License EA7E-855605 813A03DD 5E4AD9E6 6C0EEB94 BC99798F 942194A6 02396E98 E62C9979 4BB979FE 91424C9D A45400BF F6747D88 2FB88078 90F5CC94 1CDC92DC 8457107A F151657B 1D22E383 A997F016 42397640 33F41CFC E1D0AE85 A0BBD039 0E9C8D55 E1B89D5D 5CDB7036 E56DE1C0 EFCC0840 650CD3A6 B98FC99C 8FAC73EE D2B95564 DF450523 ------ END LICENSE ------ 安装包控制器（package control） Ctrl+~ 调出命令控制器 输入下面命令，回车 1import urllib2,os; pf='Package Control.sublime-package'; ipp=sublime.installed_packages_path(); os.makedirs(ipp) if not os.path.exists(ipp) else None; urllib2.install_opener(urllib2.build_opener(urllib2.ProxyHandler())); open(os.path.join(ipp,pf),'wb').write(urllib2.urlopen('http://sublime.wbond.net/'+pf.replace(' ','%20')).read()); print('Please restart Sublime Text to finish installation') 基本配置123456789101112131415&#123; "color_scheme": "Packages/Color Scheme - Default/Monokai.tmTheme", "font_size": 15.0, "highlight_line": true, "ignored_packages": [ "Vintage" ], "scroll_past_end": false, "show_encoding": true, "tab_size": 4, "translate_tabs_to_spaces": true, "word_wrap": true, "open_files_in_new_window":false&#125; 安装插件 安装插件：Ctrl+Shift+p –&gt; install package删除插件：Ctrl+Shift+p –&gt; remove package 常用插件 1.Sublime CodeIntel 它提供了很多IDE提供的功能，例如代码自动补齐，快速跳转到变量定义，在状态栏显示函数快捷信息等 2.Sublime Linter 这个插件帮你找到代码中的错误 3.Emmet(Zen Coding) 快速生成html代码 4.MarkdownEditing 支持Markdown语法高亮和自动补全 5.Markdown Extended + Extends Monokai 不错的Markdown主题，支持对多种语言的高亮 6.Sublime Alignment 用于代码格式的自动对齐。 7.jsFormat 快速格式化javascript代码 Ctrl + Alt + F 常用命令 Alt+Shift+1（非小键盘）窗口分屏，恢复默认1屏 Alt+tab 切换窗口 Ctrl+Shift+分屏序号 将当前焦点页分配到分屏序号页 Ctrl+P 查找当前项目中的文件和快速搜索；输入 @ 查找文件主标题/函数；或者输入 : 跳转到文件某行； Ctrl+K Backspace 从光标处删除至行首 Ctrl+KK 从光标处删除至行尾 Ctrl+D 选词 （使用Ctrl+K是取消本次选择，反复按快捷键，即可继续向下同时选中下一个相同的文本进行同时编辑） Ctrl+G 跳转到相应的行 Shift+右击 块操作 Ctrl+Alt+F 快速格式化javascript代码 Reference[1]：http://jingyan.baidu.com/article/ff4116259b057c12e48237b8.html]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>sublime</tag>
        <tag>注册破解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github如何将代码回到过去]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2016-01-17-github%E5%A6%82%E4%BD%95%E5%B0%86%E4%BB%A3%E7%A0%81%E5%9B%9E%E5%88%B0%E8%BF%87%E5%8E%BB%2F</url>
    <content type="text"><![CDATA[github如何将代码回到过去 git 命令的使用对于阅读代码是非常有益处的 回到过去12$ git log$ git reset --hard b998bff6aa0f09a725d0186f289ccb9dd5481203 回到未来12$ git reflog$ git reset --hard 18548b2 git log 后无法退出 直接按q就可以退出，这点应该是沿袭了VI的标准 参考：【1】：http://www.imooc.com/video/4584]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>Latex</tag>
        <tag>Linux</tag>
        <tag>log</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python绘制基本图表全解答-持续更新中]]></title>
    <url>%2Fpython%2F2016-01-13-python%E7%BB%98%E5%88%B6%E5%9F%BA%E6%9C%AC%E5%9B%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[python绘制基本图表 参考网址：matplotlib官网 绘制折线图 如何绘制折线图 如何在matplotlib中加入latex公式 代码 12345678910111213141516171819202122232425262728293031# coding=utf-8import numpy as npimport matplotlib.pyplot as pltfrom matplotlib.font_manager import FontProperties# 引入Mac下的字体库# font = FontProperties(fname=r"/System/Library/Fonts/PingFang.ttc",size=15)#font_E = FontProperties(fname=r"/System/Library/Fonts/Times.dfont", size=15)#引入本地的字体库font = FontProperties(fname=r"c:\windows\fonts\simsun.ttc", size=14)font_E = FontProperties(fname=r"c:\windows\fonts\times.ttf", size=20) x = np.linspace(0,10,1000)y = np.sin(x)z = np.cos(x**2)plt.figure(figsize = (8,4))plt.plot(x,y,label="$sin(x)$",color="red",linewidth=2)plt.plot(x,z,"b--",label="$cos(x^2)$")plt.xlabel("Time(s)")plt.ylabel("Volt")plt.title("PyPlot First Example")plt.ylim(-1.2,1.2)plt.axhline(y=0.9,linewidth=1,color='k',label=u'similatline')plt.legend()#在图中加入test注释plt.text(x[100],y[100]+0.3, r'$\mu=100,\ \sigma=15$',fontproperties=font_E) plt.show() 效果 效果解释 label:给曲线一个标签名称。如果用’$’包裹起来，matplotlib会使用内嵌的LaTeX引擎将其显示为数学公式 xlim,ylim：分别设置X,Y轴的显示范围 使用LaTeX语法，会极大降低图表的描绘速度 实际上plot()是在Axes(子图)对象上绘图 axhline是绘制一条直线,x,y表示画的直线是哪个轴上的值 绘制柱状图 绘制柱状图 加入中文标题 代码 12345678910111213141516171819202122232425262728293031323334#coding=utf-8import matplotlibimport matplotlib.pyplot as pltimport numpy as npfrom matplotlib.font_manager import FontProperties#引入本地的字体库font = FontProperties(fname=r"c:\windows\fonts\simsun.ttc", size=14)font_E = FontProperties(fname=r"c:\windows\fonts\times.ttf", size=20) #这是需要进行绘图的list，list是可变的，不要管root_list = [[1,2],[3,4],[5,6],[7,8]]#对list的元素提取list_a = []list_b = []for item in root_list: list_a.append(item[0]) list_b.append(item[1])opacity = 0.4fig, ax = plt.subplots()bar_width = 0.4index = np.arange(len(list_a))p1 = plt.bar(index-0.2,list_a, bar_width,hatch='//',alpha=opacity,color='w')p2 = plt.bar(index+0.2,list_b, bar_width,hatch='\\',alpha=opacity,color='w')######这边需要手动改变下表值及个数#######plt.xticks(index, (u'一', u'二', u'三', u'四'),fontproperties=font)### 修改标题 ###plt.title(u'这是标题',fontproperties=font)######修改图例###########plt.legend((p1[0],p2[0]),(u'均值',u'峰值'),loc='upper left',prop=font)plt.show() 效果 绘制直方图代码 123456789101112131415161718192021222324import numpy as np import matplotlib.pyplot as plt mu,sigma=100,15 x=mu+sigma*np.random.randn(10000) n,bins,patches=plt.hist(x,50,normed=1,facecolor='g',alpha=0.75) plt.xlabel('Smarts') plt.ylabel('Probability') plt.title('Histogram of IQ') plt.text(60,.025, r'$\mu=100,\ \sigma=15$') plt.axis([40,160,0,0.03]) plt.grid(True)##不要坐标轴#plt.tick_params(labelbottom='off', labelleft='off', left='off', right='off',bottom='off', top='off')##使边框不显示#ax = plt.gca()#ax.spines['right'].set_color('none')#ax.spines['bottom'].set_color('none')#ax.spines['left'].set_color('none')#ax.spines['top'].set_color('none')plt.show() 效果 散点图代码 12345678910import matplotlib.pyplot as pltimport numpy as npplt.figure(figsize(8,4))x = np.random.random(100)y = np.random.random(100)plt.scatter(x,y,s=x*1000,c=y,marker=(5,1),alpha=0.8,lw=2,facecolors="none")plt.xlim(0,1)plt.ylim(0,1)plt.show() 效果 效果解释 scatter()的前两个参数是数组，分别指定每个点的X轴和Y轴。s参数指定点的大小，值和点的面积成正比。它可以是一个数，指定所有点的大小；也可以是数组，分别对每个点指定大小。 c参数指定每个点的颜色，可以是数值或数组。这里使用一维数组为每个点指定了一个数值。通过颜色映射表，每个值都会与一个颜色相对应。 marker参数设置点的形状，可以是一个表示形状的字符串，也可以是表示多边形的两个元素的元祖，第一个元素表示多边形的边数，第二个元素表示多边形的样式，取值范围是0，1，2，3.0表示多边形，1表示星形，2表示放射形，3表示圆。 最后，通过alpha设置点的透明度，通过lw设置线宽，facecolor表示填充色。 箱型图代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#coding=utf-8import numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom matplotlib.font_manager import FontProperties#引入本地的字体库font = FontProperties(fname=r"c:\windows\fonts\simsun.ttc", size=14)font_E = FontProperties(fname=r"c:\windows\fonts\times.ttf", size=20)np.random.seed(10)data_to_plot = [np.random.normal(100, 10, 200), np.random.normal(80, 30, 200), np.random.normal(90, 20, 200), np.random.normal(70, 25, 200)]fig = plt.figure(1, figsize=(9, 6))# Create an axes instanceax = fig.add_subplot(111)## add patch_artist=True option to ax.boxplot() ## to get fill colorbp = ax.boxplot(data_to_plot, patch_artist=True)## change outline color, fill color and linewidth of the boxesfor box in bp['boxes']: # change outline color box.set( color='#7570b3', linewidth=2) # change fill color box.set( facecolor = '#1b9e77' )## change color and linewidth of the whiskersfor whisker in bp['whiskers']: whisker.set(color='y', linewidth=2)## change color and linewidth of the capsfor cap in bp['caps']: # 上下的帽子 cap.set(color='#7570b3', linewidth=2)## change color and linewidth of the mediansfor median in bp['medians']: #中值 median.set(color='r', linewidth=2)## change the style of fliers and their fillfor flier in bp['fliers']: #异常值 flier.set(marker='o', color='k', alpha=0.5)## Custom x-axis labelsax.set_xticklabels(['1','2','3','4'],fontproperties=font_E)plt.ylabel("error(m)",fontproperties=font_E)plt.show() 效果 双轴图代码 123456789101112131415161718192021222324252627#coding=utf-8import numpy as npimport pandas as pdimport matplotlib.pyplot as pltfrom matplotlib.font_manager import FontProperties#引入本地的字体库font = FontProperties(fname=r"c:\windows\fonts\simsun.ttc", size=14)font_E = FontProperties(fname=r"c:\windows\fonts\times.ttf", size=20) particle_num = np.arange(50,1050,50)time_comsume = [0.00060916718125664639, 0.0013099725676996689, 0.0016603804020226163, 0.0020053920077506421, 0.0028140191440633685, 0.003849056531798165, 0.0033719783844652199, 0.0044824858560073731, 0.0045660351807216429, 0.0055148260934012273, 0.0060431263196179166, 0.0068409764220451084, 0.0065606520824997893, 0.007911049130791924, 0.0091536443509824192, 0.0089164429276458665, 0.009954174895170885, 0.010528301614314077, 0.012064690859812611, 0.010964955281054557]error_list = [1.2623084782819491, 1.1763773539878053, 1.1616158220269037, 1.1321476231320482, 1.13237038454, 1.1175918934736424, 1.1061712463307345, 1.13353829727, 1.13501225098, 1.12704532681, 1.1314668475, 1.1499213579690104, 1.1161069361015437, 1.1468033594361338, 1.1317538877380131, 1.1520113949657633, 1.1155484809619332, 1.133242220113426, 1.1257514347852002, 1.131728691883565]fig = plt.figure()ax1 = fig.add_subplot(111)p1, = ax1.plot(particle_num, error_list, label='Error', linewidth=2)ax1.set_ylabel('error(m)',fontproperties=font_E)ax2 = ax1.twinx()p2, = ax2.plot(particle_num, time_comsume, label='Time Consume', color = 'r', linewidth=2)ax2.set_ylabel('time consume(s)',fontproperties=font_E)ax1.set_xlabel('The number of particle',fontproperties=font_E)plt.xticks(fontproperties=font)plt.legend(handles=[p1,p2])plt.show() 效果 图片背景图代码 12345678910111213141516#coding=utf-8import matplotlib.pyplot as pltimport matplotlib.image as mpimgfrom matplotlib.font_manager import FontPropertiesimport numpy as npimport pandas as pd#引入本地的字体库font = FontProperties(fname=r"c:\windows\fonts\simsun.ttc", size=14)font_E = FontProperties(fname=r"c:\windows\fonts\times.ttf", size=20) image = mpimg.imread('./map.jpg')plt.imshow(image)plt.axis("off")#不显示坐标轴plt.show() 效果 Reference[1] http://matplotlib.org/gallery.html [2] http://liam0205.me/2014/09/11/matplotlib-tutorial-zh-cn/ [3] http://blog.csdn.net/golden1314521/article/details/44700551]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>折线图</tag>
        <tag>柱状图</tag>
        <tag>python绘图，Matplotlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[落户上海政策]]></title>
    <url>%2F%E7%94%9F%E6%B4%BB%2F2016-01-13-%E8%90%BD%E6%88%B7%E4%B8%8A%E6%B5%B7%E6%94%BF%E7%AD%96%2F</url>
    <content type="text"><![CDATA[2015年非上海生源普通高校应届毕业生进沪就业评分办法 落户上的基本政策如下 一、毕业生要素分（一）基本要素1.最高学位、学历 博士、研究生 27分 硕士、研究生 24分 学士、本科生 21分 2.毕业学校 “985工程”建设高校、在沪“211工程”建设高校、中科院在沪各研究所等研究生培养单位（名单见附件1） 15分 其它“211工程”建设高校、中央直属研究生培养单位、上海各高校及研究生培养单位（名单见附件2） 12分 其他高校及研究生培养单位 8分 3.学习成绩 （按照毕业生在校期间学习成绩专业（班级）综合排名对其等级进行评定） 一级（成绩综合排名前25％） 8分 二级（成绩综合排名26％-50％） 6分 三级（成绩综合排名51％-75％） 4分 四级（成绩综合排名76％-100％） 2分 4.外语水平 （外语水平证书一般应在所在学校或培养单位考点取得） CET-6级证书或成绩达到425分（含）以上、专业英语八级 8分 CET-4级证书或成绩达到425分（含）以上、专业英语四级 7分 外语类、艺术类、体育类专业外语课程合格 7分 5.计算机水平 毕业研究生 7分 理科类计算机高级水平或免予此项要求的专业（数学类、电子信息科学类、电气信息类、管理科学与工程类） 7分 文科类专业计算机中级或省级二级水平 7分 理科类专业计算机中级或省级二级水平 6分 文科类专业计算机初级或省级一级水平 6分 艺术、体育类专业相关课程合格 6分 （二）导向要素1.荣誉称号 （校级及以上级“三好学生”、“优秀学生”、“优秀学生干部”、“优秀毕业生”） 经认定的国家级 10分 省（自治区、直辖市）级 5分 学校级（每次1分，不超过2分） 2分 2.学术、文体竞赛获奖 （在全国大学生电子设计竞赛、全国大学生数学建模竞赛、全国大学生英语竞赛、全国大学生“挑战杯”赛、全国大学生“飞思卡尔杯”智能汽车竞赛等全国性比赛（含地方赛区）获奖） ⑴上述全国性比赛奖项： 一等奖 10分 二等奖 8分 三等奖 6分 ⑵上述全国性比赛地方赛区奖项： 一等奖 5分 二等奖 3分 三等奖 1分 （1.以上奖励表彰仅限在高校最高学历就读期间所获奖励表彰；2.同类奖励取最高分；3.荣誉类和竞赛类奖励可以累计加分，最高不超过15分。） 3.科研创新 拥有最高学历就读期间获得授权的发明专利证书并提供经学校（或培养单位）就业工作部门在本校网站上公示无异议、由指导教师签名的证明材料。落户申请人应为该专利首次申请时的发明人，如落户申请人为该专利首次申请后变更的发明人，须提交本人参与该项发明的相关证明材料，并经由专家认定 5分 （凡是通过转让获得的发明专利证书不予认定） 4.国家就业项目服务期满 上海高校毕业生参加西部计划服务期满（毕业生按照其毕业当年的评分办法予以评分，并在此基础上给予加分） 5分 上海高校毕业生参加“到村任职”、“三支一扶”计划服务期满按相关政策执行 二、用人单位要素分（一）基本要素 用人单位招聘高校毕业生行为诚信规范，并与毕业生直接签订录用协议 5分 （二）导向要素1.引进重点领域人才 用人单位录用上海市重点发展领域所需学科（专业）（见附件3）毕业生 3分 用人单位录用上海市重点发展领域所需学科中的教育部、上海市、上海市教委重点学科毕业研究生 3分 2.承担重大项目 用人单位承担国家和上海经济社会发展重大项目且录用的毕业生专业与行业相匹配 3分 用人单位为远郊地区教育、卫生、农业等社会公益事业单位 3分 （上述用人单位由各有关行业主管部门进行推荐，并报上海市高校毕业生就业工作联席会议办公室确认后予以公布） 3.自主创业（创业企业注册资金须到账（不含受让股份）且经营状况良好） ⑴创办市大学生科技创业基金资助的科技企业 获得科技创业基金资助企业的法定代表人 5分 ⑵创办其他企业 担任法定代表人 5分 三、标准分标准分为非上海生源进沪就业申请上海市户籍的基本资格分。进沪就业的非上海生源高校毕业生，其各项要素累积分值不低于标准分的，可办理上海市户籍；低于标准分的，可按照相关规定申请办理《上海市居住证》并获得相应的积分。 标准分由市教委、市人力资源社会保障局、市发展改革委联合发布，2015年为72分。 附件：1.“985工程”建设高校、在沪“211工程”建设高校、中科院在沪各研究所等研究生培养单位名单2.其它“211工程”建设高校、中央直属研究生培养单位、上海各高校和研究生培养单位名单3.上海市重点发展领域所需学科（专业）名单 说明：《非上海生源普通高校应届毕业生进沪就业评分办法》由上海市高校毕业生就业工作联席会议办公室制定，《评分办法》每年根据上海经济社会发展对非上海生源高校毕业生的需求及市政府相关政策进行必要的调整。 附件1：“985工程”建设高校、在沪“211工程”建设高校、中科院在沪各研究所等研究生培养单位名单(排名不分先后)北京大学清华大学中国人民大学北京师范大学南开大学天津大学大连理工大学东北大学吉林大学南京大学东南大学浙江大学厦门大学山东大学中国海洋大学复旦大学上海交通大学同济大学华东师范大学武汉大学华中科技大学湖南大学中南大学中山大学华南理工大学四川大学重庆大学电子科技大学西安交通大学兰州大学北京航空航天大学北京理工大学哈尔滨工业大学中国科学技术大学西北工业大学中央民族大学中国农业大学国防科学技术大学西北农林科技大学 东华大学上海财经大学华东理工大学上海外国语大学上海大学第二军医大学 中科院上海应用物理研究所中科院上海有机化学研究所中科院上海药物研究所中科院上海技术物理研究所中科院上海天文台中科院上海硅酸盐研究所中科院上海微系统与信息技术研究所中科院声学研究所东海研究站中科院上海生命科学研究院中科院上海光学精密机械研究所中科院上海高等研究院 上海社会科学院上海医药工业研究院 附件2：其它“211工程”建设高校、中央直属研究生培养单位、上海各高校和研究生培养单位名单（排名不分先后）北京交通大学北京工业大学北京科技大学北京邮电大学北京林业大学北京中医药大学北京外国语大学中国传媒大学对外经济贸易大学中央音乐学院东北师范大学东北农业大学中国矿业大学河海大学江南大学南京农业大学中国药科大学中国石油大学中国地质大学武汉理工大学西南交通大学西南财经大学西安电子科技大学长安大学北京化工大学南京理工大学天津医科大学河北工业大学太原理工大学内蒙古大学辽宁大学大连海事大学延边大学哈尔滨工程大学苏州大学南京航空航天大学南京理工大学南京师范大学安徽大学福州大学南昌大学郑州大学湖南师范大学暨南大学华南师范大学广西大学四川农业大学云南大学西北大学新疆大学第四军医大学中国政法大学华北电力大学中央财经大学东北林业大学合肥工业大学华中师范大学华中农业大学中南财经政法大学贵州大学西南大学北京体育大学陕西师范大学海南大学宁夏大学青海大学西藏大学石河子大学 中国科学院大学中国科学院各研究所中国社会科学院 上海理工大学上海海事大学上海音乐学院上海戏剧学院上海体育学院华东政法大学上海海洋大学上海电力学院上海中医药大学上海师范大学上海对外经贸大学上海工程技术大学上海应用技术学院上海金融学院上海立信会计学院上海第二工业大学上海电机学院上海商学院上海政法学院上海杉达学院上海建桥学院上海海关学院上海视觉艺术学院上海外国语大学贤达经济人文学院上海师范大学天华学院 上海材料研究所上海发电设备成套设计研究所上海内燃机研究所上海核工程研究设计院电子科学研究院华东计算技术所上海航天技术研究院煤炭科学研究总院上海分院上海化工研究院上海香料研究所上海船舶运输科学研究所电信科学技术第一研究所上海生物制品研究所上海船舶及海洋工程研究所舰船研究院上海船舶设备所舰船研究院上海船用柴油机所上海船舶电子设备研究所上海市计算技术研究所上海国际问题研究院中共上海市委党校中国航空研究院（640研究所）上海飞机研究所中国工程物理研究院上海激光等离子体研究所中国疾病预防控制中心寄生虫病预防所上海国家会计学院 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796797798799800801802803804805806807808809810811812813814815816817818819820821822823824825826827828829830831832833834835836837838839840841842843844845846847848849850851852853854855856857858859860861862863864865866867868869870871872873874875876877878879880881882883884885886887888889890891892893894895896897898899900901902903904905906907908909910911912913914915916917918919920921922923924925926927928929930931932933934935936937938939940941942943944945946947948949950951952953954955956957958959960961962963964965966967968969970971972973974975976977978979980981982983984985986987988989990991992993994995996997998999100010011002100310041005100610071008100910101011101210131014101510161017101810191020102110221023102410251026102710281029103010311032103310341035103610371038103910401041104210431044104510461047104810491050105110521053105410551056105710581059106010611062106310641065106610671068106910701071107210731074107510761077107810791080108110821083108410851086108710881089109010911092109310941095109610971098109911001101110211031104110511061107110811091110111111121113111411151116111711181119112011211122112311241125112611271128112911301131113211331134113511361137113811391140114111421143114411451146114711481149115011511152115311541155115611571158115911601161116211631164116511661167116811691170117111721173117411751176117711781179118011811182118311841185118611871188118911901191119211931194119511961197119811991200120112021203120412051206120712081209121012111212121312141215121612171218121912201221122212231224122512261227122812291230123112321233123412351236123712381239124012411242124312441245124612471248124912501251125212531254125512561257125812591260126112621263126412651266126712681269127012711272127312741275127612771278127912801281128212831284128512861287128812891290129112921293129412951296129712981299130013011302130313041305130613071308130913101311131213131314131513161317131813191320132113221323132413251326132713281329133013311332133313341335133613371338133913401341134213431344134513461347134813491350135113521353135413551356135713581359136013611362136313641365136613671368136913701371137213731374137513761377137813791380138113821383138413851386138713881389139013911392139313941395139613971398139914001401140214031404140514061407140814091410141114121413141414151416141714181419142014211422142314241425142614271428142914301431143214331434143514361437附件3：上海市重点发展领域所需学科（专业）一、研究生学科010101马克思主义哲学030500马克思主义理论010102中国哲学030501马克思主义基本原理010103外国哲学030502马克思主义发展史020101政治经济学030503马克思主义中国化研究020102经济思想史030504国外马克思主义研究020104西方经济学030505思想政治教育020105世界经济035100法律020201国民经济学035101法律(非法学)020202区域经济学035102法律(法学)020203财政学035200社会工作020204金融学040101教育学原理020205产业经济学040102课程与教学论020206国际贸易学040103教育史020208统计学040104比较教育学020209数量经济学040105学前教育学025100金融040106高等教育学025200应用统计040109特殊教育学025300税务040110教育技术学025400国际商务040200心理学025500保险040201基础心理学025600资产评估040202发展与教育心理学025700审计040203应用心理学027000统计学040300体育学030101法学理论040301体育人文社会学030102法律史040302运动人体科学030103宪法学与行政法学040303体育教育训练学030104刑法学040304民族传统体育学030105民商法学045102学科教学(思政)030106诉讼法学045103学科教学(语文)030107经济法学045104学科教学(数学)030109国际法学045105学科教学(物理)030201政治学理论045106学科教学(化学)030203科学社会主义与国际共产主义运动045107学科教学(生物)030204中共党史045108学科教学(英语)030207国际关系045109学科教学(历史)030300社会学045110学科教学(地理)030301社会学045111学科教学(音乐)030302人口学045112学科教学(体育)045113学科教学(美术)050405戏剧戏曲学045114现代教育技术050406电影学045115小学教育050407广播电视艺术学045116心理健康教育050408舞蹈学045117科学与技术教育055100翻译045118学前教育055101英语笔译045119特殊教育055102英语口译045200体育055103俄语笔译045201体育教学055104俄语口译045202运动训练055105日语笔译045203竞赛组织055106日语口译045204社会体育指导055107法语笔译045300汉语国际教育055108法语口译045400应用心理055109德语笔译048101学校课程与教学055110德语口译048102学生发展与教育055111朝鲜语笔译050100中国语言文学055112朝鲜语口译050101文艺学055200新闻与传播050102语言学及应用语言学055400出版硕士050103汉语言文字学060102考古学及博物馆学050104中国古典文献学065100文物与博物馆050105中国古代文学070101基础数学050106中国现当代文学070102计算数学050107中国少数民族语言文学070103概率论与数理统计050108比较文学与世界文学070104应用数学050200外国语言文学071000生物学050201英语语言文学071001植物学050202俄语语言文学071002动物学050203法语语言文学071003生理学050204德语语言文学071004水生生物学050205日语语言文学071005微生物学050206印度语言文学071006神经生物学050207西班牙语语言文学071007遗传学050208阿拉伯语语言文学071008发育生物学050209欧洲语言文学071009细胞生物学050210亚非语言文学071010生物化学与分子生物学050211外国语言学及应用语言学071011生物物理学050300新闻传播学071012生态学050301新闻学071300生态学050302传播学071400统计学050400艺术学077001教育技术学050401艺术学077002运动人体科学050402音乐学077100心理学050403美术学077101基础心理学050404设计艺术学077102发展与教育心理学077103应用心理学080800电气工程077300电子科学与技术080801电机与电器077301物理电子学080802电力系统及其自动化077302电路与系统080803高电压与绝缘技术077303微电子学与固体电子学080804电力电子与电力传动077304电磁场与微波技术080805电工理论与新技术077400计算机科学与技术080900电子科学与技术077401计算机系统结构080901物理电子学077402计算机软件与理论080902电路与系统077403计算机应用技术080903微电子学与固体电子学077600生物医学工程080904电磁场与微波技术077900药学081000信息与通信工程077901药物化学081001通信与信息系统077902药剂学081002信号与信息处理077903生药学081100控制科学与工程077904药物分析学081101控制理论与控制工程077905微生物与生化药学081102检测技术与自动化装置077906药理学081103系统工程078000材料科学与工程081104模式识别与智能系统078001材料物理与化学081105导航、制导与控制078002材料学081200计算机科学与技术078100中药学081201计算机系统结构080200机械工程081202计算机软件与理论080201机械制造及其自动化081203计算机应用技术080202机械电子工程081300建筑学080203机械设计及理论081301建筑历史与理论080204车辆工程081302建筑设计及其理论080400仪器科学与技术081303城市规划与设计080401精密仪器及机械081304建筑技术科学080402测试计量技术及仪器081400土木工程080500材料科学与工程081401岩土工程080501材料物理与化学081402结构工程080502材料学081403市政工程080503材料加工工程081404供热、供燃气、通风及空调工程080600冶金工程081405防灾减灾工程及防护工程080601冶金物理化学081406桥梁与隧道工程080602钢铁冶金081500水利工程080603有色金属冶金081503水工结构工程080700动力工程及工程热物理081505港口、海岸及近海工程080701工程热物理081700化学工程与技术080702热能工程081701化学工程080703动力机械及工程081702化学工艺080704流体机械及工程081703生物化工080705制冷及低温工程081704应用化学080706化工过程机械081705工业催化082100纺织科学与工程085234车辆工程082101纺织工程085235制药工程082102纺织材料与纺织品设计085236工业工程082103纺织化学与染整工程085237工业设计工程082104服装设计与工程085238生物工程082300交通运输工程085239项目管理082301道路与铁道工程085240物流工程082302交通信息工程及控制085300城市规划082303交通运输规划与管理087100管理科学与工程082304载运工具运用工程087200设计学082400船舶与海洋工程100207影像医学与核医学082401船舶与海洋结构物设计制造100209护理学082402轮机工程100217麻醉学082403水声工程100700药学082404运载工具运用工程100701药物化学082500航空宇航科学与技术100702药剂学082501飞行器设计100703生药学082502航空宇航推进理论与工程100704药物分析学082503航空宇航制造工程100705微生物与生化药学082504人机与环境工程100706药理学083100生物医学工程100800中药学083300城乡规划学101100护理学083400风景园林学105107影像医学与核医学083500软件工程105116麻醉学085100建筑学105400护理085201机械工程105500药学085203仪器仪表工程105600中药学085204材料工程107002运动人体科学085205冶金工程107200生物医学工程085206动力工程107302社会医学与卫生事业管理085207电气工程107401社会医学与卫生事业管理085208电子与通信工程108107影像医学与核医学085209集成电路工程108116麻醉学085210控制工程120100管理科学与工程085211计算机技术120200工商管理085212软件工程120201会计学085213建筑与土木工程120202企业管理085214水利工程120203旅游管理085216化学工程120204技术经济及管理085220纺织工程120302林业经济管理085222交通运输工程120402社会医学与卫生事业管理085223船舶与海洋工程120404社会保障085230生物医学工程125100工商管理085232航空工程125300会计085233航天工程125400旅游管理125600工程管理130100艺术学理论130200音乐与舞蹈学130300戏剧与影视学130400美术学130500设计学135100艺术135101音乐135102戏剧135103戏曲135104电影135105广播电视135106舞蹈135107美术135108艺术设计二、本科专业02010100经济学05022600阿尔巴尼亚语02010200国际经济与贸易05022700保加利亚语02010400金融学05022800波兰语02010700保险05022900捷克语03030100社会学05023000罗马尼亚语04010100教育学05023100葡萄牙语04010200学前教育05023200瑞典语04010300特殊教育05023300塞尔维亚—克罗地亚语04010400教育技术学05023400土耳其语04010500小学教育05023500希腊语04010600艺术教育05023600匈牙利语04020100体育教育05023700意大利语04020200运动训练05023800捷克语—斯洛伐克语05010100汉语言文学05023900泰米尔语05010300对外汉语05024000普什图语05020000外国语言文学类05024100世界语05020100英语05024200孟加拉语05020200俄语05024300尼泊尔语05020300德语05024400塞尔维亚语—克罗地亚语05020400法语05024500荷兰语05020500西班牙语05024600芬兰语05020600阿拉伯语05024700乌克兰语05020700日语05024800韩国语05020800波斯语05025000塞尔维亚语05020900朝鲜语05025100克罗地亚语05021000菲律宾语05025200挪威语05021100梵语巴利语05025300丹麦语05021200印度尼西亚语05025400冰岛语05021300印地语05025500翻译05021400柬埔寨语05030100新闻学05021500老挝语05040000艺术类05021600缅甸语05040100音乐学05021700马来语05040200作曲与作曲技术理论05021800蒙古语05040300音乐表演05021900僧加罗语05040400绘画05022000泰语05040500雕塑05022100乌尔都语05040600美术学05022200希伯莱语05040700艺术设计学05022300越南语05040800艺术设计05022400豪萨语05040900舞蹈学05022500斯瓦希里语05041000舞蹈编导05041100戏剧学08061100软件工程05041200表演08070600城市地下空间工程05041300导演08072400道路桥梁与渡河工程05041400戏剧影视文学08080300港口航道与海岸工程05041500戏剧影视美术设计08080400港口海岸及治河工程05041600摄影08110200制药工程05041700录音艺术08120400飞行技术05041800动画08130100船舶与海洋工程05041900播音与主持艺术08140500纺织工程05042000广播电视编导08140600服装设计与工程05042200艺术学08150000航空航天类05042300影视学08150100飞行器设计与工程05042400广播影视编导08150200飞行器动力工程05042500书法学08150300飞行器制造工程05042600照明艺术08150400飞行器环境与生命保障工程05042700会展艺术与技术08150500航空航天工程05042800音乐科技与艺术08150600工程力学与航天航空工程06010300考古学08150700航天运输与控制07030200应用化学08150800质量与可靠性工程07040100生物科学10010100基础医学07040200生物技术10030200麻醉学07040500生物科学与生物技术10030300医学影像学07120000电子信息科学类10050100中医学07120100电子信息科学与技术10070000护理学类07120200微电子学10070100护理学07120300光信息科学与技术10080200中药学07120400科技防卫10080300药物制剂07120500信息安全11020300会计学07120600信息科学技术13020200音乐学07120700光电子技术科学13020300作曲与作曲技术理论08020300无机非金属材料工程13020100音乐表演08020400高分子材料与工程13040200绘画08020500材料科学与工程13040300雕塑08020600复合材料与工程13040100美术学08030200材料成型及控制工程13050100艺术设计学08030300工业设计13020500舞蹈学08060100电气工程及其自动化13020600舞蹈编导08060200自动化13030200戏剧学08060300电子信息工程13030100表演08060400通信工程13030400戏剧影视文学08060500计算机科学与技术13030700戏剧影视美术设计08060600电子科学与技术13040400摄影08060700生物医学工程13030800录音艺术08060800电气工程与自动化13030900播音与主持艺术08060900信息工程13031000动画13030500广播电视编导13040500书法学]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>落户上海</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[傅里叶变换的理解（二）]]></title>
    <url>%2F%E8%AF%BE%E7%A8%8B%E7%A0%94%E7%A9%B6%2F2015-12-30-%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%E7%90%86%E8%A7%A3%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[傅里叶变换学习笔记（二） 之前一篇的傅里叶变换的学习主要还是连续型的理论分析，然后这一篇文章主要从离散信号去做分析以及展示具体的代码使用。因为在现实的世界中，主要的信号都是以离散的形式采集出来的，所以最主要的是离散的去分析信号的时域数据。 一维离散傅里叶变换变换公式$$ F\left ( u \right ) = \frac{1}{N}\sum_{x=0}^{N-1}f\left ( x \right )e^{-j\frac{2\pi ux}{N}} (u = 0,1,…,N-1) $$ 频谱、相位角和功率谱F(u)为复函数，可表示为： $$ F\left ( u \right ) = R\left ( u \right )+jI\left ( u \right ) $$ 频谱(幅值): $$ F\left ( u \right ) = \left [ R^{2}\left ( u \right )+I^{2}\left ( u \right )\right ]^{\frac{1}{2}} $$ 相位角：$$ \left | \phi \left ( u \right ) \right |=arctan\left [ I\left ( u \right )/R\left ( u \right ) \right ] $$ 功率谱：$$ P\left ( u \right ) = \left |F\left ( u \right ) \right |^{2}= R^{2}\left ( u \right )+I^{2}\left ( u \right ) $$ 一维实例$$ e^{-j2\pi ux}=cos(2\pi ux) - j sin(2\pi ux) $$ 题目: 求解过程： 详细解答过程: 二位离散傅里叶变换变换公式$$ F\left ( u,v \right ) = \frac{1}{N}\sum_{x=0}^{N-1}\sum_{y=0}^{N-1}f\left ( x,y \right )e^{\left [ -j2\pi \left ( \frac{ux+vy}{N} \right ) \right ]}\left ( u,v = 0,1,…,N-1 \right ) $$ 二维实例题目: 求解过程： python中使用傅里叶变换公式示例代码 123456789101112131415161718#conding = utf-8import numpy as npimport mathimport matplotlib.pyplot as pltsignal = []#生成叠加正弦函数的数据for j in range(1000): i = j/1000.0 temp = math.cos(2*math.pi*10*i) + math.cos(2*math.pi*25*i) + math.cos(2*math.pi*50*i) + math.cos(2*math.pi*100*i) signal.append(temp)#对正弦波进行傅里叶变换signalF = np.fft.fft(signal)#计算出信号频谱fre = np.abs(signalF)#绘制图像#plt.plot(range(1000), signal, '-', linewidth=1)plt.plot(range(250), fre[0:250], '-', linewidth=1)plt.show()]]></content>
      <categories>
        <category>课程研究</category>
      </categories>
      <tags>
        <tag>傅里叶</tag>
        <tag>信号处理</tag>
        <tag>WIFI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Splitting and Merging--区域分裂与合并算法]]></title>
    <url>%2F%E8%AF%BE%E7%A8%8B%E7%A0%94%E7%A9%B6%2F2015-12-6-region_split_merging%2F</url>
    <content type="text"><![CDATA[区域分裂与合并算法基本思想：先确定一个分裂合并的准则,即区域特征一致性的量度,当图像中某个区域的特征不一致时就将该区域分裂成4个相等的子区域,当相邻的子区域满足一致性特征时则将它们合成一个大区域,直至所有区域不再满足分裂合并的条件为止.当分裂到不能再分的情况时，分裂结束，然后它将查找相邻区域有没有相似的特征，如果有就将相似区域进行合并，最后达到分割的作用。在一定程度上区域生长和区域分裂合并算法有异曲同工之妙，互相促进相辅相成的，区域分裂到极致就是分割成单一像素点，然后按照一定的测量准则进行合并，在一定程度上可以认为是单一像素点的区域生长方法。区域生长比区域分裂合并的方法节省了分裂的过程，而区域分裂合并的方法可以在较大的一个相似区域基础上再进行相似合并，而区域生长只能从单一像素点出发进行生长（合并）。 分裂原理分裂的过程123456Set ProcessList = IMAGERepeat 取出 ProcessList 中第一个元素 IF 区域内是均匀的，则加入 RegionList Else 把区域分成四个自区域，然后都加到 ProcessListUntil ( ProcessList 中没有元素) 如何判断是否可以分裂对于一个灰度图，如果说某一区域是均匀的，那么该区域所有灰度值的标准差需要小于一定的阈值，标准差的公式如下： $$ \sigma = \left [ \frac{1}{N-1} \sum{j=1}^{N} \left ( x{j}-\bar{x} \right )^{2}\right ] $$ 合并原理合并的过程1234567Put all regions on ProcessListRepeat 从 ProcessList 每次取出一个元素 遍历列表中的元素，找到相似的元素 (homogeneity criterion) If 相邻 then 合并区域 然后上面的步骤;until (不能合并为止) 如何判断可以合并分裂与合并如果只使用拆分，最后的分区可能会包含具有相同性质的相邻区域。这种缺陷可以通过进行拆分的同时也允许进行区域聚合来得到矫正。就是说，只有在P(Rj∪Rk)=TRUE时，两个相邻的区域Rj和Rk才能聚合。 前面的讨论可以总结为如下过程。在反复操作的每一步，我们需要做： 1231.对于任何区域Ri，如果P(Ri)=FALSE，就将每个区域都拆分为4个相连的象限区域。2.将P(Rj∪Rk)=TRUE的任意两个相邻区域Rj和Rk进行聚合。3.当再无法进行聚合或拆分时操作停止。 开始时将图像拆分为一组图象块。然后对每个块进一步进行上述拆分，但聚合操作开始时受只能将4个块并为一组的限制。这4个块是四叉树表示法中节点的后代且都满足谓词P。当不能再进行此类聚合时，这个过程终止于满足步骤2的最后的区域聚合。在这种情况下，聚合的区域可能会大小不同。这种方法的主要优点是对于拆分和聚合都使用同样的四叉树，直到聚合的最后一步。 实验分析Matlab源码 源码一:splitmerge.m 12345678910111213141516171819202122232425262728function g = splitmerge( f,mindim,fun )Q = 2^nextpow2(max(size(f)));[M,N] = size(f);f = padarray(f,[Q-M,Q-N],'post');S = qtdecomp(f,@split_test,mindim,fun);Lmax = full(max(S(:)));g = zeros(size(f));MARKER = zeros(size(f));for K = 1:Lmax [vals,r,c] = qtgetblk(f,S,K); if ~isempty(vals) for I = 1:length(r) xlow = r(I); ylow = c(I); xhigh = xlow + K - 1; yhigh = ylow + K - 1; region = f(xlow:xhigh,ylow:yhigh); flag = feval(fun, region); if flag g(xlow:xhigh,ylow:yhigh) = 1; MARKER(xlow,ylow) = 1; end end endendg = bwlabel(imreconstruct(MARKER,g));g = g(1:M,1:N);end 源码二:split_test.m 123456789101112131415function v = split_test( B,mindim,fun )k = size(B,3);v(1:k) = false;for I = 1:k quadregion = B(:, :, I); if size(quadregion,1) &lt;= mindim v(I) = false; continue end flag = feval(fun,quadregion); if flag v(I) = true; endendend 源码三:predicate.m 12345function flag = predicate( region )sd = std2(region);m = mean2(region);flag = (sd &gt; 10) &amp; (m &gt; 0) &amp; (m &lt; 255);end 效果图实验一 原图 处理后的图 实验二 原图 处理后的图 实验三 原图 处理后的图 参考文章[1] http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/MARBLE/medium/segment/split.htm [2] http://blog.csdn.net/bagboy_taobao_com/article/details/5666109 [3] http://blog.csdn.net/bagboy_taobao_com/article/details/5666091 [4] 冈萨雷斯-数字图像处理（MATLAB版）]]></content>
      <categories>
        <category>课程研究</category>
      </categories>
      <tags>
        <tag>Splitting</tag>
        <tag>Merging</tag>
        <tag>图像分裂与合并</tag>
        <tag>spam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WIFI室内定位技术的详细介绍-指纹法]]></title>
    <url>%2F%E8%AF%BE%E7%A8%8B%E7%A0%94%E7%A9%B6%2F2015-12-2-WIFI%E5%AE%A4%E5%86%85%E5%AE%9A%E4%BD%8D%E6%8A%80%E6%9C%AF%E7%9A%84%E4%BB%94%E7%BB%86%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[WIFI室内定位技术的详细介绍-位置指纹法1、室内定位方法概述位置信息在我们生活中扮演着越来越重要的角色。例如，医疗行业中病人的跟踪监护、产房中婴儿的防偷、贵重医疗设备的监控；商品购物车的定位、顾客消费习惯的收集等等。然而卫星定位需要在相对空旷、高层建筑不密集的地方才能实现比较准确的定位，户内无法使用且耗电量较高。但是当终端接收机在楼群密集的城市或者室内工作的时候，由于信号强度受到建筑物的影响而大大衰减，导致定位精度低甚至不能够完成定位。于是无线室内定位技术迅速发展，包括WIFI、RFID（射频识别）、蓝牙、红外、声信号、超声波等短距离无线技术。其中基于WIFI网络的无线定位技术由于部署广泛且成本较低，因此备受关注。WIFI无线定位可以采用最强AP法，三边测量法，位置指纹法。但是无论哪种方法，都需要通过WIFI信道扫描的方式来获取AP的相关信息，如AP的BSSID,以及RSSI. 下图为我们具体的实验架构图： 2、实验环境描述首先说明我的实验都是在python2.7环境中实现的，如果没有python环境最好下个python(x,y)，把python环境安装一下。 我的demo实验主要是在江南大学的实验楼的一层中做的，在楼层中我主要采集了下面五角星标记的８个位置点的信息,数据采样和定位效果展示都是在这几个点实现的，如果读者要全部平面实现定位那就需要大量的工作量。 3、室内定位过程第一步：采集WIFI指纹数据1.采集工具 在360应用市场上搜索—Sensor log 2.采集过程用上面的Android程序在每个点下面采集单WIFI信息两分钟（１分钟也可以），那个程序可以定制每个位置的名字和所用到的传感器，我就定制了loc1-loc8的按钮，每个只要采集WIFI信号就行了。采集到的信息如下： 12|WiFi|&#123;&quot;BSSID&quot;:&quot;74:25:8a:47:36:d0&quot;,&quot;HexSSID&quot;:&quot;0x4169724a&quot;,&quot;SSID&quot;:&quot;AirJ&quot;,&quot;capabilities&quot;:&quot;[ESS]&quot;,&quot;wifiSsid&quot;:&#123;&quot;SSID&quot;:&quot;AirJ&quot;,&quot;octets&quot;:&#123;&quot;buf&quot;:[65,105,114,74,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],&quot;count&quot;:4&#125;&#125;,&quot;blackListTimestamp&quot;:0,&quot;seen&quot;:1448621242439,&quot;timestamp&quot;:10534923676,&quot;autoJoinStatus&quot;:0,&quot;distanceCm&quot;:-1,&quot;distanceSdCm&quot;:-1,&quot;frequency&quot;:2462,&quot;isAutoJoinCandidate&quot;:1,&quot;level&quot;:-33,&quot;numConnection&quot;:0,&quot;numIpConfigFailures&quot;:0,&quot;numUsage&quot;:0,&quot;untrusted&quot;:False&#125;|1448614784698 采集完成后将log.txt文件导出来，在下面的建立指纹数据库的过程中，最主要的需要用到BSSID和level。 第二步：建立指纹数据库如何构建指纹数据库呢，主要就是将上面在每个位置采集的两分钟的数据，按照AP（路由器）的Mac地址区分，将两分钟内的RSS（信号强度）求均值。可能在我的算法中还求了标准差。 建立指纹数据库的算法如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990#coding=utf-8import numpy as npimport json #the type database will be write into database as the format of jsonimport mathimport re'''this code is to create fingerprint database ''''''@author nezha 2015/08/04'''DB_FN = "log.txt" #原始数据源DB_LandMark="LMDB_std" #目标数据库#open the file of wifi infof_db = open(DB_FN)f_lmdb = open(DB_LandMark,'w')#当是1 0的时候可以读取位置信息#当是1 1的时候读取WiFi信息StrStart = 'statusId | label';StrEnd = 'statusId|sensorName|value|timestamp';FlagStart = 0 FlagEnd = 0dictRF = &#123;&#125;dictWiFi = &#123;&#125; #the item of string which will write into fileFlagLoc = '0' #init the flag of Loc positionwhile True: #逐行读取 line = f_db.readline() #去除空格或者换行符 line = line.strip() if not line or len(line) &lt; 5: dictLoc = &#123;&#125;; for key in dictWiFi.keys(): if len(dictWiFi[key]) &gt; 5: dictWiFi[key] = [np.mean(dictWiFi[key]),np.std(dictWiFi[key])]; else: del(dictWiFi[key]); dictLoc['loc'] = dictRF[FlagLoc]; #get last loc #print FlagLoc; dictLoc['wifi'] = dictWiFi; outLine = str(dictLoc); f_lmdb.write(outLine) f_lmdb.flush() break if line == StrStart: FlagStart = 1 if line == StrEnd: FlagEnd = 1 if FlagStart is 1 and FlagEnd is 0 and line != StrStart and line != StrEnd: #start read the location and label listTemp = line.split('|'); dictRF[listTemp[0]] = listTemp[1]; elif FlagStart is 1 and FlagEnd is 1 and line != StrStart and line != StrEnd: #start read the wifi info listTemp = line.split('|'); dictLine = eval(listTemp[2]); #get wifi info if FlagLoc == '0': #if is the init Flag ,init data FlagLoc = listTemp[0]; if FlagLoc == listTemp[0]: if dictLine['BSSID'] not in dictWiFi.keys(): dictWiFi[dictLine['BSSID']] = [int(dictLine['level'])]; else: dictWiFi[dictLine['BSSID']].append(int(dictLine['level'])); else: dictLoc = &#123;&#125;; for key in dictWiFi.keys(): if len(dictWiFi[key]) &gt; 60: dictWiFi[key] = [np.mean(dictWiFi[key]),np.std(dictWiFi[key])]; else: del(dictWiFi[key]); dictLoc['loc'] = dictRF[FlagLoc]; #get last loc dictLoc['wifi'] = dictWiFi; outLine = str(dictLoc); outLine = outLine + '\n' f_lmdb.write(outLine) f_lmdb.flush() dictWiFi = &#123;&#125;; dictLoc = &#123;&#125;; FlagLoc = listTemp[0]; #new Flag if dictLine['BSSID'] not in dictWiFi.keys(): dictWiFi[dictLine['BSSID']] = [int(dictLine['level'])]; else: dictWiFi[dictLine['BSSID']].append(int(dictLine['level'])); f_db.close()f_lmdb.close() 抽象出来后的图如下： 具体的指纹数据库的内容如下： 123&#123;'loc': 'loc1', 'wifi': &#123;'74:25:8a:47:35:e0': [-90.88732394366197, 1.4393787370187285], '74:25:8a:47:36:90': [-45.328947368421055, 5.941354085193962], '74:25:8a:47:3a:30': [-78.28947368421052, 0.7748648349650241], '74:25:8a:47:3a:e0': [-75.27631578947368, 1.6270629351730226]&#125;&#125;&#123;'loc': 'loc2', 'wifi': &#123;'74:25:8a:47:36:90': [-33.84415584415584, 1.5294930410843932], '74:25:8a:47:3a:e0': [-71.7012987012987, 0.8836896538287793], '74:25:8a:47:3a:10': [-84.0, 0.0], '70:f9:6d:2b:85:b0': [-85.06493506493507, 0.9978894915479763]&#125;&#125;&#123;'loc': 'loc3', 'wifi': &#123;'74:25:8a:47:36:90': [-52.734939759036145, 4.741725417622794], '74:25:8a:47:3a:e0': [-80.26506024096386, 2.0888939677301046], '74:25:8a:47:3a:10': [-84.0, 0.0], '70:f9:6d:2b:85:b0': [-86.0, 0.0]&#125;&#125; 第三步：定位算法的描述定位算法主要实现的是RADAR的KNN算法，这种算法简单且效果好。算法的实现都已经按照对象的思想整理过了，代码如下： KNN的主要思想： 将loc1的指纹数据的内容拿出与查询位置的WIFI指纹中的所有AP取一个交集 将交集中AP对应的RSSI（信号强度）计算欧式距离平方和，然后放到数组中 循环上面步骤，直到loc1~loc8的指纹数据库中的条目都比较过之后 取出欧式距离平方和最小的对应的位置输出 1234567891011121314151617181920212223242526272829303132333435363738394041424344#coding=utf-8import stringfrom scipy import statsimport mathclass DBEntry: location = '' def __init__(self): self.location = '' self.ap_rss_dict = &#123;&#125; #need init or all object will use the same apRssiList to appendclass LMDB(list): #extend the list def __init__(self,path):#read the file and add DBEntry to self f = open(path); while True: line = f.readline(); line = line.strip(); if not line:break; line = eval(line); #set the str to dict db_entry = DBEntry(); db_entry.location = line['loc']; db_entry.ap_rss_dict = line['wifi']; self.append(db_entry); f.close(); def __calDiatance(self,query_entry, db_entry): query_aps = set(query_entry.keys()); db_aps = set(db_entry.keys()); all_aps = query_aps &amp; db_aps; distance = 0.0; sum = 0.0 for singleAp in all_aps: sum = sum + (query_entry[singleAp]-db_entry[singleAp][0])**2; distance = sum; return distance/len(all_aps); #use knn lm_str format as &#123;'mac1':level,'mac2':level2&#125; def nn_location(self,lm_str): client_entry = eval(lm_str); distance_list = []; for db_entry in self: distance = self.__calDiatance(client_entry,db_entry.ap_rss_dict); distance_list.append(distance); nn_index = distance_list.index(min(distance_list)); return self[nn_index].location; 第四步：离线模拟仿真 我的源码已经上传到github了，在这里，可以自行下载 其中log.txt是用于构建指纹数据库的原始WIFI采样数据 执行create_lmdb.py时就会自动生成LMDB_std文件的指纹数据库 然后LMDB.py中是KNN算法 执行client_demo.py可以看到具体的定位效果 其中loc1-loc8 是我在实验环境中的模拟位置采集指纹数据 4、存在的不足与展望不足： RSSI容易受到环境的影响产生波动 建立指纹库太复杂 指纹数据更新复杂 展望： 结合航位推算和WIFI Landmark 结合大数据应用到商业 结合医疗 5、参考文献[1] https://github.com/nezha/WIFIDemo [2] Bahl P, Padmanabhan V N. RADAR: An in-building RF-based user location and tracking system[C]. IEEE. Ieee, 2000, 2: 775-784.]]></content>
      <categories>
        <category>课程研究</category>
      </categories>
      <tags>
        <tag>室内定位</tag>
        <tag>KNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[傅里叶变换的理解（一）]]></title>
    <url>%2F%E8%AF%BE%E7%A8%8B%E7%A0%94%E7%A9%B6%2F2015-11-30-%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2%E7%90%86%E8%A7%A3(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[傅里叶变换学习笔记（一） 在学习无线网络实现室内定位的过程中，发现信号强度的波动受到来自各个方面的影响以及自身的噪声影响。所以在学习图像处理的过程中，发现傅里叶变换能将时域信号转换到频域上，在频域上信号的强度实则是多个正弦波的叠加。所以在WiFi信号中应该是可以使用傅里叶变换发现一些在时域无法发现的特征，应该在处理噪声上也有一定的帮助。 学习傅里叶变化的三个层次 学习傅里叶变化可以分三步去理解：傅里叶变换（Fourier Transform，FT）-&gt; 离散傅里叶变换（Discrete Fourier Transform， DFT）-&gt; 快速傅里叶变换（Fast Fourier Transform） FT是理论基础，以FT为理论基础，可以完成从频率估计到求解微分方程各式各样的问题； DFT是指信号被采样之后会得到离散而非连续的信号，这个时候就需要DFT来告诉你怎样处理并告知你一些离散情况下的特殊问题 FFT是一种计算DFT的算法，计算复杂度很低也就是执行起来很快的意思。 一、什么是频域频域就是一个信号所具有的所有正弦分量的频率的总合，任何一个周期信号都可以分解为以不同振幅和频率或相位的正弦波为分量的级数，所有分量的频率的总合叫该信号的频域，频域和时域都是对非正弦信号的分析方法。 时域（信号对时间的函数）和频域（信号对频率的函数）的变换在数学上是通过积分变换实现，对周期信号可以直接使用傅立叶变换，对非周期信号则要进行周期扩展，使用拉普拉斯变换。而傅式级数只是对信号的分解。 二、傅里叶级数(Fourier Series)的频谱在实际环境中很多我们采集到的波形都是可以分解成很多个正弦波。正如下图所表示的。 这些正弦波按照频率从低到高从前向后排列开来，而每一个波的振幅都是不同的。每两个正弦波之间都还有一条直线，那并不 是分割线，而是振幅为 0 的正弦波！为了组成特殊的曲线，有些正弦波成分是不需要的。 其实有些关于正弦波的基础知识我们在初中都已经学过了，函数f(x)=Asin(wx+β)中的A就是振幅，最小正周期T=2π/w，频率f=1/T，初始相位角是β。 正弦波就是一个圆周运动在一条直线上的投影。所以频域的基本单元也可以理解为一个始终在旋转的圆 理解了频域的基本组成单元，继续理解上面的矩形波在频域里的另一个模样： 可能，只有幅值和频率的关系不是很直观，然后又找到下面的一张图： 将时域和频域集合在一张图上理解就成下面这样了： 三、傅里叶级数（Fourier Series）的相位谱通过时域到频域的变换，可以得到了一个从侧面看的频谱，但是这个频谱并没有包含时域中全部的信息。因为频谱只代表每一个对应的正弦波的振幅是多少，而没 有提到相位。基础的正弦波A.sin (wt+θ)中，振幅，频率，相位缺一不可，不同相位决定了波的位置，所以对于频域分析，仅仅有频谱（振幅谱）是不够的，我们还需要一个相位谱。下面的一张图就可以比较直观的理解相位谱了。 鉴于正弦波是周期的，我们需要设定一个用来标记正弦波位置的东西。在图中就是那些小红点。小红点是距离频率轴最近的波峰，而这个波峰所处的位置离频率轴 有多远呢？为了看的更清楚，我们将红色的点投影到下平面，投影点我们用粉色点来表示。当然，这些粉色的点只标注了波峰距离频率轴的距离，并不是相位。 四、傅里叶变换（Fourier Tranformation）傅里叶变换总体来说有以下几中类型，上面已经将傅里叶级数理解了，然后继续参控维基理解傅里叶变换的公式及推导。 变换 时间 频率 连续傅里叶变换 连续，非周期性 连续，非周期性 傅里叶级数 连续，周期性 离散，非周期性 离散时间傅里叶变换 离散，非周期性 连续，周期性 离散傅里叶变换 离散，周期性 离散，周期性 4.1 连续傅里叶变换wiki定义：连续傅里叶变换是一个特殊的把一组函数映射为另一组函数的线性算子。 不严格地说，傅里叶变换就是把一个函数分解为组成该函数的连续频率谱。 在数学分析中，信号f(t)的傅里叶变换被认为是处在频域中的信号。 假设f是一个可积的函数。 我们定义其连续傅里叶变换F也是一个复函数:对任意实数 ω (这里i是虚数单位) ω是角频率，F(ω)为复数，并且是信号在该频率成分处的相位和幅度。 傅里叶变换是自反映射，若 F(ω)如上定义，f是连续的，则对于任意实数 t 每个积分前的根号下2pi分之一为规范化因子。 因子的选择是主观任意的，只要满足二者的乘积为$$1 \over {2\pi}$$ 4.2 离散时间傅里叶变换(没有看完)五、欧拉公式虚数i这个概念在高中就接触过，但那时我们只知道它是-1 的平方根，可是它真正的意义是什么呢? 这里有一条数轴，在数轴上有一个红色的线段，它的长度是1。当它乘以 3 的时候，它的长度发生了变化，变成了蓝色的线段，而当它乘以-1 的时候，就变成了绿色的线段，或者说线段在数轴上围绕原点旋转了 180 度。 知道乘-1 其实就是乘了两次 i 使线段旋转了 180 度，那么乘一次 i 呢——答案很简单——旋转了 90 度。 同时，我们获得了一个垂直的虚数轴。实数轴与虚数轴共同构成了一个复数的平面，也称复平面。这样我们就了解到，乘虚数i的一个功能——旋转。欧拉公式： $$ e^{ix} = cosx + i\cdot sinx $$ 当x等于 Pi 的时候: $$ e^{i\pi} + 1 = 0 $$这个公式关键的作用，是将正弦波统一成了简单的指数形式。我们来看看图像上的涵义： 欧拉公式所描绘的，是一个随着时间变化，在复平面上做圆周运动的点，随着时间的改变，在时间轴上就成了一条螺旋线。如果只看它的实数部分，也就是螺旋线在左侧的投影，就是一个最基础的余弦函数。而右侧的投影则是一个正弦函数。 Reference：[1] https://zh.wikipedia.org/wiki/ -&gt;傅里叶变换 [2] http://blog.jobbole.com/70549/ @花生油工人 [3] http://baike.baidu.com/ -&gt; 傅里叶变换]]></content>
      <categories>
        <category>课程研究</category>
      </categories>
      <tags>
        <tag>傅里叶</tag>
        <tag>图像处理</tag>
        <tag>信号处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jekyll使用MathJax来显示数学式]]></title>
    <url>%2F%E7%96%91%E9%9A%BE%E8%A7%A3%E6%83%91%2F2015-11-26-Jekyll%E6%94%AF%E6%8C%81Latex%E5%85%AC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[网页中嵌入公式的方法 我自己使用后的感觉是，虽然，MathJax很方便，但是有些时候会出现无法识别的问题。所有很多时候我是结合起来用的。 使用网上的一些服务生成公式图片，如这里 使用MathJax来显示数学式. 使用MathJax显示公式 修改html头部 在需要使用的页面开头加上这么一句，在Jekyll下可以通过修改default.html加上。 123&lt;script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"&gt;&lt;/script&gt; 然后直接调用公式和Latex公式一致的，没有太多难点，可以参考这个站点]]></content>
      <categories>
        <category>疑难解惑</category>
      </categories>
      <tags>
        <tag>Jekyll</tag>
        <tag>Latex公式</tag>
        <tag>MathJax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[增加JiaThis的分享和友言评论插件及百度统计]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2015-11-26-%E5%88%86%E4%BA%AB%E8%AF%84%E8%AE%BA%E8%AE%BF%E9%97%AE%E7%BB%9F%E8%AE%A1%E6%8F%92%E4%BB%B6%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[加一个JiaThis的分享组件 怎么增加分享组件 官方教程网址 复制并粘贴下面的JS代码,放到您的网页，可以在和的之间网页的任意位置放置。如果您的网站使用的模板，您也可以复制代码到您的模板，按钮将在所有网页自动出现。 123456789101112131415&lt;!-- JiaThis Button BEGIN --&gt;&lt;div class="jiathis_style_32x32"&gt; &lt;a class="jiathis_button_qzone"&gt;&lt;/a&gt; &lt;a class="jiathis_button_tsina"&gt;&lt;/a&gt; &lt;a class="jiathis_button_tqq"&gt;&lt;/a&gt; &lt;a class="jiathis_button_weixin"&gt;&lt;/a&gt; &lt;a class="jiathis_button_renren"&gt;&lt;/a&gt; &lt;a href="http://www.jiathis.com/share?uid=2073019" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"&gt;&lt;/a&gt; &lt;a class="jiathis_counter_style"&gt;&lt;/a&gt;&lt;/div&gt;&lt;script type="text/javascript"&gt;var jiathis_config = &#123;data_track_clickback:'true'&#125;;&lt;/script&gt;&lt;script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=2073019" charset="utf-8"&gt;&lt;/script&gt;&lt;!-- JiaThis Button END --&gt; 增加评论功能 怎么使用 将如下代码插入到网站中需要评论框的位置中，可以放在和的之间任意位置 1234&lt;!-- UY BEGIN --&gt;&lt;div id="uyan_frame"&gt;&lt;/div&gt;&lt;script type="text/javascript" src="http://v2.uyan.cc/code/uyan.js?uid=2073019"&gt;&lt;/script&gt;&lt;!-- UY END --&gt; 添加百度统计功能 去百度统计网站注册账号 拷贝JS代码到主页中去 123456789&lt;script type=&quot;text/javascript&quot;&gt;var _hmt = _hmt || [];(function() &#123; var hm = document.createElement(&quot;script&quot;); hm.src = &quot;//hm.baidu.com/hm.js?1dd5125da2de7a41425d167822df1043&quot;; var s = document.getElementsByTagName(&quot;script&quot;)[0]; s.parentNode.insertBefore(hm, s);&#125;)();&lt;/script&gt;]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>JiaThis</tag>
        <tag>友言</tag>
        <tag>百度统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字图像分析-第四章空域增强技术]]></title>
    <url>%2F%E8%AF%BE%E7%A8%8B%E7%A0%94%E7%A9%B6%2F2015-11-25-%E7%A9%BA%E5%9F%9F%E5%A2%9E%E5%BC%BA%E6%8A%80%E6%9C%AF%2F</url>
    <content type="text"><![CDATA[数字图像分析-第四章空域增强技术数字图像分析-第四章空域增强技术直方图均衡化 定义：直方图均衡化技术是将原图像的直方图变为均衡分布的形式, 即将一已知灰度概率分布的图像, 经过某种变换, 变成一幅具有均匀灰度概率分布的新图像。 基本思想：通过灰度级fk的概率函数Pf(fk )，求出累积分布函数(CDF)gk ，建立等值像素出现的次数与结果图象像素值之间的关系。 算法步骤： 代码实现 12345678910111213141516171819202122232425262728293031323334353637383940414243%直方图均衡化I = imread('rice.png');[height,width] = size(I);figuresubplot(221)imshow(I)%显示原始图像subplot(222)imhist(I)%显示原始图像直方图%进行像素灰度统计;NumPixel = zeros(1,256);%统计各灰度数目，共256个灰度级for i = 1:height for j = 1: width NumPixel(I(i,j) + 1) = NumPixel(I(i,j) + 1) + 1;%对应灰度值像素点数量增加一 endend%计算灰度分布密度ProbPixel = zeros(1,256);for i = 1:256 ProbPixel(i) = NumPixel(i) / (height * width * 1.0);end%计算累计直方图分布CumuPixel = zeros(1,256);for i = 1:256 if i == 1 CumuPixel(i) = ProbPixel(i); else CumuPixel(i) = CumuPixel(i - 1) + ProbPixel(i); endend%累计分布取整CumuPixel = uint8(255 .* CumuPixel + 0.5);%对灰度值进行映射（均衡化）for i = 1:height for j = 1: width I(i,j) = CumuPixel(I(i,j)); endendsubplot(223)imshow(I)%显示原始图像subplot(224)imhist(I)%显示原始图像直方图 最后的效果图如下： 直方图规定化直方图均衡化通过扩展输入图像的灰度级来增强图像，然而在实际应用中，可能需要有目的的增强某个灰度区间的图像。 如：当需要从左边图像的灰度分布变换到右边的灰度密度函数 主要步骤:2.2 先对原始的直方图均衡化： S = T(r)2.2 同时对规定的直方图均衡化：$ v = G(z)$2.3 由于都是均衡化，故令$$S = v$$,则：$$ z = {G}^{-1}\left(v \right) = {G}^{-1}\left(T\left(r \right ) \right )$$ 主要的代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778clear allfigureA=imread('pout.tif'); %读入bmp彩色图像subplot(221)imshow(A) %显示出来 title('输入的bmp图像')%绘制直方图[m,n]=size(A); %测量图像尺寸B=zeros(1,256); %预创建存放灰度出现概率的向量for k=0:255 B(k+1)=length(find(A==k))/(m*n); %计算每级灰度出现的概率，将其存入B中相应位置endsubplot(222)bar(0:255,B,'g'); %绘制直方图title('原图像直方图')xlabel('灰度值')ylabel('出现概率')axis([0,260,0,0.015])S1=zeros(1,256);for i=1:256 for j=1:i S1(i)=B(j)+S1(i); %计算原灰度图累计直方图 endend counts=[zeros(1,49),0.1,zeros(1,49),0.2,zeros(1,49),0.3,zeros(1,49),0.1,zeros(1,49),0.2,zeros(1,49),0.1];%规定化直方图 %figure,bar(1:300,counts,'r') S2=zeros(1,256); for i=1:256 for j=1:i S2(i)=counts(j)+S2(i); end end; %"累计"规定化直方图 %对比直方图，找到相差最小的灰度级 for i=1:256 for j=1:256 if S1(j)&lt;=S2(i)&amp;S1(j+1)&gt;=S2(i) if abs(S1(j)-S2(i))&lt;=abs(S1(j+1)-S2(i)) T(i)=j; else T(i)=j+1; end end end end%确定变换关系，重组直方图 H=zeros(1,256); H(1)=S2(1); for i=2:256 if T(i-1)&gt;0 for k=(T(i-1)+1):T(i) H(i)=H(i)+B(k); end else H(i)=0; end endsubplot(223) bar(0:255,H,'g') %显示规定化后的直方图title('规定化后的直方图')xlabel('灰度值')ylabel('出现概率')axis([0,260,0,0.6])%显示规定图PA=A; %将各个像素归一化后的灰度值赋给这个像素for i=1:m for j=1:n for k=2:256 if T(k-1)&lt;=A(i,j)&amp;A(i,j)&lt;=T(k) PA(i,j)=k; break; end end endendsubplot(224)imshow(PA) %显示均衡化后的图像title('规定化后图像') 最后的效果图： 空间滤波 卷积：图像就是图像f(x),模板是g(x),然后将模版g(x)在模版中移动,每到一个位置,就把f(x)与g(x)的定义域相交的元素进行乘积并且求和,得出新的图像一点,就是被卷积后的图像.模版又称为卷积核.卷积核做一个矩阵的形状。由于大多数模板都是对称的，所以模板不旋转。 一个简单的数字图像卷积处理流程可以如下： 读取源图像像素 应用卷积操作数矩阵产生目标图像 对目标图像进行归一化处理 处理边界像素 常用模板 梯度算子—用于边缘检测 水平垂直差分法： $$g\left(i,j \right ) = \left | f\left(i,j \right ) -f\left(i+1,j \right ) \right | + \left | f\left(i,j \right ) -f\left(i,j+1 \right ) \right |$$ Robert 算子梯度 $$g\left(i,j \right ) = \left | f\left(i,j \right ) -f\left(i+1,j+1 \right ) \right | + \left | f\left(i+1,j \right ) -f\left(i,j+1 \right ) \right |$$ sobel算子 该算子包含两组3x3的矩阵，分别为横向及纵向，将之与图像作平面卷积，即可分别得出横向及纵向的亮度差分近似值。如果以A代表原始图像，Gx及Gy分别代表经横向及纵向边缘检测的图像灰度值，其公式如下： 图像的每一个像素的横向及纵向灰度值通过以下公式结合，来计算该点灰度的大小： 通常，为了提高效率使用不开平方的近似值： 拉普拉斯算子 $$g\left(i,j \right ) = 8*f\left(i,j \right ) - \left | f\left(i-1,j \right ) + f\left(i+1,j \right ) + f\left(i,j-1 \right ) + f\left(i,j+1 \right ) \right |$$]]></content>
      <categories>
        <category>课程研究</category>
      </categories>
      <tags>
        <tag>均衡化</tag>
        <tag>规定化</tag>
        <tag>边缘检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决问题：手机ping不通主机win10]]></title>
    <url>%2F%E7%96%91%E9%9A%BE%E8%A7%A3%E6%83%91%2F2015-11-25-%E6%89%8B%E6%9C%BAping%E4%B8%8D%E9%80%9A%E4%B8%BB%E6%9C%BAwin10%2F</url>
    <content type="text"><![CDATA[如何Ping通主机 先Ping一下win10的主机 打开控制面板，进入系统和安全 进入Window防火墙 点击高级设置 选择入站规则 向下拉，找到文件与打印机共享（回显请求-ICMPv4），启用规则]]></content>
      <categories>
        <category>疑难解惑</category>
      </categories>
      <tags>
        <tag>ping</tag>
        <tag>win10访问受限</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于Latex、git、vim、Linux的常用命令]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2015-11-23-github_vim_Linux_Note%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>Latex</tag>
        <tag>vim</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jekyll的本地环境搭建及编译]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2015-11-22-Jekyll_github_page%2F</url>
    <content type="text"><![CDATA[注意点 关于源的问题 1.1 有些时候外网不是很好访问，这个时候就需要访问一些镜像网站了，如在下载某些插件或更新Ruby的时候可以将源指向https://ruby.taobao.org/ 1.2 还有就是自己花钱买专用网络通道了 关于Ruby的版本 最好下载的时候将Ruby和RubyDevKit的版本下载一个版本的 关于gem的介绍 网上有些教程还说要下载什么gem系统，其实现在已经不用了，因为ruby已经集成了 本地环境的搭建第一步：Ruby的安装jekyll本身基于Ruby开发，因此，想要在本地构建一个测试环境需要具有Ruby的开发和运行环境。在windows下，可以使用Rubyinstaller安装。 第二步：RubyDevKit安装从这里下载DevKit，注意版本要与Ruby版本一致 下载下来的是一个压缩文件，如果你安装有7-zip，可以直接双击，它会自解压到你所选择的目录。建议安装在和Ruby的同级目录下，例如：两者同时安装在D盘根目录下。 解压完成之后，用cmd进入到刚才解压的目录下，运行下面命令，该命令会生成config.yml。 1ruby dk.rb init config.yml文件实际上是检测系统安装的ruby的位置并记录在这个文件中，以便稍后使用。但上面的命令只针对使用rubyinstall安装的ruby有效，如果是其他方式安装的话，需要手动修改config.yml。我生成的config.yml文件内容如下：（注意路径用的是linux的斜杠方向） 123456789101112131415# This configuration file contains the absolute path locations of all# installed Rubies to be enhanced to work with the DevKit. This config# file is generated by the &apos;ruby dk.rb init&apos; step and may be modified# before running the &apos;ruby dk.rb install&apos; step. To include any installed# Rubies that were not automagically discovered, simply add a line below# the triple hyphens with the absolute path to the Ruby root directory.## Example:## ---# - C:/ruby19trunk# - C:/ruby192dev#---- E:/Dev/Ruby22-x64 最后，执行如下命令，执行安装： 1ruby setup.rb 如果没有setup.rb的话，执行： 1ruby dk.rb install 第三步：Ruby gems的安装(可免，Ruby已经集成)Rubygems是类似Radhat的RPM、centOS的Yum、Ubuntu的apt-get的应用程序打包部署解决方案。Rubygems本身基于Ruby开发，在Ruby命令行中执行。我们需要它主要是因为jekyll的执行需要依赖很多Ruby应用程序，如果一个个手动安装比较繁琐。jekyll作为一个Ruby的应用，也实现了Rubygems打包标准。只要通过简单的命令就可以自动下载其依赖。 更新ruby和gems系统时 1gem update --system 现在的Ruby版本都已经默认安装了gem，所有就没有大费周折的去绕过天朝的墙了，不过由于源问题，还是留一手比较好 123$ gem sources --remove http://rubygems.org/$ gem sources -a http://ruby.taobao.org/$ gem sources -l 第四步：安装jekyll(可免,见第6步)有了上面的基础，安装jekyll就十分轻松了，执行下面gem命令即可全自动搞定： 1$ gem install jekyll 第五步：安装Bundle 以前搭建Jekyll本地环境的时候步骤非常复杂，不过现在情况变的更简单了，github有一个对应的gem，可以”一键”配置环境，具体可以参考Using Jekyll with Pages。 直接使用下面命令即可： 1$ gem install bundle 第六步：Gemfile和Bundle安装在你blog项目的根目录下创建一个叫Gemfile的文件，注意没有后缀，输入下面内容 123456789source 'https://ruby.taobao.org/'gem 'jekyll'gem 'jekyll-paginate'gem 'redcarpet', '~&gt; 3.2.3'gem 'jekyll-watch', '~&gt; 1.2.1'gem 'pygments.rb'gem 'kramdown'gem 'wdm', '&gt;= 0.1.0' if Gem.win_platform? 保存后，在命令行中执行 1$ bundle install 命令会根据当前目录下的Gemfile，安装所需要的所有软件。这一步所安装的东西，可以说跟github本身的环境是完全一致的，所以可以确保本地如果没有错误，上传后也不会有错误。而且可以在将来使用下面命令，随时更新环境，十分方便 1$ bundle update 第七步：启动转化和本地服务1$ bundle exec jekyll serve]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>Jekyll</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初步学习github page 和Jekyll来构建博客]]></title>
    <url>%2F%E7%AC%94%E8%AE%B0%2F2015-11-19-github_blog%2F</url>
    <content type="text"><![CDATA[首先最基本的博客搭建出现的问题 1.文本一定要以UTF-8 无BOM格式存储啊！！！不然显示不出 引言：一些问题的解答： 想找服务器挂载一个自己的个人主页或博客，去哪找呢？ 一般像自己当掌握一门技术，当希望有一个属于自己空间，然后把自己的技术心得进行阐述的时候，就会想起记工作笔记，之前自己尝试过用Latex模板来记录学习情况，但是渐渐的。。。。发现Latex在消耗自己的时间成本上代价太大了，然后转转悠悠，偶然的机会我接触到了Mardown语法，突然间自己对此简直爱不释手，语法非常简单，虽然在版面的优化上比不上Latex模板的强大，但是语法之简单，而且可以生成Html的格式。此时我又发现一个问题，Markdown生成的Html页面整理起来不方便。于是自己又通过马克飞象这个工具，离线的记录然后生成PDF版本的笔记，这样就能很好的做一个工作笔记了。但是简简是自己查看感觉这个文档不是在线的查看而是离线查看不太方便，于是自己开始酝酿搞一个自己的博客。一开始自己去了CSDN上写博客，总感觉自己好不爽，爽然东西都是自己的，但是感觉东西是放在人家那里的，整个目录的内容不能离线的处理同步，逐渐自己发现了github能开设自己的博客，于是一下子自己找到了组织了。下面三个阶段很能描述自己纠结的三个阶段。 第一阶段，刚接触Blog，觉得很新鲜，试着选择一个免费空间来写。 第二阶段，发现免费空间限制太多，就自己购买域名和空间，搭建独立博客。 第三阶段，觉得独立博客的管理太麻烦，最好在保留控制权的前提下，让别人来管，自己只负责写文章。 为什么来到github上挂载自己的博客？什么情况下github.io又不适合了？ 一开始自己还考虑过挂载到阿里云上去，但是在查看阿里云上面的价格后自己就退却了，自己还真没有这个实力去支持这个，当然了主要的还是要看自己的需求了，如果自己需要所有的网页内容都动态的更新加载，所有的操作都在云端实现，这个时候就需要自己花钱买云服务器了，应为在github上挂载的主页都是些静态的网页，如果有大量的交互操作的时候，显然github page是不适合你的。 关于区分个人博客的创建和项目主页的创建 github page主要有两种创建方式 一种是在github根目录上创建一个名字为：username.github.io的项目，并且定义成master属性。此时访问的网址则为：username.github.io 就是主页的网址。 另一个是在任意定义的projectName项目下，通过以下命令在项目的根目录上创建分支节点 1~$ git checkout --orphan gh-pages 因为github规定，只有该分支中的页面，才会生成网页文件 第一步：在github创建一个项目首先到GitHub上创建一个项目（ create a new repository）,并且命名为：username.github.io，username是你注册github账号时的用户名。 第二步：clone到本地~$ git clone https://github.com/username/username.github.io 第三步：编写Helloworld的主程序~$ cd username.github.io ~$ echo &quot;Hello World&quot; &gt; index.html 第四步：上传主程序，查看效果~$ git add --all ~$ git commit -m &quot;Initial commit&quot; ~$ git push -u origin master 然后是结合Jekyll搭建博客Jekyll是什么？Jekyll（发音/‘d?i?k ?l/，”杰克尔”）是一个静态站点生成器，它会根据网页源码生成静态文件。它提供了模板、变量、插件等功能，所以实际上可以用来编写整个网站。 整个思路到这里就很明显了。你先在本地编写符合Jekyll规范的网站源码，然后上传到github，由github生成并托管整个网站。 这种做法的好处是： 免费，无限流量。 享受git的版本管理功能，不用担心文章遗失。 你只要用自己喜欢的编辑器写文章就可以了，其他事情一概不用操心，都由github处理 它的缺点是： 有一定技术门槛，你必须要懂一点git和网页开发。 它生成的是静态网页，添加动态功能必须使用外部服务，比如评论功能就只能用disqus。 它不适合大型网站，因为没有用到数据库，每运行一次都必须遍历全部的文本文件，网站越大，生成时间越长。如何快速完成一个基于Jekyll的个人博客？第一步在你的电脑上，建立一个目录，作为项目的主目录。我们假定，它的名称为jekyll_demo。 1$ mkdir jekyll_demo 对该目录进行git初始化 12$ cd jekyll_demo$ git init 然后，创建一个没有父节点的分支gh-pages。因为github规定，只有该分支中的页面，才会生成网页文件。 1$ git checkout --orphan gh-pages 第二步在项目根目录下，建立一个名为_config.yml的文本文件。它是jekyll的设置文件，我们在里面填入如下内容，其他设置都可以用默认选项，具体解释参见官方网页。 1baseurl: /jekyll_demo 目录结构变成： 12/jekyll_demo |-- _config.yml 第三步在项目根目录下，创建一个_layouts目录，用于存放模板文件。 1$ mkdir _layouts 进入该目录，创建一个default.html文件，作为Blog的默认模板。并在该文件中填入以下内容。 123456789101112&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta http-equiv="content-type" content="text/html; charset=utf-8" /&gt; &lt;title&gt;&#123;&#123; page.title &#125;&#125;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &#123;&#123; content &#125;&#125; &lt;/body&gt; &lt;/html&gt; Jekyll使用Liquid模板语言，表示文章标题，首先最基本的博客搭建出现的问题 1.文本一定要以UTF-8 无BOM格式存储啊！！！不然显示不出 引言：一些问题的解答： 想找服务器挂载一个自己的个人主页或博客，去哪找呢？ 一般像自己当掌握一门技术，当希望有一个属于自己空间，然后把自己的技术心得进行阐述的时候，就会想起记工作笔记，之前自己尝试过用Latex模板来记录学习情况，但是渐渐的。。。。发现Latex在消耗自己的时间成本上代价太大了，然后转转悠悠，偶然的机会我接触到了Mardown语法，突然间自己对此简直爱不释手，语法非常简单，虽然在版面的优化上比不上Latex模板的强大，但是语法之简单，而且可以生成Html的格式。此时我又发现一个问题，Markdown生成的Html页面整理起来不方便。于是自己又通过马克飞象这个工具，离线的记录然后生成PDF版本的笔记，这样就能很好的做一个工作笔记了。但是简简是自己查看感觉这个文档不是在线的查看而是离线查看不太方便，于是自己开始酝酿搞一个自己的博客。一开始自己去了CSDN上写博客，总感觉自己好不爽，爽然东西都是自己的，但是感觉东西是放在人家那里的，整个目录的内容不能离线的处理同步，逐渐自己发现了github能开设自己的博客，于是一下子自己找到了组织了。下面三个阶段很能描述自己纠结的三个阶段。 第一阶段，刚接触Blog，觉得很新鲜，试着选择一个免费空间来写。 第二阶段，发现免费空间限制太多，就自己购买域名和空间，搭建独立博客。 第三阶段，觉得独立博客的管理太麻烦，最好在保留控制权的前提下，让别人来管，自己只负责写文章。 为什么来到github上挂载自己的博客？什么情况下github.io又不适合了？ 一开始自己还考虑过挂载到阿里云上去，但是在查看阿里云上面的价格后自己就退却了，自己还真没有这个实力去支持这个，当然了主要的还是要看自己的需求了，如果自己需要所有的网页内容都动态的更新加载，所有的操作都在云端实现，这个时候就需要自己花钱买云服务器了，应为在github上挂载的主页都是些静态的网页，如果有大量的交互操作的时候，显然github page是不适合你的。 关于区分个人博客的创建和项目主页的创建 github page主要有两种创建方式 一种是在github根目录上创建一个名字为：username.github.io的项目，并且定义成master属性。此时访问的网址则为：username.github.io 就是主页的网址。 另一个是在任意定义的projectName项目下，通过以下命令在项目的根目录上创建分支节点 1~$ git checkout --orphan gh-pages 因为github规定，只有该分支中的页面，才会生成网页文件 第一步：在github创建一个项目首先到GitHub上创建一个项目（ create a new repository）,并且命名为：username.github.io，username是你注册github账号时的用户名。 第二步：clone到本地~$ git clone https://github.com/username/username.github.io 第三步：编写Helloworld的主程序~$ cd username.github.io ~$ echo &quot;Hello World&quot; &gt; index.html 第四步：上传主程序，查看效果~$ git add --all ~$ git commit -m &quot;Initial commit&quot; ~$ git push -u origin master 然后是结合Jekyll搭建博客Jekyll是什么？Jekyll（发音/‘d?i?k ?l/，”杰克尔”）是一个静态站点生成器，它会根据网页源码生成静态文件。它提供了模板、变量、插件等功能，所以实际上可以用来编写整个网站。 整个思路到这里就很明显了。你先在本地编写符合Jekyll规范的网站源码，然后上传到github，由github生成并托管整个网站。 这种做法的好处是： 免费，无限流量。 享受git的版本管理功能，不用担心文章遗失。 你只要用自己喜欢的编辑器写文章就可以了，其他事情一概不用操心，都由github处理 它的缺点是： 有一定技术门槛，你必须要懂一点git和网页开发。 它生成的是静态网页，添加动态功能必须使用外部服务，比如评论功能就只能用disqus。 它不适合大型网站，因为没有用到数据库，每运行一次都必须遍历全部的文本文件，网站越大，生成时间越长。如何快速完成一个基于Jekyll的个人博客？第一步在你的电脑上，建立一个目录，作为项目的主目录。我们假定，它的名称为jekyll_demo。 1$ mkdir jekyll_demo 对该目录进行git初始化 12$ cd jekyll_demo$ git init 然后，创建一个没有父节点的分支gh-pages。因为github规定，只有该分支中的页面，才会生成网页文件。 1$ git checkout --orphan gh-pages 第二步在项目根目录下，建立一个名为_config.yml的文本文件。它是jekyll的设置文件，我们在里面填入如下内容，其他设置都可以用默认选项，具体解释参见官方网页。 1baseurl: /jekyll_demo 目录结构变成： 12/jekyll_demo |-- _config.yml 第三步在项目根目录下，创建一个_layouts目录，用于存放模板文件。 1$ mkdir _layouts 进入该目录，创建一个default.html文件，作为Blog的默认模板。并在该文件中填入以下内容。 123456789101112&lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;meta http-equiv="content-type" content="text/html; charset=utf-8" /&gt; &lt;title&gt;&#123;&#123; page.title &#125;&#125;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &#123;&#123; content &#125;&#125; &lt;/body&gt; &lt;/html&gt; Jekyll使用Liquid模板语言，{{ page.title }}表示文章标题，{{ content }}表示文章内容，更多模板变量请参考官方文档。目录结构变成： 1234/jekyll_demo |-- _config.yml |-- _layouts | |-- default.html 第四步回到项目根目录，创建一个_posts目录，用于存放blog文章。 1$ mkdir _posts 进入该目录，创建第一篇文章。文章就是普通的文本文件，文件名假定为2012-08-25-hello-world.html。(注意，文件名必须为”年-月-日-文章标题.后缀名”的格式。如果网页代码采用html格式，后缀名为html；如果采用markdown格式，后缀名为md。）在该文件中，填入以下内容：（注意，行首不能有空格） 1234567---layout: defaulttitle: 你好，世界---&lt;h2&gt;&#123;&#123; page.title &#125;&#125;&lt;/h2&gt;&lt;p&gt;我的第一篇文章&lt;/p&gt;&lt;p&gt;&#123;&#123; page.date | date_to_string &#125;&#125;&lt;/p&gt; 每篇文章的头部，必须有一个yaml文件头，用来设置一些元数据。它用三根短划线”—“，标记开始和结束，里面每一行设置一种元数据。”layout:default”，表示该文章的模板使用_layouts目录下的default.html文件；”title: 你好，世界”，表示该文章的标题是”你好，世界”，如果不设置这个值，默认使用嵌入文件名的标题，即”hello world”。在yaml文件头后面，就是文章的正式内容，里面可以使用模板变量。{{ page.title }}就是文件头中设置的”你好，世界”，{{ page.date }}则是嵌入文件名的日期（也可以在文件头重新定义date变量），”| date_to_string”表示将page.date变量转化成人类可读的格式。目录结构变成： 123456/jekyll_demo |-- _config.yml |-- _layouts | |-- default.html |-- _posts | |-- 2012-08-25-hello-world.html 第五步:创建首页有了文章以后，还需要有一个首页。回到根目录，创建一个index.html文件，填入以下内容。 1234567891011---layout: defaulttitle: 我的Blog--- &lt;h2&gt;&#123;&#123; page.title &#125;&#125;&lt;/h2&gt; &lt;p&gt;最新文章&lt;/p&gt; &lt;ul&gt; &#123;% for post in site.posts %&#125; &lt;li&gt;&#123;&#123; post.date | date_to_string &#125;&#125; &lt;a href="&#123;&#123; site.baseurl &#125;&#125;&#123;&#123; post.url &#125;&#125;"&gt;&#123;&#123; post.title &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; 它的Yaml文件头表示，首页使用default模板，标题为”我的Blog”。然后，首页使用了 {$% for post in site.posts %$} ‘，表示对所有帖子进行一个遍历。这里要注意的是，Liquid模板语言规定，输出内容使用两层大括号，单纯的命令使用一层大括号。至于{{site.baseurl}}就是_config.yml中设置的baseurl变量。目录结构变成： 1234567/jekyll_demo |-- _config.yml |-- _layouts | |-- default.html |-- _posts | |-- 2012-08-25-hello-world.html |-- index.html 第六步，发布内容。现在，这个简单的Blog就可以发布了。先把所有内容加入本地git库。 12$ git add .$ git commit -m "first post" 然后，前往github的网站，在网站上创建一个名为jekyll_demo的库。接着，再将本地内容推送到github上你刚创建的库。注意，下面命令中的username，要替换成你的username。 12$ git remote add origin https://github.com/username/jekyll_demo.git$ git push origin gh-pages 上传成功之后，等10分钟左右，访问http://username.github.com/jekyll_demo/就可以看到Blog已经生成了（将username换成你的用户名）。 参考文章: 阮一峰的搭建一个免费的，无限流量的Blog—-github Pages和Jekyll入门 表示文章内容，更多模板变量请参考官方文档。目录结构变成： 1234/jekyll_demo |-- _config.yml |-- _layouts | |-- default.html 第四步回到项目根目录，创建一个_posts目录，用于存放blog文章。 1$ mkdir _posts 进入该目录，创建第一篇文章。文章就是普通的文本文件，文件名假定为2012-08-25-hello-world.html。(注意，文件名必须为”年-月-日-文章标题.后缀名”的格式。如果网页代码采用html格式，后缀名为html；如果采用markdown格式，后缀名为md。）在该文件中，填入以下内容：（注意，行首不能有空格） 1234567---layout: defaulttitle: 你好，世界---&lt;h2&gt;&#123;&#123; page.title &#125;&#125;&lt;/h2&gt;&lt;p&gt;我的第一篇文章&lt;/p&gt;&lt;p&gt;&#123;&#123; page.date | date_to_string &#125;&#125;&lt;/p&gt; 每篇文章的头部，必须有一个yaml文件头，用来设置一些元数据。它用三根短划线”—“，标记开始和结束，里面每一行设置一种元数据。”layout:default”，表示该文章的模板使用_layouts目录下的default.html文件；”title: 你好，世界”，表示该文章的标题是”你好，世界”，如果不设置这个值，默认使用嵌入文件名的标题，即”hello world”。在yaml文件头后面，就是文章的正式内容，里面可以使用模板变量。就是文件头中设置的”你好，世界”，则是嵌入文件名的日期（也可以在文件头重新定义date变量），”| date_to_string”表示将page.date变量转化成人类可读的格式。目录结构变成： 123456/jekyll_demo |-- _config.yml |-- _layouts | |-- default.html |-- _posts | |-- 2012-08-25-hello-world.html 第五步:创建首页有了文章以后，还需要有一个首页。回到根目录，创建一个index.html文件，填入以下内容。 1234567891011---layout: defaulttitle: 我的Blog--- &lt;h2&gt;&#123;&#123; page.title &#125;&#125;&lt;/h2&gt; &lt;p&gt;最新文章&lt;/p&gt; &lt;ul&gt; &#123;% for post in site.posts %&#125; &lt;li&gt;&#123;&#123; post.date | date_to_string &#125;&#125; &lt;a href="&#123;&#123; site.baseurl &#125;&#125;&#123;&#123; post.url &#125;&#125;"&gt;&#123;&#123; post.title &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; 它的Yaml文件头表示，首页使用default模板，标题为”我的Blog”。然后，首页使用了 {$% for post in site.posts %$} ‘，表示对所有帖子进行一个遍历。这里要注意的是，Liquid模板语言规定，输出内容使用两层大括号，单纯的命令使用一层大括号。至于就是_config.yml中设置的baseurl变量。目录结构变成： 1234567/jekyll_demo |-- _config.yml |-- _layouts | |-- default.html |-- _posts | |-- 2012-08-25-hello-world.html |-- index.html 第六步，发布内容。现在，这个简单的Blog就可以发布了。先把所有内容加入本地git库。 12$ git add .$ git commit -m "first post" 然后，前往github的网站，在网站上创建一个名为jekyll_demo的库。接着，再将本地内容推送到github上你刚创建的库。注意，下面命令中的username，要替换成你的username。 12$ git remote add origin https://github.com/username/jekyll_demo.git$ git push origin gh-pages 上传成功之后，等10分钟左右，访问http://username.github.com/jekyll_demo/就可以看到Blog已经生成了（将username换成你的用户名）。 参考文章: 阮一峰的搭建一个免费的，无限流量的Blog—-github Pages和Jekyll入门]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>Jekyll</tag>
      </tags>
  </entry>
</search>
